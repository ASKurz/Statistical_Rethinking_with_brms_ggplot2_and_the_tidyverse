<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Big Entropy and the Generalized Linear Model | Statistical rethinking with brms, ggplot2, and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Big Entropy and the Generalized Linear Model | Statistical rethinking with brms, ggplot2, and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKURZ/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Big Entropy and the Generalized Linear Model | Statistical rethinking with brms, ggplot2, and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz" />


<meta name="date" content="2020-10-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="markov-chain-monte-carlo.html"/>
<link rel="next" href="counting-and-classification.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>This is a love letter</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this"><i class="fa fa-check"></i>Why this?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#my-assumptions-about-you"><i class="fa fa-check"></i>My assumptions about you</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-and-understand-this-project"><i class="fa fa-check"></i>How to use and understand this project</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#you-can-do-this-too"><i class="fa fa-check"></i>You can do this, too</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#we-have-updates"><i class="fa fa-check"></i>We have updates</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-0.9.0."><i class="fa fa-check"></i>Version 0.9.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.0.0."><i class="fa fa-check"></i>Version 1.0.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.0.1."><i class="fa fa-check"></i>Version 1.0.1.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.1.0."><i class="fa fa-check"></i>Version 1.1.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.2.0."><i class="fa fa-check"></i>Version 1.2.0.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#is-this-material-obsolete"><i class="fa fa-check"></i>Is this material obsolete?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#thank-yous-are-in-order"><i class="fa fa-check"></i>Thank-you’s are in order</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html"><i class="fa fa-check"></i><b>1</b> The Golem of Prague</a><ul>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html"><i class="fa fa-check"></i><b>2</b> Small Worlds and Large Worlds</a><ul>
<li class="chapter" data-level="2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#the-garden-of-forking-data"><i class="fa fa-check"></i><b>2.1</b> The garden of forking data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#counting-possibilities."><i class="fa fa-check"></i><b>2.1.1</b> Counting possibilities.</a></li>
<li class="chapter" data-level="2.1.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#using-prior-information."><i class="fa fa-check"></i><b>2.1.2</b> Using prior information.</a></li>
<li class="chapter" data-level="2.1.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#from-counts-to-probability."><i class="fa fa-check"></i><b>2.1.3</b> From counts to probability.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#building-a-model"><i class="fa fa-check"></i><b>2.2</b> Building a model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-data-story."><i class="fa fa-check"></i><b>2.2.1</b> A data story.</a></li>
<li class="chapter" data-level="2.2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayesian-updating."><i class="fa fa-check"></i><b>2.2.2</b> Bayesian updating.</a></li>
<li class="chapter" data-level="2.2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#evaluate."><i class="fa fa-check"></i><b>2.2.3</b> Evaluate.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#components-of-the-model"><i class="fa fa-check"></i><b>2.3</b> Components of the model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#likelihood."><i class="fa fa-check"></i><b>2.3.1</b> Likelihood.</a></li>
<li class="chapter" data-level="2.3.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#parameters."><i class="fa fa-check"></i><b>2.3.2</b> Parameters.</a></li>
<li class="chapter" data-level="2.3.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#prior."><i class="fa fa-check"></i><b>2.3.3</b> Prior.</a></li>
<li class="chapter" data-level="2.3.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#posterior."><i class="fa fa-check"></i><b>2.3.4</b> Posterior.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#making-the-model-go"><i class="fa fa-check"></i><b>2.4</b> Making the model go</a><ul>
<li class="chapter" data-level="2.4.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#grid-approximation."><i class="fa fa-check"></i><b>2.4.1</b> Grid approximation.</a></li>
<li class="chapter" data-level="2.4.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#quadratic-approximation."><i class="fa fa-check"></i><b>2.4.2</b> Quadratic approximation.</a></li>
<li class="chapter" data-level="2.4.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#markov-chain-monte-carlo."><i class="fa fa-check"></i><b>2.4.3</b> Markov chain Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html"><i class="fa fa-check"></i><b>3</b> Sampling the Imaginary</a><ul>
<li class="chapter" data-level="3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-from-a-grid-like-approximate-posterior"><i class="fa fa-check"></i><b>3.1</b> Sampling from a grid-like approximate posterior</a></li>
<li class="chapter" data-level="3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-summarize"><i class="fa fa-check"></i><b>3.2</b> Sampling to summarize</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-boundaries."><i class="fa fa-check"></i><b>3.2.1</b> Intervals of defined boundaries.</a></li>
<li class="chapter" data-level="3.2.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-mass."><i class="fa fa-check"></i><b>3.2.2</b> Intervals of defined mass.</a></li>
<li class="chapter" data-level="3.2.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#point-estimates."><i class="fa fa-check"></i><b>3.2.3</b> Point estimates.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-simulate-prediction"><i class="fa fa-check"></i><b>3.3</b> Sampling to simulate prediction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#dummy-data."><i class="fa fa-check"></i><b>3.3.1</b> Dummy data.</a></li>
<li class="chapter" data-level="3.3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#model-checking."><i class="fa fa-check"></i><b>3.3.2</b> Model checking.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#summary-lets-practice-with-brms"><i class="fa fa-check"></i><b>3.4</b> <del>Summary</del> Let’s practice with brms</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>4</b> Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-models.html"><a href="linear-models.html#why-normal-distributions-are-normal"><i class="fa fa-check"></i><b>4.1</b> Why normal distributions are normal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linear-models.html"><a href="linear-models.html#normal-by-addition."><i class="fa fa-check"></i><b>4.1.1</b> Normal by addition.</a></li>
<li class="chapter" data-level="4.1.2" data-path="linear-models.html"><a href="linear-models.html#normal-by-multiplication."><i class="fa fa-check"></i><b>4.1.2</b> Normal by multiplication.</a></li>
<li class="chapter" data-level="4.1.3" data-path="linear-models.html"><a href="linear-models.html#normal-by-log-multiplication."><i class="fa fa-check"></i><b>4.1.3</b> Normal by log-multiplication.</a></li>
<li class="chapter" data-level="4.1.4" data-path="linear-models.html"><a href="linear-models.html#using-gaussian-distributions."><i class="fa fa-check"></i><b>4.1.4</b> Using Gaussian distributions.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-models.html"><a href="linear-models.html#a-language-for-describing-models"><i class="fa fa-check"></i><b>4.2</b> A language for describing models</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-models.html"><a href="linear-models.html#re-describing-the-globe-tossing-model."><i class="fa fa-check"></i><b>4.2.1</b> Re-describing the globe tossing model.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-models.html"><a href="linear-models.html#a-gaussian-model-of-height"><i class="fa fa-check"></i><b>4.3</b> A Gaussian model of height</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linear-models.html"><a href="linear-models.html#the-data."><i class="fa fa-check"></i><b>4.3.1</b> The data.</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-models.html"><a href="linear-models.html#the-model."><i class="fa fa-check"></i><b>4.3.2</b> The model.</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-models.html"><a href="linear-models.html#grid-approximation-of-the-posterior-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Grid approximation of the posterior distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="linear-models.html"><a href="linear-models.html#sampling-from-the-posterior."><i class="fa fa-check"></i><b>4.3.4</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="4.3.5" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model-with-map-brm."><i class="fa fa-check"></i><b>4.3.5</b> Fitting the model with <del><code>map</code></del> <code>brm()</code>.</a></li>
<li class="chapter" data-level="4.3.6" data-path="linear-models.html"><a href="linear-models.html#sampling-from-a-map-brm-fit."><i class="fa fa-check"></i><b>4.3.6</b> Sampling from a <del><code>map</code></del> <code>brm()</code> fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-models.html"><a href="linear-models.html#adding-a-predictor"><i class="fa fa-check"></i><b>4.4</b> Adding a predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="linear-models.html"><a href="linear-models.html#the-linear-model-strategy."><i class="fa fa-check"></i><b>4.4.1</b> The linear model strategy.</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model."><i class="fa fa-check"></i><b>4.4.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="4.4.3" data-path="linear-models.html"><a href="linear-models.html#interpreting-the-model-fit."><i class="fa fa-check"></i><b>4.4.3</b> Interpreting the model fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-models.html"><a href="linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>4.5</b> Polynomial regression</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html"><i class="fa fa-check"></i><b>5</b> Multivariate Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#spurious-associations"><i class="fa fa-check"></i><b>5.1</b> Spurious associations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multivariate-notation."><i class="fa fa-check"></i><b>5.1.1</b> Multivariate notation.</a></li>
<li class="chapter" data-level="5.1.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#fitting-the-model.-1"><i class="fa fa-check"></i><b>5.1.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="5.1.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#plotting-multivariate-posteriors."><i class="fa fa-check"></i><b>5.1.3</b> Plotting multivariate posteriors.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#masked-relationship"><i class="fa fa-check"></i><b>5.2</b> Masked relationship</a></li>
<li class="chapter" data-level="5.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinearity"><i class="fa fa-check"></i><b>5.3</b> Multicollinearity</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-legs."><i class="fa fa-check"></i><b>5.3.1</b> Multicollinear legs.</a></li>
<li class="chapter" data-level="5.3.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-milk."><i class="fa fa-check"></i><b>5.3.2</b> Multicollinear <code>milk</code>.</a></li>
<li class="chapter" data-level="5.3.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#post-treatment-bias."><i class="fa fa-check"></i><b>5.3.3</b> Post-treatment bias.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#categorical-variables"><i class="fa fa-check"></i><b>5.4</b> Categorical variables</a><ul>
<li class="chapter" data-level="5.4.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#binary-categories."><i class="fa fa-check"></i><b>5.4.1</b> Binary categories.</a></li>
<li class="chapter" data-level="5.4.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#many-categories."><i class="fa fa-check"></i><b>5.4.2</b> Many categories.</a></li>
<li class="chapter" data-level="5.4.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#adding-regular-predictor-variables."><i class="fa fa-check"></i><b>5.4.3</b> Adding regular predictor variables.</a></li>
<li class="chapter" data-level="5.4.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#another-approach-unique-intercepts."><i class="fa fa-check"></i><b>5.4.4</b> Another approach: Unique intercepts.</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#ordinary-least-squares-and-lm"><i class="fa fa-check"></i><b>5.5</b> <del>Ordinary least squares and <code>lm()</code></del></a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html"><i class="fa fa-check"></i><b>6</b> Overfitting, Regularization, and Information Criteria</a><ul>
<li class="chapter" data-level="6.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#the-problem-with-parameters"><i class="fa fa-check"></i><b>6.1</b> The problem with parameters</a><ul>
<li class="chapter" data-level="6.1.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#more-parameters-always-improve-fit."><i class="fa fa-check"></i><b>6.1.1</b> More parameters always improve fit.</a></li>
<li class="chapter" data-level="6.1.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#too-few-parameters-hurts-too."><i class="fa fa-check"></i><b>6.1.2</b> Too few parameters hurts, too.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-theory-and-model-performance"><i class="fa fa-check"></i><b>6.2</b> Information theory and model performance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#firing-the-weatherperson."><i class="fa fa-check"></i><b>6.2.1</b> Firing the weatherperson.</a></li>
<li class="chapter" data-level="6.2.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-and-uncertainty."><i class="fa fa-check"></i><b>6.2.2</b> Information and uncertainty.</a></li>
<li class="chapter" data-level="6.2.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-entropy-to-accuracy."><i class="fa fa-check"></i><b>6.2.3</b> From entropy to accuracy.</a></li>
<li class="chapter" data-level="6.2.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-divergence-to-deviance."><i class="fa fa-check"></i><b>6.2.4</b> From divergence to deviance.</a></li>
<li class="chapter" data-level="6.2.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-deviance-to-out-of-sample."><i class="fa fa-check"></i><b>6.2.5</b> From deviance to out-of-sample.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#regularization"><i class="fa fa-check"></i><b>6.3</b> Regularization</a></li>
<li class="chapter" data-level="6.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-criteria"><i class="fa fa-check"></i><b>6.4</b> Information criteria</a><ul>
<li class="chapter" data-level="6.4.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic."><i class="fa fa-check"></i><b>6.4.1</b> DIC.</a></li>
<li class="chapter" data-level="6.4.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#waic."><i class="fa fa-check"></i><b>6.4.2</b> WAIC.</a></li>
<li class="chapter" data-level="6.4.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic-and-waic-as-estimates-of-deviance."><i class="fa fa-check"></i><b>6.4.3</b> DIC and WAIC as estimates of deviance.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#using-information-criteria"><i class="fa fa-check"></i><b>6.5</b> Using information criteria</a><ul>
<li class="chapter" data-level="6.5.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-comparison."><i class="fa fa-check"></i><b>6.5.1</b> Model comparison.</a></li>
<li class="chapter" data-level="6.5.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-averaging."><i class="fa fa-check"></i><b>6.5.2</b> Model averaging.</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#summary-bonus-r2-talk"><i class="fa fa-check"></i><b>6.6</b> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>7</b> Interactions</a><ul>
<li class="chapter" data-level="7.1" data-path="interactions.html"><a href="interactions.html#building-an-interaction."><i class="fa fa-check"></i><b>7.1</b> Building an interaction.</a><ul>
<li class="chapter" data-level="7.1.1" data-path="interactions.html"><a href="interactions.html#adding-a-dummy-variable-doesnt-work."><i class="fa fa-check"></i><b>7.1.1</b> Adding a dummy variable doesn’t work.</a></li>
<li class="chapter" data-level="7.1.2" data-path="interactions.html"><a href="interactions.html#adding-a-linear-interaction-does-work."><i class="fa fa-check"></i><b>7.1.2</b> Adding a linear interaction does work.</a></li>
<li class="chapter" data-level="7.1.3" data-path="interactions.html"><a href="interactions.html#plotting-the-interaction."><i class="fa fa-check"></i><b>7.1.3</b> Plotting the interaction.</a></li>
<li class="chapter" data-level="7.1.4" data-path="interactions.html"><a href="interactions.html#interpreting-an-interaction-estimate."><i class="fa fa-check"></i><b>7.1.4</b> Interpreting an interaction estimate.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="interactions.html"><a href="interactions.html#symmetry-of-the-linear-interaction."><i class="fa fa-check"></i><b>7.2</b> Symmetry of the linear interaction.</a><ul>
<li class="chapter" data-level="7.2.1" data-path="interactions.html"><a href="interactions.html#buridans-interaction."><i class="fa fa-check"></i><b>7.2.1</b> Buridan’s interaction.</a></li>
<li class="chapter" data-level="7.2.2" data-path="interactions.html"><a href="interactions.html#africa-depends-upon-ruggedness."><i class="fa fa-check"></i><b>7.2.2</b> Africa depends upon ruggedness.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="interactions.html"><a href="interactions.html#continuous-interactions"><i class="fa fa-check"></i><b>7.3</b> Continuous interactions</a><ul>
<li class="chapter" data-level="7.3.1" data-path="interactions.html"><a href="interactions.html#the-data.-1"><i class="fa fa-check"></i><b>7.3.1</b> The data.</a></li>
<li class="chapter" data-level="7.3.2" data-path="interactions.html"><a href="interactions.html#the-un-centered-models."><i class="fa fa-check"></i><b>7.3.2</b> The un-centered models.</a></li>
<li class="chapter" data-level="7.3.3" data-path="interactions.html"><a href="interactions.html#center-and-re-estimate."><i class="fa fa-check"></i><b>7.3.3</b> Center and re-estimate.</a></li>
<li class="chapter" data-level="7.3.4" data-path="interactions.html"><a href="interactions.html#plotting-implied-predictions."><i class="fa fa-check"></i><b>7.3.4</b> Plotting implied predictions.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="interactions.html"><a href="interactions.html#interactions-in-design-formulas"><i class="fa fa-check"></i><b>7.4</b> Interactions in design formulas</a></li>
<li class="chapter" data-level="7.5" data-path="interactions.html"><a href="interactions.html#summary-bonus-marginal_effectsconditional_effects"><i class="fa fa-check"></i><b>7.5</b> <del>Summary</del> Bonus: <code>marginal_effects()</code>/<code>conditional_effects()</code></a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>8</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#good-king-markov-and-his-island-kingdom"><i class="fa fa-check"></i><b>8.1</b> Good King Markov and His island kingdom</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-1"><i class="fa fa-check"></i><b>8.2</b> Markov chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#gibbs-sampling."><i class="fa fa-check"></i><b>8.2.1</b> Gibbs sampling.</a></li>
<li class="chapter" data-level="8.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#hamiltonian-monte-carlo."><i class="fa fa-check"></i><b>8.2.2</b> Hamiltonian Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#easy-hmc-map2stan-brm"><i class="fa fa-check"></i><b>8.3</b> Easy HMC: <del>map2stan</del> <code>brm()</code></a><ul>
<li class="chapter" data-level="8.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#preparation."><i class="fa fa-check"></i><b>8.3.1</b> Preparation.</a></li>
<li class="chapter" data-level="8.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#estimation."><i class="fa fa-check"></i><b>8.3.2</b> Estimation.</a></li>
<li class="chapter" data-level="8.3.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-again-in-parallel."><i class="fa fa-check"></i><b>8.3.3</b> Sampling again, in parallel.</a></li>
<li class="chapter" data-level="8.3.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#visualization."><i class="fa fa-check"></i><b>8.3.4</b> Visualization.</a></li>
<li class="chapter" data-level="8.3.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#using-the-samples."><i class="fa fa-check"></i><b>8.3.5</b> Using the samples.</a></li>
<li class="chapter" data-level="8.3.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#checking-the-chain."><i class="fa fa-check"></i><b>8.3.6</b> Checking the chain.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#care-and-feeding-of-your-markov-chain."><i class="fa fa-check"></i><b>8.4</b> Care and feeding of your Markov chain.</a><ul>
<li class="chapter" data-level="8.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-samples-do-you-need"><i class="fa fa-check"></i><b>8.4.1</b> How many samples do you need?</a></li>
<li class="chapter" data-level="8.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-chains-do-you-need"><i class="fa fa-check"></i><b>8.4.2</b> How many chains do you need?</a></li>
<li class="chapter" data-level="8.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#taming-a-wild-chain."><i class="fa fa-check"></i><b>8.4.3</b> Taming a wild chain.</a></li>
<li class="chapter" data-level="8.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#non-identifiable-parameters."><i class="fa fa-check"></i><b>8.4.4</b> Non-identifiable parameters.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>9</b> Big Entropy and the Generalized Linear Model</a><ul>
<li class="chapter" data-level="9.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#maximum-entropy"><i class="fa fa-check"></i><b>9.1</b> Maximum entropy</a><ul>
<li class="chapter" data-level="9.1.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#gaussian."><i class="fa fa-check"></i><b>9.1.1</b> Gaussian.</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#binomial."><i class="fa fa-check"></i><b>9.1.2</b> Binomial.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#generalized-linear-models"><i class="fa fa-check"></i><b>9.2</b> Generalized linear models</a><ul>
<li class="chapter" data-level="9.2.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#meet-the-family."><i class="fa fa-check"></i><b>9.2.1</b> Meet the family.</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions."><i class="fa fa-check"></i><b>9.2.2</b> Linking linear models to distributions.</a></li>
<li class="chapter" data-level="9.2.3" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#absolute-and-relative-differences."><i class="fa fa-check"></i><b>9.2.3</b> Absolute and relative differences.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="counting-and-classification.html"><a href="counting-and-classification.html"><i class="fa fa-check"></i><b>10</b> Counting and Classification</a><ul>
<li class="chapter" data-level="10.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#binomial-regression"><i class="fa fa-check"></i><b>10.1</b> Binomial regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#logistic-regression-prosocial-chimpanzees."><i class="fa fa-check"></i><b>10.1.1</b> Logistic regression: Prosocial chimpanzees.</a></li>
<li class="chapter" data-level="10.1.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-chimpanzees-again-condensed."><i class="fa fa-check"></i><b>10.1.2</b> Aggregated binomial: Chimpanzees again, condensed.</a></li>
<li class="chapter" data-level="10.1.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-graduate-school-admissions."><i class="fa fa-check"></i><b>10.1.3</b> Aggregated binomial: Graduate school admissions.</a></li>
<li class="chapter" data-level="10.1.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#fitting-binomial-regressions-with-glm."><i class="fa fa-check"></i><b>10.1.4</b> Fitting binomial regressions with <code>glm()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#poisson-regression"><i class="fa fa-check"></i><b>10.2</b> Poisson regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-oceanic-tool-complexity."><i class="fa fa-check"></i><b>10.2.1</b> Example: Oceanic tool complexity.</a></li>
<li class="chapter" data-level="10.2.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#mcmc-islands."><i class="fa fa-check"></i><b>10.2.2</b> MCMC islands.</a></li>
<li class="chapter" data-level="10.2.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-exposure-and-the-offset."><i class="fa fa-check"></i><b>10.2.3</b> Example: Exposure and the offset.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#other-count-regressions"><i class="fa fa-check"></i><b>10.3</b> Other count regressions</a><ul>
<li class="chapter" data-level="10.3.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#multinomial."><i class="fa fa-check"></i><b>10.3.1</b> Multinomial.</a></li>
<li class="chapter" data-level="10.3.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#geometric."><i class="fa fa-check"></i><b>10.3.2</b> Geometric.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#summary"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html"><i class="fa fa-check"></i><b>11</b> Monsters and Mixtures</a><ul>
<li class="chapter" data-level="11.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-outcomes"><i class="fa fa-check"></i><b>11.1</b> Ordered categorical outcomes</a><ul>
<li class="chapter" data-level="11.1.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-moral-intuition."><i class="fa fa-check"></i><b>11.1.1</b> Example: Moral intuition.</a></li>
<li class="chapter" data-level="11.1.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#describing-an-ordered-distribution-with-intercepts."><i class="fa fa-check"></i><b>11.1.2</b> Describing an ordered distribution with intercepts.</a></li>
<li class="chapter" data-level="11.1.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#adding-predictor-variables."><i class="fa fa-check"></i><b>11.1.3</b> Adding predictor variables.</a></li>
<li class="chapter" data-level="11.1.4" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#bonus-figure-11.3-alternative."><i class="fa fa-check"></i><b>11.1.4</b> Bonus: Figure 11.3 alternative.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#zero-inflated-outcomes"><i class="fa fa-check"></i><b>11.2</b> Zero-inflated outcomes</a><ul>
<li class="chapter" data-level="11.2.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-zero-inflated-poisson."><i class="fa fa-check"></i><b>11.2.1</b> Example: Zero-inflated Poisson.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersed-outcomes"><i class="fa fa-check"></i><b>11.3</b> Over-dispersed outcomes</a><ul>
<li class="chapter" data-level="11.3.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#beta-binomial."><i class="fa fa-check"></i><b>11.3.1</b> Beta-binomial.</a></li>
<li class="chapter" data-level="11.3.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#negative-binomial-or-gamma-poisson."><i class="fa fa-check"></i><b>11.3.2</b> Negative-binomial or gamma-Poisson.</a></li>
<li class="chapter" data-level="11.3.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersion-entropy-and-information-criteria."><i class="fa fa-check"></i><b>11.3.3</b> Over-dispersion, entropy, and information criteria.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>12</b> Multilevel Models</a><ul>
<li class="chapter" data-level="12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-multilevel-tadpoles"><i class="fa fa-check"></i><b>12.1</b> Example: Multilevel tadpoles</a></li>
<li class="chapter" data-level="12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>12.2</b> Varying effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multilevel-models.html"><a href="multilevel-models.html#the-model.-1"><i class="fa fa-check"></i><b>12.2.1</b> The model.</a></li>
<li class="chapter" data-level="12.2.2" data-path="multilevel-models.html"><a href="multilevel-models.html#assign-values-to-the-parameters."><i class="fa fa-check"></i><b>12.2.2</b> Assign values to the parameters.</a></li>
<li class="chapter" data-level="12.2.3" data-path="multilevel-models.html"><a href="multilevel-models.html#sumulate-survivors."><i class="fa fa-check"></i><b>12.2.3</b> Sumulate survivors.</a></li>
<li class="chapter" data-level="12.2.4" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-no-pooling-estimates."><i class="fa fa-check"></i><b>12.2.4</b> Compute the no-pooling estimates.</a></li>
<li class="chapter" data-level="12.2.5" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-partial-pooling-estimates."><i class="fa fa-check"></i><b>12.2.5</b> Compute the partial-pooling estimates.</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multilevel-models.html"><a href="multilevel-models.html#more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>12.3</b> More than one type of cluster</a><ul>
<li class="chapter" data-level="12.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-chimpanzees."><i class="fa fa-check"></i><b>12.3.1</b> Multilevel chimpanzees.</a></li>
<li class="chapter" data-level="12.3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#two-types-of-cluster."><i class="fa fa-check"></i><b>12.3.2</b> Two types of cluster.</a></li>
<li class="chapter" data-level="12.3.3" data-path="multilevel-models.html"><a href="multilevel-models.html#even-more-clusters."><i class="fa fa-check"></i><b>12.3.3</b> Even more clusters.</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-posterior-predictions"><i class="fa fa-check"></i><b>12.4</b> Multilevel posterior predictions</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-same-clusters."><i class="fa fa-check"></i><b>12.4.1</b> Posterior prediction for same clusters.</a></li>
<li class="chapter" data-level="12.4.2" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-new-clusters."><i class="fa fa-check"></i><b>12.4.2</b> Posterior prediction for new clusters.</a></li>
<li class="chapter" data-level="12.4.3" data-path="multilevel-models.html"><a href="multilevel-models.html#focus-and-multilevel-prediction."><i class="fa fa-check"></i><b>12.4.3</b> Focus and multilevel prediction.</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="multilevel-models.html"><a href="multilevel-models.html#summary-bonus-put-your-random-effects-to-work"><i class="fa fa-check"></i><b>12.5</b> <del>Summary</del> Bonus: Put your random effects to work</a><ul>
<li class="chapter" data-level="12.5.1" data-path="multilevel-models.html"><a href="multilevel-models.html#intercepts-only-models-with-one-or-two-grouping-variables."><i class="fa fa-check"></i><b>12.5.1</b> Intercepts-only models with one or two grouping variables.</a></li>
<li class="chapter" data-level="12.5.2" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsposterior_samples."><i class="fa fa-check"></i><b>12.5.2</b> <code>brms::posterior_samples()</code>.</a></li>
<li class="chapter" data-level="12.5.3" data-path="multilevel-models.html"><a href="multilevel-models.html#brmscoef."><i class="fa fa-check"></i><b>12.5.3</b> <code>brms::coef()</code>.</a></li>
<li class="chapter" data-level="12.5.4" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsfitted."><i class="fa fa-check"></i><b>12.5.4</b> <code>brms::fitted()</code>.</a></li>
<li class="chapter" data-level="12.5.5" data-path="multilevel-models.html"><a href="multilevel-models.html#tidybayesspread_draws."><i class="fa fa-check"></i><b>12.5.5</b> <code>tidybayes::spread_draws()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html"><i class="fa fa-check"></i><b>13</b> Adventures in Covariance</a><ul>
<li class="chapter" data-level="13.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-slopes-by-construction"><i class="fa fa-check"></i><b>13.1</b> Varying slopes by construction</a><ul>
<li class="chapter" data-level="13.1.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-the-population."><i class="fa fa-check"></i><b>13.1.1</b> Simulate the population.</a></li>
<li class="chapter" data-level="13.1.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-observations."><i class="fa fa-check"></i><b>13.1.2</b> Simulate observations.</a></li>
<li class="chapter" data-level="13.1.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#the-varying-slopes-model."><i class="fa fa-check"></i><b>13.1.3</b> The varying slopes model.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-admission-decisions-and-gender"><i class="fa fa-check"></i><b>13.2</b> Example: Admission decisions and gender</a><ul>
<li class="chapter" data-level="13.2.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-intercepts."><i class="fa fa-check"></i><b>13.2.1</b> Varying intercepts.</a></li>
<li class="chapter" data-level="13.2.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-effects-of-being-male."><i class="fa fa-check"></i><b>13.2.2</b> Varying effects of being <code>male</code>.</a></li>
<li class="chapter" data-level="13.2.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#shrinkage."><i class="fa fa-check"></i><b>13.2.3</b> Shrinkage.</a></li>
<li class="chapter" data-level="13.2.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#model-comparison.-1"><i class="fa fa-check"></i><b>13.2.4</b> Model comparison.</a></li>
<li class="chapter" data-level="13.2.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#more-slopes."><i class="fa fa-check"></i><b>13.2.5</b> More slopes.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-cross-classified-chimpanzees-with-varying-slopes"><i class="fa fa-check"></i><b>13.3</b> Example: Cross-classified <code>chimpanzees</code> with varying slopes</a></li>
<li class="chapter" data-level="13.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#continuous-categories-and-the-gaussian-process"><i class="fa fa-check"></i><b>13.4</b> Continuous categories and the Gaussian process</a><ul>
<li class="chapter" data-level="13.4.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-spatial-autocorrelation-in-oceanic-tools."><i class="fa fa-check"></i><b>13.4.1</b> Example: Spatial autocorrelation in Oceanic tools.</a></li>
<li class="chapter" data-level="13.4.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#other-kinds-of-distance."><i class="fa fa-check"></i><b>13.4.2</b> Other kinds of “distance”.</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#summary-bonus-another-berkley-admissions-data-like-example."><i class="fa fa-check"></i><b>13.5</b> <del>Summary</del> Bonus: Another Berkley-admissions-data-like example.</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html"><i class="fa fa-check"></i><b>14</b> Missing Data and Other Opportunities</a><ul>
<li class="chapter" data-level="14.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-error"><i class="fa fa-check"></i><b>14.1</b> Measurement error</a><ul>
<li class="chapter" data-level="14.1.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-the-outcome."><i class="fa fa-check"></i><b>14.1.1</b> Error on the outcome.</a></li>
<li class="chapter" data-level="14.1.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-both-outcome-and-predictor."><i class="fa fa-check"></i><b>14.1.2</b> Error on both outcome and predictor.</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#missing-data"><i class="fa fa-check"></i><b>14.2</b> Missing data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#imputing-neocortex"><i class="fa fa-check"></i><b>14.2.1</b> Imputing <code>neocortex</code></a></li>
<li class="chapter" data-level="14.2.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#improving-the-imputation-model"><i class="fa fa-check"></i><b>14.2.2</b> Improving the imputation model</a></li>
<li class="chapter" data-level="14.2.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#bonus-mi-can-replace-me"><i class="fa fa-check"></i><b>14.2.3</b> Bonus: <code>mi()</code> can replace <code>me()</code></a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#summary-bonus-meta-analysis"><i class="fa fa-check"></i><b>14.3</b> <del>Summary</del> Bonus: Meta-analysis</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html"><i class="fa fa-check"></i><b>15</b> <del>Horoscopes</del> Insights</a><ul>
<li class="chapter" data-level="15.1" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-r-notebooks"><i class="fa fa-check"></i><b>15.1</b> Use R Notebooks</a></li>
<li class="chapter" data-level="15.2" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#save-your-model-fits"><i class="fa fa-check"></i><b>15.2</b> Save your model fits</a></li>
<li class="chapter" data-level="15.3" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#build-your-models-slowly"><i class="fa fa-check"></i><b>15.3</b> Build your models slowly</a></li>
<li class="chapter" data-level="15.4" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#look-at-your-data"><i class="fa fa-check"></i><b>15.4</b> Look at your data</a></li>
<li class="chapter" data-level="15.5" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-the-0-intercept-syntax"><i class="fa fa-check"></i><b>15.5</b> Use the <code>0 + Intercept</code> syntax</a></li>
<li class="chapter" data-level="15.6" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-workflow"><i class="fa fa-check"></i><b>15.6</b> Annotate your workflow</a></li>
<li class="chapter" data-level="15.7" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-code"><i class="fa fa-check"></i><b>15.7</b> Annotate your code</a></li>
<li class="chapter" data-level="15.8" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#break-up-your-workflow"><i class="fa fa-check"></i><b>15.8</b> Break up your workflow</a></li>
<li class="chapter" data-level="15.9" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#code-in-public"><i class="fa fa-check"></i><b>15.9</b> Code in public</a></li>
<li class="chapter" data-level="15.10" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#read-gelmans-blog"><i class="fa fa-check"></i><b>15.10</b> Read Gelman’s blog</a></li>
<li class="chapter" data-level="15.11" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#check-out-other-social-media-too"><i class="fa fa-check"></i><b>15.11</b> Check out other social media, too</a></li>
<li class="chapter" data-level="15.12" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#parting-wisdom"><i class="fa fa-check"></i><b>15.12</b> Parting wisdom</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical rethinking</em> with brms, ggplot2, and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="big-entropy-and-the-generalized-linear-model" class="section level1">
<h1><span class="header-section-number">9</span> Big Entropy and the Generalized Linear Model</h1>
<blockquote>
<p>Statistical models force many choices upon us. Some of these choices are distributions that represent uncertainty. We must choose, for each parameter, a prior distribution. And we must choose a likelihood function, which serves as a distribution of data. There are conventional choices, such as wide Gaussian priors and the Gaussian likelihood of linear regression. These conventional choices work unreasonably well in many circumstances. But very often the conventional choices are not the best choices. Inference can be more powerful when we use all of the information, and doing so usually requires going beyond convention.</p>
<p>To go beyond convention, it helps to have some principles to guide choice. When an engineer wants to make an unconventional bridge, engineering principles help guide choice. When a researcher wants to build an unconventional model, entropy provides one useful principle to guide choice of probability distributions: Bet on the distribution with the biggest entropy. <span class="citation">(McElreath, <a href="#ref-mcelreathStatisticalRethinkingBayesian2015" role="doc-biblioref">2015</a>, p. 267)</span></p>
</blockquote>
<div id="maximum-entropy" class="section level2">
<h2><span class="header-section-number">9.1</span> Maximum entropy</h2>
<blockquote>
<p>In <a href="overfitting-regularization-and-information-criteria.html#information-and-uncertainty.">Chapter 6</a>, you met the basics of information theory. In brief, we seek a measure of uncertainty that satisfies three criteria: (1) the measure should be continuous; (2) it should increase as the number of possible events increases; and (3) it should be additive. The resulting unique measure of the uncertainty of a probability distribution <span class="math inline">\(p\)</span> with probabilities <span class="math inline">\(p_i\)</span> for each possible event <span class="math inline">\(i\)</span> turns out to be just the average log-probability:</p>
<p><span class="math display">\[H(p) = - \sum_i p_i \log p_i\]</span></p>
<p>This function is known as <em>information entropy</em>.</p>
<p>The principle of maximum entropy applies this measure of uncertainty to the problem of choosing among probability distributions. Perhaps the simplest way to sate the maximum entropy principle is:</p>
<blockquote>
<p>The distribution that can happen the most ways is also the distribution with the biggest information entropy. The distribution with the biggest entropy is the most conservative distribution that obeys its constraints.</p>
</blockquote>
<p>There’s nothing intuitive about this idea, so if it seems weird, you are normal. (pp. 268–269, <em>emphasis</em> in the original)</p>
</blockquote>
<p>Let’s execute the code for the pebbles-in-buckets example.</p>
<div class="sourceCode" id="cb837"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb837-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb837-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-2"></a></span>
<span id="cb837-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-3"></a>d &lt;-</span>
<span id="cb837-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-4"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">a =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb837-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-5"></a>         <span class="dt">b =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb837-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-6"></a>         <span class="dt">c =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">2</span>, <span class="dv">0</span>),</span>
<span id="cb837-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-7"></a>         <span class="dt">d =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>),</span>
<span id="cb837-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-8"></a>         <span class="dt">e =</span> <span class="dv">2</span>) </span>
<span id="cb837-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-9"></a></span>
<span id="cb837-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-10"></a><span class="co"># this is our analogue to McElreath&#39;s `lapply()` code</span></span>
<span id="cb837-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-11"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb837-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-12"></a><span class="st">  </span><span class="kw">mutate_all</span>(<span class="op">~</span><span class="st"> </span>. <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(.)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb837-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-13"></a><span class="st">  </span><span class="co"># the next few lines constitute our analogue to his `sapply()` code</span></span>
<span id="cb837-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-14"></a><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb837-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-15"></a><span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb837-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb837-16"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">h =</span> <span class="op">-</span><span class="kw">sum</span>(<span class="kw">ifelse</span>(value <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">0</span>, value <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(value))))</span></code></pre></div>
<pre><code>## # A tibble: 5 x 2
##   key       h
##   &lt;chr&gt; &lt;dbl&gt;
## 1 a     0    
## 2 b     0.639
## 3 c     0.950
## 4 d     1.47 
## 5 e     1.61</code></pre>
<p>For more on the formula syntax we used within <code>mutate_all()</code>, you might check out <a href="https://dplyr.tidyverse.org/reference/mutate_all.html">this</a> or <a href="https://purrr.tidyverse.org/reference/map.html">this</a>.</p>
<p>Anyway, we’re almost ready to plot, which brings us to color. For the plots in this chapter, we’ll be taking our color palettes from the <a href="https://github.com/ewenme/ghibli">ghibli package</a> <span class="citation">(Henderson, <a href="#ref-R-ghibli" role="doc-biblioref">2020</a>)</span>, which provides palettes based on scenes from anime films by the Studio Ghibli.</p>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb839-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb839-1"></a><span class="co"># install.packages(&quot;ghibli&quot;, dependencies = T)</span></span>
<span id="cb839-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb839-2"></a><span class="kw">library</span>(ghibli)</span></code></pre></div>
<p>The main function is <code>ghibli_palette()</code> which you can use to both preview the palettes before using them and also index in order to use specific colors. For example, we’ll play with “MarnieMedium1”, first.</p>
<div class="sourceCode" id="cb840"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb840-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb840-1"></a><span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium1&quot;</span>)</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-4-1.png" width="480" /></p>
<div class="sourceCode" id="cb841"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb841-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb841-1"></a><span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium1&quot;</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>]</span></code></pre></div>
<pre><code>## [1] &quot;#28231D&quot; &quot;#5E2D30&quot; &quot;#008E90&quot; &quot;#1C77A3&quot; &quot;#C5A387&quot; &quot;#67B8D6&quot; &quot;#E9D097&quot;</code></pre>
<p>Now we’re ready to plot five of the six panels of Figure 9.1.</p>
<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb843-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb843-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">bucket =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb843-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-3"></a><span class="st">  </span><span class="kw">gather</span>(letter, pebbles, <span class="op">-</span><span class="st"> </span>bucket) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb843-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-4"></a><span class="st">  </span></span>
<span id="cb843-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> bucket, <span class="dt">y =</span> pebbles)) <span class="op">+</span></span>
<span id="cb843-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-6"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">width =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">5</span>, <span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium1&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span></span>
<span id="cb843-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-7"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">y =</span> pebbles <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">label =</span> pebbles)) <span class="op">+</span></span>
<span id="cb843-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-8"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> <span class="kw">tibble</span>(</span>
<span id="cb843-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-9"></a>    <span class="dt">letter  =</span> letters[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>],</span>
<span id="cb843-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-10"></a>    <span class="dt">bucket  =</span> <span class="fl">5.5</span>,</span>
<span id="cb843-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-11"></a>    <span class="dt">pebbles =</span> <span class="fl">10.5</span>,</span>
<span id="cb843-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-12"></a>    <span class="dt">label   =</span> <span class="kw">str_c</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">90</span>, <span class="dv">1260</span>, <span class="dv">37800</span>, <span class="dv">113400</span>), </span>
<span id="cb843-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-13"></a>                    <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot; way&quot;</span>, <span class="st">&quot; ways&quot;</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)))),</span>
<span id="cb843-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-14"></a>    <span class="kw">aes</span>(<span class="dt">label =</span> label), </span>
<span id="cb843-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-15"></a>    <span class="dt">hjust =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb843-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-16"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">10</span>), <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">12</span>)) <span class="op">+</span></span>
<span id="cb843-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-17"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb843-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-18"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium1&quot;</span>)[<span class="dv">6</span>]),</span>
<span id="cb843-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-19"></a>        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium1&quot;</span>)[<span class="dv">7</span>])) <span class="op">+</span></span>
<span id="cb843-20"><a href="big-entropy-and-the-generalized-linear-model.html#cb843-20"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>letter, <span class="dt">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-5-1.png" width="576" /></p>
<p>We might plot our version of the final panel like so.</p>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb844-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb844-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-2"></a><span class="st">  </span><span class="co"># the next four lines are the same from above</span></span>
<span id="cb844-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-3"></a><span class="st">  </span><span class="kw">mutate_all</span>(<span class="op">~</span><span class="st"> </span>. <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(.)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb844-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-4"></a><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb844-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-5"></a><span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb844-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-6"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">h =</span> <span class="op">-</span><span class="kw">sum</span>(<span class="kw">ifelse</span>(value <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">0</span>, value <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(value)))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb844-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-7"></a><span class="st">  </span><span class="co"># here&#39;s the R code 9.4 stuff</span></span>
<span id="cb844-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_ways   =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">90</span>, <span class="dv">1260</span>, <span class="dv">37800</span>, <span class="dv">113400</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb844-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-9"></a><span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb844-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_ways =</span> <span class="kw">log</span>(n_ways) <span class="op">/</span><span class="st"> </span><span class="dv">10</span>,</span>
<span id="cb844-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-11"></a>         <span class="dt">text_y   =</span> <span class="kw">ifelse</span>(key <span class="op">&lt;</span><span class="st"> &quot;c&quot;</span>, h <span class="op">+</span><span class="st"> </span><span class="fl">.15</span>, h <span class="op">-</span><span class="st"> </span><span class="fl">.15</span>)) <span class="op">%&gt;%</span></span>
<span id="cb844-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-12"></a><span class="st">  </span></span>
<span id="cb844-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-13"></a><span class="st">  </span><span class="co"># plot</span></span>
<span id="cb844-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-14"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> log_ways, <span class="dt">y =</span> h)) <span class="op">+</span></span>
<span id="cb844-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-15"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="fl">1.37</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb844-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-16"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">2.5</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium1&quot;</span>)[<span class="dv">7</span>]) <span class="op">+</span></span>
<span id="cb844-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-17"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">y =</span> text_y, <span class="dt">label =</span> key)) <span class="op">+</span></span>
<span id="cb844-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-18"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log(ways) per pebble&quot;</span>,</span>
<span id="cb844-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-19"></a>       <span class="dt">y =</span> <span class="st">&quot;entropy&quot;</span>) <span class="op">+</span></span>
<span id="cb844-20"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-20"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb844-21"><a href="big-entropy-and-the-generalized-linear-model.html#cb844-21"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium1&quot;</span>)[<span class="dv">6</span>]))</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-6-1.png" width="288" /></p>
<p>“The distribution that can happen the greatest number of ways is the most plausible distribution. Call this distribution the maximum entropy distribution” (p. 271). Among the pebbles, the maximum entropy distribution was <code>e</code> (i.e., the uniform).</p>
<div id="rethinking-what-good-is-intuition" class="section level4">
<h4><span class="header-section-number">9.1.0.1</span> Rethinking: What good is intuition?</h4>
<p>“Like many aspects of information theory, maximum entropy is not very intuitive. But note that intuition is just a guide to developing methods. When a method works, it hardly matters whether our intuition agrees” (p. 271).</p>
</div>
<div id="gaussian." class="section level3">
<h3><span class="header-section-number">9.1.1</span> Gaussian.</h3>
<p>Behold the probability density for the generalized normal distribution:</p>
<p><span class="math display">\[\text{Pr}(y | \mu, \alpha, \beta) = \frac{\beta}{2 \alpha \Gamma \left (\frac{1}{\beta} \right )} e ^ {- \left (\frac{|y - \mu|}{\alpha} \right ) ^ {\beta}},\]</span></p>
<p>where <span class="math inline">\(\alpha =\)</span> the scale, <span class="math inline">\(\beta =\)</span> the shape, <span class="math inline">\(\mu =\)</span> the location, and <span class="math inline">\(\Gamma =\)</span> the <a href="https://en.wikipedia.org/wiki/Gamma_function">gamma function</a>. If you read closely in the text, you’ll discover that the densities in the right panel of Figure 9.2 were all created with the constraint <span class="math inline">\(\sigma^2 = 1\)</span>. But <span class="math inline">\(\sigma^2 \neq \alpha\)</span> and there’s no <span class="math inline">\(\sigma\)</span> in the equations in the text. However, it appears the variance for the generalized normal distribution follows the form</p>
<p><span class="math display">\[\sigma^2 = \frac{\alpha^2 \Gamma (3/\beta)}{\Gamma (1/\beta)}.\]</span></p>
<p>So if you do the algebra, you’ll see that you can compute <span class="math inline">\(\alpha\)</span> for a given <span class="math inline">\(\sigma^2\)</span> and <span class="math inline">\(\beta\)</span> with the equation</p>
<p><span class="math display">\[\alpha = \sqrt{ \frac{\sigma^2 \Gamma (1/\beta)}{\Gamma (3/\beta)} }.\]</span></p>
<p>I got the formula from <a href="https://en.wikipedia.org/wiki/Generalized_normal_distribution">Wikipedia.com</a>. Don’t judge. We can wrap that formula in a custom function, <code>alpha_per_beta()</code>, use it to solve for the desired <span class="math inline">\(\beta\)</span> values, and plot. But one more thing: McElreath didn’t tell us exactly which <span class="math inline">\(\beta\)</span> values the left panel of Figure 9.2 was based on. So the plot below is my best guess.</p>
<div class="sourceCode" id="cb845"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb845-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-1"></a>alpha_per_beta &lt;-<span class="st"> </span><span class="cf">function</span>(beta, <span class="dt">variance =</span> <span class="dv">1</span>) {</span>
<span id="cb845-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-2"></a>  <span class="kw">sqrt</span>((variance <span class="op">*</span><span class="st"> </span><span class="kw">gamma</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>beta)) <span class="op">/</span><span class="st"> </span><span class="kw">gamma</span>(<span class="dv">3</span> <span class="op">/</span><span class="st"> </span>beta))</span>
<span id="cb845-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-3"></a>}</span>
<span id="cb845-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-4"></a></span>
<span id="cb845-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-5"></a><span class="kw">tibble</span>(<span class="dt">mu   =</span> <span class="dv">0</span>,</span>
<span id="cb845-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-6"></a>       <span class="co"># I arrived at these values by trial and error</span></span>
<span id="cb845-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-7"></a>       <span class="dt">beta =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">1.5</span>, <span class="dv">2</span>, <span class="dv">4</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb845-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">alpha =</span> <span class="kw">alpha_per_beta</span>(beta)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb845-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-9"></a><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(mu, beta, alpha), </span>
<span id="cb845-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-10"></a>         <span class="dt">value =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-5</span>, <span class="dt">to =</span> <span class="dv">5</span>, <span class="dt">by =</span> <span class="fl">.01</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb845-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-11"></a><span class="st">  </span><span class="co"># behold the formula for the generalized normal distribution in code!</span></span>
<span id="cb845-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-12"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> (beta <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>alpha <span class="op">*</span><span class="st"> </span><span class="kw">gamma</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>beta))) <span class="op">*</span><span class="st"> </span></span>
<span id="cb845-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-13"></a><span class="st">           </span><span class="kw">exp</span>(<span class="dv">1</span>) <span class="op">^</span><span class="st"> </span>(<span class="op">-</span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">abs</span>(value <span class="op">-</span><span class="st"> </span>mu) <span class="op">/</span><span class="st"> </span>alpha) <span class="op">^</span><span class="st"> </span>beta)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb845-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-14"></a><span class="st">  </span></span>
<span id="cb845-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-15"></a><span class="st">  </span><span class="co"># plot</span></span>
<span id="cb845-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-16"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value, <span class="dt">y =</span> density, <span class="dt">group =</span> beta)) <span class="op">+</span></span>
<span id="cb845-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-17"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> beta <span class="op">==</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">size  =</span> beta <span class="op">==</span><span class="st"> </span><span class="dv">2</span>)) <span class="op">+</span></span>
<span id="cb845-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-18"></a><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium2&quot;</span>)[<span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>)])) <span class="op">+</span></span>
<span id="cb845-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-19"></a><span class="st">  </span><span class="kw">scale_size_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="fl">1.25</span>)) <span class="op">+</span></span>
<span id="cb845-20"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-20"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Guess which color denotes the Gaussian.&quot;</span>) <span class="op">+</span></span>
<span id="cb845-21"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-21"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>)) <span class="op">+</span></span>
<span id="cb845-22"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-22"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb845-23"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-23"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb845-24"><a href="big-entropy-and-the-generalized-linear-model.html#cb845-24"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium2&quot;</span>)[<span class="dv">7</span>]))</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-7-1.png" width="336" /></p>
<p>Here’s Figure 9.2’s right panel.</p>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-1"></a><span class="kw">tibble</span>(<span class="dt">mu   =</span> <span class="dv">0</span>,</span>
<span id="cb846-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-2"></a>       <span class="co"># this time we need a more densely-packed sequence of `beta` values</span></span>
<span id="cb846-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-3"></a>       <span class="dt">beta =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1</span>, <span class="dt">to =</span> <span class="dv">4</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb846-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">alpha =</span> <span class="kw">alpha_per_beta</span>(beta)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb846-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-5"></a><span class="st">  </span><span class="kw">expand</span>(<span class="kw">nesting</span>(mu, beta, alpha), </span>
<span id="cb846-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-6"></a>         <span class="dt">value =</span> <span class="dv">-8</span><span class="op">:</span><span class="dv">8</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb846-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> (beta <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>alpha <span class="op">*</span><span class="st"> </span><span class="kw">gamma</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>beta))) <span class="op">*</span><span class="st"> </span></span>
<span id="cb846-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-8"></a><span class="st">           </span><span class="kw">exp</span>(<span class="dv">1</span>) <span class="op">^</span><span class="st"> </span>(<span class="op">-</span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">abs</span>(value <span class="op">-</span><span class="st"> </span>mu) <span class="op">/</span><span class="st"> </span>alpha) <span class="op">^</span><span class="st"> </span>beta)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb846-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-9"></a><span class="st">  </span><span class="kw">group_by</span>(beta) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb846-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-10"></a><span class="st">  </span><span class="co"># this is just an abbreviated version of the formula we used in our first code block</span></span>
<span id="cb846-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-11"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">entropy =</span> <span class="op">-</span><span class="kw">sum</span>(density <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(density))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb846-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-12"></a><span class="st">  </span></span>
<span id="cb846-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-13"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> beta, <span class="dt">y =</span> entropy)) <span class="op">+</span></span>
<span id="cb846-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-14"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb846-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-15"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium2&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span></span>
<span id="cb846-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-16"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(beta<span class="op">*</span><span class="st">&quot; (i.e., shape)&quot;</span>)) <span class="op">+</span></span>
<span id="cb846-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-17"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.34</span>, <span class="fl">1.42</span>)) <span class="op">+</span></span>
<span id="cb846-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-18"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb846-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb846-19"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MarnieMedium2&quot;</span>)[<span class="dv">7</span>]))</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-8-1.png" width="336" /></p>
<p>If you look closely, you’ll see our version doesn’t quite match up with McElreath’s. Over <span class="math inline">\(x\)</span>-axis values of 2 to 4, they match up pretty well. But as you go from 2 to 1, you’ll see our line drops off more steeply than his did. [And no, <code>coord_cartesian()</code> isn’t the problem.] If you can figure out why our numbers diverged, <a href="https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/issues">please share the answer</a>.</p>
<p>But getting back on track:</p>
<blockquote>
<p>The take-home lesson from all of this is that, if all we are willing to assume about a collection of measurements is that they have a finite variance, then the Gaussian distribution represents the most conservative probability distribution to assign to those measurements. But very often we are comfortable assuming something more. And in those cases, provided our assumptions are good ones, the principle of maximum entropy leads to distributions other than the Gaussian. (p. 274)</p>
</blockquote>
</div>
<div id="binomial." class="section level3">
<h3><span class="header-section-number">9.1.2</span> Binomial.</h3>
<p>The binomial likelihood entails</p>
<blockquote>
<p>counting the numbers of ways that a given observation could arise, according to assumptions… If only two things can happen (blue or white marble, for example), and there’s a constant chance <span class="math inline">\(p\)</span> of each across <span class="math inline">\(n\)</span> trials, then the probability of observing <span class="math inline">\(y\)</span> events of type 1 and <span class="math inline">\(n - y\)</span> events of type 2 is:</p>
<p><span class="math display">\[\text{Pr}(y | n, p) = \frac{n!}{y! (n - y)!} p^y (1 - p)^{n - y}\]</span></p>
<p>It may help to note that the fraction with the factorials is just saying how many different ordered sequences of <span class="math inline">\(n\)</span> outcomes have a count of <span class="math inline">\(y\)</span>. (p. 275)</p>
</blockquote>
<p>For me, that last sentence made more sense when I walked it out in an example. To do so, let’s wrap that fraction of factorials into a function.</p>
<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb847-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb847-1"></a>count_ways &lt;-<span class="st"> </span><span class="cf">function</span>(n, y) {</span>
<span id="cb847-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb847-2"></a>  <span class="co"># n = the total number of trials (i.e., the number of rows in your vector)</span></span>
<span id="cb847-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb847-3"></a>  <span class="co"># y = the total number of 1s (i.e., successes) in your vector</span></span>
<span id="cb847-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb847-4"></a>  (<span class="kw">factorial</span>(n) <span class="op">/</span><span class="st"> </span>(<span class="kw">factorial</span>(y) <span class="op">*</span><span class="st"> </span><span class="kw">factorial</span>(n <span class="op">-</span><span class="st"> </span>y)))</span>
<span id="cb847-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb847-5"></a>}</span></code></pre></div>
<p>Now consider three sequences:</p>
<ul>
<li>0, 0, 0, 0 (i.e., <span class="math inline">\(n = 4\)</span> and <span class="math inline">\(y = 0\)</span>)</li>
<li>1, 0, 0, 0 (i.e., <span class="math inline">\(n = 4\)</span> and <span class="math inline">\(y = 1\)</span>)</li>
<li>1, 1, 0, 0 (i.e., <span class="math inline">\(n = 4\)</span> and <span class="math inline">\(y = 2\)</span>)</li>
</ul>
<p>We can organize that information in a little tibble and then demo our <code>count_ways()</code> function.</p>
<div class="sourceCode" id="cb848"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb848-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb848-1"></a><span class="kw">tibble</span>(<span class="dt">sequence =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>,</span>
<span id="cb848-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb848-2"></a>       <span class="dt">n        =</span> <span class="dv">4</span>,</span>
<span id="cb848-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb848-3"></a>       <span class="dt">y        =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb848-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb848-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_ways =</span> <span class="kw">count_ways</span>(<span class="dt">n =</span> n, <span class="dt">y =</span> y))</span></code></pre></div>
<pre><code>## # A tibble: 3 x 4
##   sequence     n     y n_ways
##      &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1        1     4     0      1
## 2        2     4     1      4
## 3        3     4     2      6</code></pre>
<p>Here’s the pre-Figure 9.3 data McElreath presented at the bottom of page 275.</p>
<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb850-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-1"></a>(</span>
<span id="cb850-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-2"></a>  d &lt;-</span>
<span id="cb850-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-3"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">distribution =</span> letters[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>],</span>
<span id="cb850-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-4"></a>         <span class="dt">ww =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dv">2</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">8</span>),</span>
<span id="cb850-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-5"></a>         <span class="dt">bw =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">2</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">4</span><span class="op">/</span><span class="dv">8</span>),</span>
<span id="cb850-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-6"></a>         <span class="dt">wb =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">2</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">2</span><span class="op">/</span><span class="dv">8</span>),</span>
<span id="cb850-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-7"></a>         <span class="dt">bb =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">4</span>, <span class="dv">2</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">6</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">8</span>))</span>
<span id="cb850-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb850-8"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   distribution    ww    bw    wb    bb
##   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 a            0.25  0.25  0.25  0.25 
## 2 b            0.333 0.167 0.167 0.333
## 3 c            0.167 0.333 0.333 0.167
## 4 d            0.125 0.5   0.25  0.125</code></pre>
<p>Those data take just a tiny bit of wrangling before they’re ready to plot in our version of Figure 9.3.</p>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb852-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb852-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-2"></a><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>distribution) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb852-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;ww&quot;</span>, <span class="st">&quot;bw&quot;</span>, <span class="st">&quot;wb&quot;</span>, <span class="st">&quot;bb&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb852-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-4"></a><span class="st">  </span></span>
<span id="cb852-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> key, <span class="dt">y =</span> value, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb852-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-6"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;PonyoMedium&quot;</span>)[<span class="dv">4</span>]) <span class="op">+</span></span>
<span id="cb852-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-7"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;PonyoMedium&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span></span>
<span id="cb852-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-8"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb852-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-9"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb852-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-10"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb852-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-11"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb852-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-12"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;PonyoMedium&quot;</span>)[<span class="dv">2</span>]),</span>
<span id="cb852-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-13"></a>        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;PonyoMedium&quot;</span>)[<span class="dv">6</span>])) <span class="op">+</span></span>
<span id="cb852-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb852-14"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>distribution)</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-12-1.png" width="384" /></p>
<p>If we go step by step, we might count the expected value for each <code>distribution</code> like follows.</p>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb853-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb853-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb853-2"></a><span class="st">  </span><span class="kw">gather</span>(sequence, probability, <span class="op">-</span>distribution) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb853-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb853-3"></a><span class="st">  </span><span class="co"># `str_count()` will count the number of times &quot;b&quot; occurs within a given row of `sequence`</span></span>
<span id="cb853-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb853-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_b =</span> <span class="kw">str_count</span>(sequence, <span class="st">&quot;b&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb853-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb853-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">product =</span> probability <span class="op">*</span><span class="st"> </span>n_b) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb853-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb853-6"></a><span class="st">  </span><span class="kw">group_by</span>(distribution) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb853-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb853-7"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">expected_value =</span> <span class="kw">sum</span>(product))</span></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   distribution expected_value
##   &lt;chr&gt;                 &lt;dbl&gt;
## 1 a                         1
## 2 b                         1
## 3 c                         1
## 4 d                         1</code></pre>
<p>We can use the same <code>gather()</code> and <code>group_by()</code> strategies on the way to computing the entropies.</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb855-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb855-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb855-2"></a><span class="st">  </span><span class="kw">gather</span>(sequence, probability, <span class="op">-</span>distribution) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb855-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb855-3"></a><span class="st">  </span><span class="kw">group_by</span>(distribution) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb855-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb855-4"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">entropy =</span> <span class="op">-</span><span class="kw">sum</span>(probability <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(probability)))</span></code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   distribution entropy
##   &lt;chr&gt;          &lt;dbl&gt;
## 1 a               1.39
## 2 b               1.33
## 3 c               1.33
## 4 d               1.21</code></pre>
<p>Like in the text, <code>distribution == "a"</code> had the largest <code>entropy</code> of the four. In the next example, the <span class="math inline">\(\text{expected value} = 1.4\)</span> and <span class="math inline">\(p = .7\)</span>.</p>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb857-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-1"></a>p &lt;-<span class="st"> </span><span class="fl">0.7</span></span>
<span id="cb857-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-2"></a></span>
<span id="cb857-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-3"></a>(</span>
<span id="cb857-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-4"></a>  a &lt;-<span class="st"> </span></span>
<span id="cb857-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-5"></a><span class="st">  </span><span class="kw">c</span>((<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p)<span class="op">^</span><span class="dv">2</span>, </span>
<span id="cb857-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-6"></a>    p <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p), </span>
<span id="cb857-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-7"></a>    (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p) <span class="op">*</span><span class="st"> </span>p, </span>
<span id="cb857-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-8"></a>    p<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb857-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb857-9"></a>)</span></code></pre></div>
<pre><code>## [1] 0.09 0.21 0.21 0.49</code></pre>
<p>Here’s the entropy for our distribution <code>a</code>.</p>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb859-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb859-1"></a><span class="op">-</span><span class="kw">sum</span>(a <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(a))</span></code></pre></div>
<pre><code>## [1] 1.221729</code></pre>
<p>I’m going to alter McElreath’s simulation function from R code block 9.9 to take a seed argument. In addition, I altered the names of the objects within the function and changed the output to a tibble that will also include the conditions “ww”, “bw”, “wb”, and “bb”.</p>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb861-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-1"></a>sim_p &lt;-<span class="st"> </span><span class="cf">function</span>(seed, <span class="dt">g =</span> <span class="fl">1.4</span>) {</span>
<span id="cb861-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-2"></a>  </span>
<span id="cb861-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-3"></a>  <span class="kw">set.seed</span>(seed)</span>
<span id="cb861-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-4"></a>  </span>
<span id="cb861-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-5"></a>  x_<span class="dv">123</span> &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">3</span>)</span>
<span id="cb861-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-6"></a>  x_<span class="dv">4</span>   &lt;-<span class="st"> </span>((g) <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>(x_<span class="dv">123</span>) <span class="op">-</span><span class="st"> </span>x_<span class="dv">123</span>[<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>x_<span class="dv">123</span>[<span class="dv">3</span>]) <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">-</span><span class="st"> </span>g)</span>
<span id="cb861-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-7"></a>  z     &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">c</span>(x_<span class="dv">123</span>, x_<span class="dv">4</span>))</span>
<span id="cb861-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-8"></a>  p     &lt;-<span class="st"> </span><span class="kw">c</span>(x_<span class="dv">123</span>, x_<span class="dv">4</span>) <span class="op">/</span><span class="st"> </span>z</span>
<span id="cb861-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-9"></a>  <span class="kw">tibble</span>(<span class="dt">h   =</span> <span class="op">-</span><span class="kw">sum</span>(p <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p)), </span>
<span id="cb861-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-10"></a>         <span class="dt">p   =</span> p,</span>
<span id="cb861-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-11"></a>         <span class="dt">key =</span> <span class="kw">factor</span>(<span class="kw">c</span>(<span class="st">&quot;ww&quot;</span>, <span class="st">&quot;bw&quot;</span>, <span class="st">&quot;wb&quot;</span>, <span class="st">&quot;bb&quot;</span>), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;ww&quot;</span>, <span class="st">&quot;bw&quot;</span>, <span class="st">&quot;wb&quot;</span>, <span class="st">&quot;bb&quot;</span>)))</span>
<span id="cb861-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-12"></a>  </span>
<span id="cb861-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb861-13"></a>}</span></code></pre></div>
<p>For a given <code>seed</code> and <code>g</code> value, our augmented <code>sim_p()</code> function returns a <span class="math inline">\(4 \times 3\)</span> tibble.</p>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb862-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb862-1"></a><span class="kw">sim_p</span>(<span class="dt">seed =</span> <span class="fl">9.9</span>, <span class="dt">g =</span> <span class="fl">1.4</span>)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 3
##       h      p key  
##   &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;
## 1  1.02 0.197  ww   
## 2  1.02 0.0216 bw   
## 3  1.02 0.184  wb   
## 4  1.02 0.597  bb</code></pre>
<p>So the next step is to determine how many replications we’d like, create a tibble with seed values ranging from 1 to that number, and then feed those <code>seed</code> values into <code>sim_p()</code> via <code>purrr::map2()</code>, which will return a nested tibble. We’ll then <code>unnest()</code> and take a peek.</p>
<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb864-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb864-1"></a><span class="co"># how many replications would you like?</span></span>
<span id="cb864-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb864-2"></a>n_rep &lt;-<span class="st"> </span><span class="fl">1e5</span></span>
<span id="cb864-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb864-3"></a></span>
<span id="cb864-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb864-4"></a>d &lt;-</span>
<span id="cb864-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb864-5"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">seed =</span> <span class="dv">1</span><span class="op">:</span>n_rep) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb864-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb864-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> <span class="kw">map2</span>(seed, <span class="fl">1.4</span>, sim_p)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb864-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb864-7"></a><span class="st">  </span><span class="kw">unnest</span>(sim)</span></code></pre></div>
<p>Take a look.</p>
<div class="sourceCode" id="cb865"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb865-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb865-1"></a><span class="kw">head</span>(d)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 4
##    seed     h      p key  
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;
## 1     1  1.21 0.108  ww   
## 2     1  1.21 0.151  bw   
## 3     1  1.21 0.233  wb   
## 4     1  1.21 0.508  bb   
## 5     2  1.21 0.0674 ww   
## 6     2  1.21 0.256  bw</code></pre>
<p>In order to intelligently choose which four replications we want to highlight in Figure 9.4, we’ll want to rank order them by entropy, <code>h</code>.</p>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb867-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-1"></a>ranked_d &lt;-</span>
<span id="cb867-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-2"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb867-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-3"></a><span class="st">  </span><span class="kw">group_by</span>(seed) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb867-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-4"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(h)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb867-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-5"></a><span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb867-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-6"></a><span class="st">  </span><span class="co"># here&#39;s the rank order step</span></span>
<span id="cb867-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">rank =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span>n_rep, <span class="dt">each =</span> <span class="dv">4</span>))</span>
<span id="cb867-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-8"></a></span>
<span id="cb867-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb867-9"></a><span class="kw">head</span>(ranked_d)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##    seed     h      p key    rank
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;
## 1 55665  1.22 0.0903 ww        1
## 2 55665  1.22 0.209  bw        1
## 3 55665  1.22 0.210  wb        1
## 4 55665  1.22 0.490  bb        1
## 5 71132  1.22 0.0902 ww        2
## 6 71132  1.22 0.210  bw        2</code></pre>
<p>And we’ll also want a subset of the data to correspond to McElreath’s “A” through “D” distributions.</p>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb869-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-1"></a>subset_d &lt;-</span>
<span id="cb869-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-2"></a><span class="st">  </span>ranked_d <span class="op">%&gt;%</span></span>
<span id="cb869-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-3"></a><span class="st">  </span><span class="co"># I arrived at these `rank` values by trial and error</span></span>
<span id="cb869-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-4"></a><span class="st">  </span><span class="kw">filter</span>(rank <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">87373</span>, n_rep <span class="op">-</span><span class="st"> </span><span class="dv">1500</span>, n_rep <span class="op">-</span><span class="st"> </span><span class="dv">10</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb869-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-5"></a><span class="st">  </span><span class="co"># I arrived at the `height` values by trial and error, too</span></span>
<span id="cb869-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">height       =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">8</span>, <span class="fl">2.25</span>, <span class="fl">.75</span>, <span class="fl">.5</span>), <span class="dt">each =</span> <span class="dv">4</span>),</span>
<span id="cb869-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-7"></a>         <span class="dt">distribution =</span> <span class="kw">rep</span>(letters[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], <span class="dt">each =</span> <span class="dv">4</span>))</span>
<span id="cb869-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-8"></a></span>
<span id="cb869-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb869-9"></a><span class="kw">head</span>(subset_d)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 7
##    seed     h      p key    rank height distribution
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;       
## 1 55665  1.22 0.0903 ww        1   8    a           
## 2 55665  1.22 0.209  bw        1   8    a           
## 3 55665  1.22 0.210  wb        1   8    a           
## 4 55665  1.22 0.490  bb        1   8    a           
## 5 50981  1.00 0.0459 ww    87373   2.25 b           
## 6 50981  1.00 0.0459 bw    87373   2.25 b</code></pre>
<p>We’re finally ready to make our version of the left panel of Figure 9.4.</p>
<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb871-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-1"></a>p1 &lt;-</span>
<span id="cb871-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-2"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb871-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> h)) <span class="op">+</span></span>
<span id="cb871-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-4"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;LaputaMedium&quot;</span>)[<span class="dv">3</span>],</span>
<span id="cb871-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-5"></a>               <span class="dt">adjust =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb871-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-6"></a><span class="st">  </span><span class="co"># note the data statements for the next two geoms</span></span>
<span id="cb871-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-7"></a><span class="st">  </span><span class="kw">geom_linerange</span>(<span class="dt">data =</span> subset_d <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(seed) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span>),</span>
<span id="cb871-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-8"></a>                 <span class="kw">aes</span>(<span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> height),</span>
<span id="cb871-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-9"></a>                 <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;LaputaMedium&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span></span>
<span id="cb871-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-10"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> subset_d <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">group_by</span>(seed) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="dv">1</span>),</span>
<span id="cb871-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-11"></a>            <span class="kw">aes</span>(<span class="dt">y =</span> height <span class="op">+</span><span class="st"> </span><span class="fl">.5</span>, <span class="dt">label =</span> distribution)) <span class="op">+</span></span>
<span id="cb871-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-12"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;Entropy&quot;</span>, <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">.7</span>, <span class="dt">to =</span> <span class="fl">1.2</span>, <span class="dt">by =</span> <span class="fl">.1</span>)) <span class="op">+</span></span>
<span id="cb871-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-13"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb871-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb871-14"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;LaputaMedium&quot;</span>)[<span class="dv">7</span>]))</span></code></pre></div>
<p>Did you notice how our <code>adjust = 1/4</code> with <code>geom_density()</code> served a similar function to the <code>adj=0.1</code> in McElreath’s <code>dens()</code> code? Anyways, here we make the right panel and combine the two with patchwork.</p>
<div class="sourceCode" id="cb872"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb872-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-1"></a>p2 &lt;-</span>
<span id="cb872-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-2"></a><span class="st">  </span>ranked_d <span class="op">%&gt;%</span></span>
<span id="cb872-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-3"></a><span class="st">  </span><span class="kw">filter</span>(rank <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">87373</span>, n_rep <span class="op">-</span><span class="st"> </span><span class="dv">1500</span>, n_rep <span class="op">-</span><span class="st"> </span><span class="dv">10</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb872-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">distribution =</span> <span class="kw">rep</span>(letters[<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>], <span class="dt">each =</span> <span class="dv">4</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb872-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-5"></a></span>
<span id="cb872-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> key, <span class="dt">y =</span> p, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb872-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-7"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;LaputaMedium&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span></span>
<span id="cb872-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-8"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;LaputaMedium&quot;</span>)[<span class="dv">4</span>]) <span class="op">+</span></span>
<span id="cb872-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-9"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">.75</span>)) <span class="op">+</span></span>
<span id="cb872-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-10"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb872-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-11"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.x =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb872-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-12"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb872-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-13"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;LaputaMedium&quot;</span>)[<span class="dv">7</span>]),</span>
<span id="cb872-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-14"></a>        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;LaputaMedium&quot;</span>)[<span class="dv">6</span>])) <span class="op">+</span></span>
<span id="cb872-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-15"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>distribution)</span>
<span id="cb872-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-16"></a></span>
<span id="cb872-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-17"></a><span class="co"># combine and plot</span></span>
<span id="cb872-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-18"></a><span class="kw">library</span>(patchwork)</span>
<span id="cb872-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-19"></a></span>
<span id="cb872-20"><a href="big-entropy-and-the-generalized-linear-model.html#cb872-20"></a>p1 <span class="op">|</span><span class="st"> </span>p2</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-25-1.png" width="672" /></p>
<p>Because we were simulating, our values won’t match up identically with those in the text. But we’re pretty close, eh?</p>
<p>Since we saved our <code>sim_p()</code> output in a nested tibble, which we then <code>unnested()</code>, there’s no need to separate the entropy values from the distributional values the way McElreath did in R code 9.11. If we wanted to determine our highest entropy value–and the corresponding <code>seed</code> and <code>p</code> values, while we’re at it–, we might execute something like this.</p>
<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb873-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb873-1"></a>ranked_d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb873-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb873-2"></a><span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb873-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb873-3"></a><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(h)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb873-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb873-4"></a><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
## # Groups:   key [4]
##    seed     h      p key    rank
##   &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt; &lt;int&gt;
## 1 55665  1.22 0.0903 ww        1
## 2 55665  1.22 0.209  bw        1
## 3 55665  1.22 0.210  wb        1
## 4 55665  1.22 0.490  bb        1</code></pre>
<p>That maximum <code>h</code> value matched up nicely with the one in the text. If you look at the <code>p</code> column, you’ll see our values approximated McElreath’s <code>distribution</code> values, too. In both cases, they’re real close to the <code>a</code> values we computed, above.</p>
<div class="sourceCode" id="cb875"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb875-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb875-1"></a>a</span></code></pre></div>
<pre><code>## [1] 0.09 0.21 0.21 0.49</code></pre>
<p>“All four of these distributions really do have expected value 1.4. But among the infinite distributions that satisfy this constraint, it is only the most even distribution, the exact one nominated by the binomial distribution, that has greatest entropy” (p. 278).</p>
</div>
</div>
<div id="generalized-linear-models" class="section level2">
<h2><span class="header-section-number">9.2</span> Generalized linear models</h2>
<blockquote>
<p>For an outcome variable that is continuous and far from any theoretical maximum or minimum, [a simple] Gaussian model has maximum entropy. But when the outcome variable is either discrete or bounded, a Gaussian likelihood is not the most powerful choice. (p. 280)</p>
</blockquote>
<p>I winged the values for our Figure 9.5.</p>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb877-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-1"></a><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-1</span>, <span class="dt">to =</span> <span class="dv">3</span>, <span class="dt">by =</span> <span class="fl">.01</span>)) <span class="op">%&gt;%</span></span>
<span id="cb877-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">probability =</span> <span class="fl">.35</span> <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span><span class="fl">.5</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb877-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-3"></a></span>
<span id="cb877-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> probability)) <span class="op">+</span></span>
<span id="cb877-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-5"></a><span class="st">  </span><span class="kw">geom_rect</span>(<span class="dt">xmin =</span> <span class="dv">-1</span>, <span class="dt">xmax =</span> <span class="dv">3</span>,</span>
<span id="cb877-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-6"></a>            <span class="dt">ymin =</span> <span class="dv">0</span>,  <span class="dt">ymax =</span> <span class="dv">1</span>,</span>
<span id="cb877-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-7"></a>            <span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MononokeMedium&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span></span>
<span id="cb877-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-8"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MononokeMedium&quot;</span>)[<span class="dv">7</span>]) <span class="op">+</span></span>
<span id="cb877-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-9"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">linetype =</span> probability <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">color =</span> probability <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>),</span>
<span id="cb877-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-10"></a>            <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb877-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-11"></a><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">x =</span> <span class="fl">1.3</span>, <span class="dt">xend =</span> <span class="dv">3</span>,</span>
<span id="cb877-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-12"></a>               <span class="dt">y =</span> <span class="dv">1</span>, <span class="dt">yend =</span> <span class="dv">1</span>,</span>
<span id="cb877-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-13"></a>               <span class="dt">size =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MononokeMedium&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span></span>
<span id="cb877-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-14"></a><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">ghibli_palette</span>(<span class="st">&quot;MononokeMedium&quot;</span>)[<span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">4</span>)])) <span class="op">+</span></span>
<span id="cb877-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-15"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">.5</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb877-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-16"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2</span>),</span>
<span id="cb877-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-17"></a>                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">1.2</span>)) <span class="op">+</span></span>
<span id="cb877-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-18"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb877-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-19"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb877-20"><a href="big-entropy-and-the-generalized-linear-model.html#cb877-20"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;MononokeMedium&quot;</span>)[<span class="dv">1</span>]))</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-28-1.png" width="312" /></p>
<blockquote>
<p>For a count outcome <span class="math inline">\(y\)</span> for which each observation arises from <span class="math inline">\(n\)</span> trials and with constant expected value <span class="math inline">\(np\)</span>, the binomial distribution has maximum entropy. So it’s the least informative distribution that satisfies our prior knowledge of the outcomes <span class="math inline">\(y\)</span>. (p. 281)</p>
</blockquote>
<p>The binomial model follows the basic form</p>
<p><span class="math display">\[\begin{align*}
y_i    &amp; \sim \operatorname{Binomial} (n, p_i) \\
f(p_i) &amp; = \alpha + \beta x_i,
\end{align*}\]</span></p>
<p>where the <span class="math inline">\(f()\)</span> portion of the second line represents the link function. We need the link function because, though the shape of the Binomial distribution is determined by two parameters–<span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>–, neither is equivalent to the Gaussian mean <span class="math inline">\(\mu\)</span>. The mean outcome, rather, is <span class="math inline">\(np\)</span>–a function of both. The link function also ensures the model doesn’t make probability predictions outside of the boundary <span class="math inline">\([0, 1]\)</span>.</p>
<p>Let’s get more general.</p>
<div id="meet-the-family." class="section level3">
<h3><span class="header-section-number">9.2.1</span> Meet the family.</h3>
<blockquote>
<p>The most common distributions used in statistical modeling are members of a family known as the <strong>exponential family</strong>. Every member of this family is a maximum entropy distribution, for some set of constraints. And conveniently, just about every other statistical modeling tradition employs the exact same distributions, even though they arrive at them via justifications other than maximum entropy. (p. 282, <strong>emphasis</strong> in the original)</p>
</blockquote>
<p>Here are the Gamma and Exponential panels for Figure 9.6.</p>
<div class="sourceCode" id="cb878"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb878-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-1"></a>length_out &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb878-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-2"></a></span>
<span id="cb878-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-3"></a><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">5</span>, <span class="dt">length.out =</span> length_out)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb878-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Gamma       =</span> <span class="kw">dgamma</span>(x, <span class="dv">2</span>, <span class="dv">2</span>),</span>
<span id="cb878-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-5"></a>         <span class="dt">Exponential =</span> <span class="kw">dexp</span>(x)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb878-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-6"></a><span class="st">  </span><span class="kw">gather</span>(key, density, <span class="op">-</span>x) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb878-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">label =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;y %~% Gamma(lambda, kappa)&quot;</span>, <span class="st">&quot;y %~% Exponential(lambda)&quot;</span>), <span class="dt">each =</span> <span class="kw">n</span>()<span class="op">/</span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb878-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-8"></a><span class="st">  </span></span>
<span id="cb878-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> density)) <span class="op">+</span></span>
<span id="cb878-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-10"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span></span>
<span id="cb878-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-11"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb878-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-12"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb878-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-13"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">4</span>)) <span class="op">+</span></span>
<span id="cb878-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-14"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb878-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-15"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">5</span>]),</span>
<span id="cb878-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-16"></a>        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">7</span>])) <span class="op">+</span></span>
<span id="cb878-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb878-17"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>label, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>, <span class="dt">labeller =</span> label_parsed)</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-29-1.png" width="576" /></p>
<p>The Gaussian:</p>
<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb879-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-1"></a><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-5</span>, <span class="dt">to =</span> <span class="dv">5</span>, <span class="dt">length.out =</span> length_out)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb879-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dnorm</span>(x),</span>
<span id="cb879-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-3"></a>         <span class="dt">strip   =</span> <span class="st">&quot;y %~% Normal(mu, sigma)&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb879-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-4"></a></span>
<span id="cb879-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> density)) <span class="op">+</span></span>
<span id="cb879-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-6"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span></span>
<span id="cb879-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-7"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb879-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-8"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb879-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-9"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>)) <span class="op">+</span></span>
<span id="cb879-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-10"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb879-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-11"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">5</span>]),</span>
<span id="cb879-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-12"></a>        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">7</span>])) <span class="op">+</span></span>
<span id="cb879-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb879-13"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>strip, <span class="dt">labeller =</span> label_parsed)</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-30-1.png" width="288" /></p>
<p>Here is the Poisson.</p>
<div class="sourceCode" id="cb880"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb880-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-1"></a><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb880-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dpois</span>(x, <span class="dt">lambda =</span> <span class="fl">2.5</span>),</span>
<span id="cb880-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-3"></a>         <span class="dt">strip   =</span> <span class="st">&quot;y %~% Poisson(lambda)&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb880-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-4"></a></span>
<span id="cb880-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> density)) <span class="op">+</span></span>
<span id="cb880-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-6"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">2</span>], <span class="dt">width =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb880-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-7"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb880-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-8"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb880-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-9"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="op">+</span></span>
<span id="cb880-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-10"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb880-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-11"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">5</span>]),</span>
<span id="cb880-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-12"></a>        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">7</span>])) <span class="op">+</span></span>
<span id="cb880-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb880-13"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>strip, <span class="dt">labeller =</span> label_parsed)</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-31-1.png" width="288" /></p>
<p>Finally, the Binomial:</p>
<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb881-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-1"></a><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">10</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb881-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dbinom</span>(x, <span class="dt">size =</span> <span class="dv">10</span>, <span class="dt">prob =</span> <span class="fl">.85</span>),</span>
<span id="cb881-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-3"></a>         <span class="dt">strip   =</span> <span class="st">&quot;y %~% Binomial(n, p)&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb881-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-4"></a></span>
<span id="cb881-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> density)) <span class="op">+</span></span>
<span id="cb881-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-6"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">2</span>], <span class="dt">width =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb881-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-7"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb881-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-8"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb881-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-9"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="op">+</span></span>
<span id="cb881-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-10"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb881-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-11"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">5</span>]),</span>
<span id="cb881-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-12"></a>        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;SpiritedMedium&quot;</span>)[<span class="dv">7</span>])) <span class="op">+</span></span>
<span id="cb881-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb881-13"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>strip, <span class="dt">labeller =</span> label_parsed)</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-32-1.png" width="288" /></p>
<div id="rethinking-a-likelihood-is-a-prior." class="section level4">
<h4><span class="header-section-number">9.2.1.1</span> Rethinking: A likelihood is a prior.</h4>
<blockquote>
<p>In traditional statistics, likelihood functions are “objective” and prior distributions “subjective.” However, likelihoods are themselves prior probability distributions: They are priors for the data, conditional on the parameters. And just like with other priors, there is no correct likelihood. But there are better and worse likelihoods, depending upon context. (p. 284)</p>
</blockquote>
<p>For a little more in this, check out McElreath’s great lecture, <a href="https://www.youtube.com/watch?v=yakg94HyWdE&amp;t=1s&amp;frags=pl%2Cwn">Bayesian statistics without frequentist language</a>. This subsection also reminds me of the title of one of Gelman’s blog posts, <a href="https://statmodeling.stat.columbia.edu/2015/01/27/perhaps-merely-accident-history-skeptics-subjectivists-alike-strain-gnat-prior-distribution-swallowing-camel-likelihood/"><em>“It is perhaps merely an accident of history that skeptics and subjectivists alike strain on the gnat of the prior distribution while swallowing the camel that is the likelihood”</em></a>. The title, which itself is a quote, comes from one of his papers, which he linked to in the blog, along with several related papers. It’s taken some time for the weight of that quote to sink in with me, and indeed it’s still sinking. Perhaps you’ll benefit from it, too.</p>
</div>
</div>
<div id="linking-linear-models-to-distributions." class="section level3">
<h3><span class="header-section-number">9.2.2</span> Linking linear models to distributions.</h3>
<blockquote>
<p>To build a regression model from any of the exponential family distributions is just a matter of attaching one or more linear models to one or more of the parameters that describe the distribution’s shape. But as hinted at earlier, usually we require a link function to prevent mathematical accidents like negative distances or probability masses that exceed 1. (p. 284)</p>
</blockquote>
<p>These models generally follow the form</p>
<p><span class="math display">\[\begin{align*}
y_i         &amp; \sim \operatorname{Some distribution} (\theta_i, \phi) \\
f(\theta_i) &amp; = \alpha + \beta x_i,
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\theta_i\)</span> is a parameter of central interest (e.g., the probability of 1 in a Binomial distribution) and <span class="math inline">\(\phi\)</span> is a placeholder for any other parameters necessary for the likelihood but not of primary substantive interest (e.g., <span class="math inline">\(\sigma\)</span> in work-a-day Gaussian models). And as stated earlier, <span class="math inline">\(f()\)</span> is the link function.</p>
<p>Speaking of,</p>
<blockquote>
<p>the logit link maps a parameter that is defined as a probability mass and therefore constrained to lie between zero and one, onto a linear model that can take on any real value. This link is extremely common when working with binomial GLMs. In the context of a model definition, it looks like this:</p>
<p><span class="math display">\[\begin{align*}
y_i &amp; \sim \operatorname{Binomial}(n, p_i)\\
\text{logit}(p_i) &amp; = \alpha+\beta x_i 
\end{align*}\]</span></p>
<p>And the logit function itself is defined as the <em>log-odds:</em></p>
<p><span class="math display">\[\operatorname{logit}(p_i) = \log \frac{p_i}{1 - p_i}\]</span></p>
<p>The “odds” of an event are just the probability it happens divided by the probability it does not happen. So really all that is being stated here is:</p>
<p><span class="math display">\[\log \frac{p_i}{1 - p_i} = \alpha + \beta x_i\]</span></p>
</blockquote>
<p>If we do the final algebraic manipulation on page 285, we can solve for <span class="math inline">\(p_i\)</span> in terms of the linear model</p>
<p><span class="math display">\[p_i = \frac{\exp (\alpha + \beta x_i)}{1 + \exp (\alpha + \beta x_i)}.\]</span></p>
<p>As we’ll see later, we will make great use of this formula via the <code>brms::inv_logit_scaled()</code> when making sense of logistic regression models. Now we have that last formula in hand, we can make the data necessary for Figure 9.7.</p>
<div class="sourceCode" id="cb882"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb882-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-1"></a><span class="co"># first, we&#39;ll make data for the horizontal lines</span></span>
<span id="cb882-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-2"></a>alpha &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb882-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-3"></a>beta  &lt;-<span class="st"> </span><span class="dv">4</span></span>
<span id="cb882-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-4"></a></span>
<span id="cb882-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-5"></a>lines &lt;-</span>
<span id="cb882-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-6"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-1</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">by =</span> <span class="fl">.25</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb882-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">log-odds</span><span class="st">`</span>  =<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta,</span>
<span id="cb882-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-8"></a>         <span class="dt">probability =</span> <span class="kw">exp</span>(alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta)))</span>
<span id="cb882-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-9"></a></span>
<span id="cb882-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-10"></a><span class="co"># now we&#39;re ready to make the primary data</span></span>
<span id="cb882-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-11"></a>beta  &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb882-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-12"></a></span>
<span id="cb882-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-13"></a>d &lt;-</span>
<span id="cb882-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-14"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">-1.5</span>, <span class="dt">to =</span> <span class="fl">1.5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb882-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-15"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">log-odds</span><span class="st">`</span>  =<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta,</span>
<span id="cb882-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-16"></a>         <span class="dt">probability =</span> <span class="kw">exp</span>(alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta))) </span>
<span id="cb882-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-17"></a></span>
<span id="cb882-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-18"></a><span class="co"># now we make the individual plots</span></span>
<span id="cb882-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-19"></a>p1 &lt;-</span>
<span id="cb882-20"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-20"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb882-21"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-21"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="st">`</span><span class="dt">log-odds</span><span class="st">`</span>)) <span class="op">+</span></span>
<span id="cb882-22"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-22"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">data =</span> lines,</span>
<span id="cb882-23"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-23"></a>             <span class="kw">aes</span>(<span class="dt">yintercept =</span> <span class="st">`</span><span class="dt">log-odds</span><span class="st">`</span>),</span>
<span id="cb882-24"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-24"></a>             <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span></span>
<span id="cb882-25"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-25"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span></span>
<span id="cb882-26"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-26"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb882-27"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-27"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb882-28"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-28"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">5</span>]))</span>
<span id="cb882-29"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-29"></a></span>
<span id="cb882-30"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-30"></a>p2 &lt;-</span>
<span id="cb882-31"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-31"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb882-32"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-32"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> probability)) <span class="op">+</span></span>
<span id="cb882-33"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-33"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">data =</span> lines,</span>
<span id="cb882-34"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-34"></a>             <span class="kw">aes</span>(<span class="dt">yintercept =</span> probability),</span>
<span id="cb882-35"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-35"></a>             <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span></span>
<span id="cb882-36"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-36"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span></span>
<span id="cb882-37"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-37"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb882-38"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-38"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb882-39"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-39"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">7</span>]))</span>
<span id="cb882-40"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-40"></a></span>
<span id="cb882-41"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-41"></a><span class="co"># finally, we&#39;re ready to mash the plots together and behold their nerdy glory</span></span>
<span id="cb882-42"><a href="big-entropy-and-the-generalized-linear-model.html#cb882-42"></a>p1 <span class="op">|</span><span class="st"> </span>p2</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-33-1.png" width="576" /></p>
<blockquote>
<p>The key lesson for now is just that no regression coefficient, such as <span class="math inline">\(\beta\)</span>, from a GLM ever produces a constant change on the outcome scale. Recall that we defined interaction (<a href="interactions.html#interactions">Chapter 7</a>) as a situation in which the effect of a predictor depends upon the value of another predictor. Well now every predictor essentially interacts with itself, because the impact of a change in a predictor depends upon the value of the predictor before the change…</p>
<p>The second very common link function is the log link. This link function maps a parameter that is defined over only positive real values onto a linear model. For example, suppose we want to model the standard deviation of <span class="math inline">\(\sigma\)</span> of a Gaussian distribution so it is a function of a predictor variable <span class="math inline">\(x\)</span>. The parameter <span class="math inline">\(\sigma\)</span> must be positive, because a standard deviation cannot be negative no can it be zero. The model might look like:</p>
<p><span class="math display">\[\begin{align*}
y_i                   &amp; \sim \operatorname{Normal}(\mu, \sigma_i) \\
\log (\sigma_i) &amp; = \alpha + \beta x_i
\end{align*}\]</span></p>
<p>In this model, the mean <span class="math inline">\(\mu\)</span> is constant, but the standard deviation scales with the value <span class="math inline">\(x_i\)</span>. (p. 268)</p>
</blockquote>
<p>This kind of model is trivial in the brms framework, which you can learn more about in Bürkner’s <span class="citation">(<a href="#ref-Bürkner2020Distributional" role="doc-biblioref">2020</a><a href="#ref-Bürkner2020Distributional" role="doc-biblioref">f</a>)</span> vignette, <a href="https://cran.r-project.org/package=brms/vignettes/brms_distreg.html"><em>Estimating distributional models with brms</em></a>. Before moving on with the text, let’s detour and see how we might fit such a model. First, we’ll simulate some continuous data <code>y</code> for which the <span class="math inline">\(SD\)</span> is affected by a dummy variable <code>x</code>.</p>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb883-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb883-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb883-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb883-2"></a>(</span>
<span id="cb883-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb883-3"></a>  d &lt;-</span>
<span id="cb883-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb883-4"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">rep</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">each =</span> <span class="dv">100</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb883-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb883-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">mean =</span> <span class="dv">100</span>, <span class="dt">sd =</span> <span class="dv">10</span> <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span><span class="dv">10</span>))</span>
<span id="cb883-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb883-6"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 200 x 2
##        x     y
##    &lt;int&gt; &lt;dbl&gt;
##  1     0  92.3
##  2     0  91.8
##  3     0  98.6
##  4     0  97.2
##  5     0 104. 
##  6     0  88.1
##  7     0 112. 
##  8     0  99.8
##  9     0  97.5
## 10     0  96.4
## # … with 190 more rows</code></pre>
<p>We can view what data like these look like with aid from <code>tidybayes::stat_halfeye()</code>.</p>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb885-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-1"></a><span class="kw">library</span>(tidybayes)</span>
<span id="cb885-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-2"></a></span>
<span id="cb885-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-3"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb885-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x =</span> x <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.character</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb885-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-5"></a><span class="st">  </span></span>
<span id="cb885-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> y, <span class="dt">y =</span> x, <span class="dt">fill =</span> x)) <span class="op">+</span></span>
<span id="cb885-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-7"></a><span class="st">  </span><span class="kw">stat_halfeye</span>(<span class="dt">point_interval =</span> mean_qi, <span class="dt">.width =</span> <span class="fl">.68</span>,</span>
<span id="cb885-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-8"></a>               <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;KikiMedium&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span></span>
<span id="cb885-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-9"></a><span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">ghibli_palette</span>(<span class="st">&quot;KikiMedium&quot;</span>)[<span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">6</span>)])) <span class="op">+</span></span>
<span id="cb885-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-10"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.5</span>, <span class="dv">2</span>)) <span class="op">+</span></span>
<span id="cb885-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-11"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb885-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-12"></a>        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb885-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-13"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb885-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb885-14"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;KikiMedium&quot;</span>)[<span class="dv">7</span>]))</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-35-1.png" width="336" /></p>
<p>Even though the means of <code>y</code> are the same for both levels of the <code>x</code> dummy, the variance for <code>x == 1</code> is substantially larger than that for <code>x == 0</code>. Let’s open brms.</p>
<div class="sourceCode" id="cb886"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb886-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb886-1"></a><span class="kw">library</span>(brms)</span></code></pre></div>
<p>For such a model, we have two formulas: one for <span class="math inline">\(\mu\)</span> and one for <span class="math inline">\(\sigma\)</span>. We wrap both within the <code>bf()</code> function.</p>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb887-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-1"></a>b9<span class="fl">.1</span> &lt;-<span class="st"> </span></span>
<span id="cb887-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d,</span>
<span id="cb887-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb887-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-4"></a>      <span class="kw">bf</span>(y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, sigma <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x),</span>
<span id="cb887-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-5"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">100</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb887-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-6"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>),   <span class="dt">class =</span> Intercept, <span class="dt">dpar =</span> sigma),</span>
<span id="cb887-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-7"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>),   <span class="dt">class =</span> b,         <span class="dt">dpar =</span> sigma)),</span>
<span id="cb887-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-8"></a>      <span class="dt">seed =</span> <span class="dv">9</span>,</span>
<span id="cb887-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb887-9"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b09.01&quot;</span>)</span></code></pre></div>
<p>Do note our use of the <code>dpar</code> arguments in the <code>prior</code> statements. Here’s the summary.</p>
<div class="sourceCode" id="cb888"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb888-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb888-1"></a><span class="kw">print</span>(b9<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: y ~ 1 
##          sigma ~ 1 + x
##    Data: d (Number of observations: 200) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept          99.05      0.86    97.33   100.77 1.00     3820     2917
## sigma_Intercept     2.27      0.07     2.13     2.42 1.00     3580     2560
## sigma_x             0.72      0.10     0.53     0.92 1.00     3547     2999
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Now we get an intercept for both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, with the intercept for sigma identified as <code>sigma_Intercept</code>. And note the coefficient for <span class="math inline">\(\sigma\)</span> was named <code>sigma_x</code>. Also notice the scale the <code>sigma_i</code> coefficients are on. These are not in the original metric, but rather based on a logarithmic transformation of <span class="math inline">\(\sigma\)</span>. You can confirm that by the second line of the <code>print()</code> output: <code>Links: mu = identity; sigma = log</code>. So if you want to get a sense of the effects of <code>x</code> on the <span class="math inline">\(\sigma\)</span> for <code>y</code>, you have to exponentiate the formula. Here we’ll do so with the <code>posterior_samples()</code>.</p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb890-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb890-1"></a>post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b9<span class="fl">.1</span>)</span>
<span id="cb890-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb890-2"></a></span>
<span id="cb890-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb890-3"></a><span class="kw">head</span>(post)</span></code></pre></div>
<pre><code>##   b_Intercept b_sigma_Intercept b_sigma_x      lp__
## 1    98.84956          2.233535 0.8623039 -818.6777
## 2   100.14612          2.266612 0.6808733 -818.3497
## 3    99.92042          2.288555 0.5394581 -820.7937
## 4    98.53169          2.252506 0.8204850 -818.3785
## 5    99.33601          2.316855 0.8825084 -821.8363
## 6    97.89674          2.327657 0.8140927 -821.0064</code></pre>
<p>With the samples in hand, we’ll use the model formula to compute the model-implied standard deviations of <code>y</code> based on the <code>x</code> dummy and then examine them in a plot.</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb892-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-1"></a>post <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb892-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-2"></a><span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">x == 0</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> </span>b_sigma_x <span class="op">*</span><span class="st"> </span><span class="dv">0</span>),</span>
<span id="cb892-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-3"></a>            <span class="st">`</span><span class="dt">x == 1</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(b_sigma_Intercept <span class="op">+</span><span class="st"> </span>b_sigma_x <span class="op">*</span><span class="st"> </span><span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb892-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-4"></a><span class="st">  </span><span class="kw">gather</span>(key, sd) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb892-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-5"></a><span class="st">  </span></span>
<span id="cb892-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sd, <span class="dt">y =</span> key, <span class="dt">fill =</span> key)) <span class="op">+</span></span>
<span id="cb892-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-7"></a><span class="st">  </span><span class="kw">stat_halfeye</span>(<span class="dt">point_interval =</span> median_qi, <span class="dt">.width =</span> <span class="fl">.95</span>,</span>
<span id="cb892-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-8"></a>               <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;KikiMedium&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span></span>
<span id="cb892-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-9"></a><span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">ghibli_palette</span>(<span class="st">&quot;KikiMedium&quot;</span>)[<span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">6</span>)])) <span class="op">+</span></span>
<span id="cb892-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-10"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Model-implied standard deviations by group&quot;</span>,</span>
<span id="cb892-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-11"></a>       <span class="dt">x =</span> <span class="kw">expression</span>(sigma[x]), </span>
<span id="cb892-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-12"></a>       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb892-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-13"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">1.5</span>, <span class="dv">2</span>)) <span class="op">+</span></span>
<span id="cb892-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-14"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb892-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-15"></a>        <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb892-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-16"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb892-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb892-17"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;KikiMedium&quot;</span>)[<span class="dv">7</span>]))</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-39-1.png" width="360" /></p>
<p>And if we looked back at the data, those <span class="math inline">\(SD\)</span> estimates are just what we’d expect.</p>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb893-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb893-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb893-2"></a><span class="st">  </span><span class="kw">group_by</span>(x) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb893-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb893-3"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(y) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">1</span>)) </span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##       x    sd
##   &lt;int&gt; &lt;dbl&gt;
## 1     0   9.6
## 2     1  19.8</code></pre>
<p>For more on models like this, check out Christakis’s blog post, <a href="https://www.edge.org/response-detail/25437"><em>2014: What scientific idea is ready for retirement?</em></a>, or his paper with Subramanian and Kim, <a href="http://humannaturelab.net/publications/the-average-treatment-effect-a-construct-ripe-for-retirement-a-commentary-on-deaton-and-cartwright"><em>The “average” treatment effect: A construct ripe for retirement. A commentary on Deaton and Cartwright</em></a>, <span class="citation">(Subramanian et al., <a href="#ref-subramanianAverageTreatmentEffect2018a" role="doc-biblioref">2018</a>)</span>. Kruschke covered modeling <span class="math inline">\(\sigma\)</span> a bit in his <span class="citation">(<a href="#ref-kruschkeDoingBayesianData2015" role="doc-biblioref">2015</a>)</span> <a href="https://sites.google.com/site/doingbayesiandataanalysis/"><em>Doing Bayesian data analysis, second edition: A tutorial with R, JAGS, and Stan</em></a>, my <span class="citation">(<a href="#ref-kurzDoingBayesianData2020" role="doc-biblioref">2020</a><a href="#ref-kurzDoingBayesianData2020" role="doc-biblioref">a</a>)</span> translation for which lives <a href="https://bookdown.org/content/3686/">here</a>. Finally, this is foreshadowing a bit because it requires the multilevel model (see Chapters <a href="multilevel-models.html#multilevel-models">12</a> and <a href="adventures-in-covariance.html#adventures-in-covariance">13</a>), but you might also check out the <span class="citation">(<a href="#ref-williamsBayesianMultivariateMixedeffects2019a" role="doc-biblioref">2019</a>)</span> preprint by Williams, Liu, Martin, and Rast, <a href="https://psyarxiv.com/4kfjp/"><em>Bayesian multivariate mixed-effects location scale modeling of longitudinal relations among affective traits, states, and physical activity</em></a> or Williams’s blog post, <a href="https://donaldrwilliams.github.io/2020/04/04/a-defining-feature-of-cognitive-interference-tasks-heterogeneous-within-person-variance/"><em>A defining feature of cognitive interference tasks: Heterogeneous within-person variance</em></a>.</p>
<p>But getting back to the text,</p>
<blockquote>
<p>what the log link effectively assumes is that the parameter’s value is the exponentiation of the linear model. Solving <span class="math inline">\(\log (\sigma_i) = \alpha + \beta x_i\)</span> for <span class="math inline">\(\sigma_i\)</span> yields the inverse link:</p>
<p><span class="math display">\[\sigma_i = \exp (\alpha + \beta x_i)\]</span></p>
<p>The impact of this assumption can be seen in [our version of] Figure 9.8. (pp. 286—287)</p>
</blockquote>
<div class="sourceCode" id="cb895"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb895-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-1"></a><span class="co"># first, we&#39;ll make data that&#39;ll be make the horizontal lines</span></span>
<span id="cb895-2"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-2"></a>alpha &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb895-3"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-3"></a>beta  &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb895-4"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-4"></a></span>
<span id="cb895-5"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-5"></a>lines &lt;-</span>
<span id="cb895-6"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-6"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="st">`</span><span class="dt">log-measurement</span><span class="st">`</span>      =<span class="st"> </span><span class="dv">-3</span><span class="op">:</span><span class="dv">3</span>,</span>
<span id="cb895-7"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-7"></a>         <span class="st">`</span><span class="dt">original measurement</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">3</span><span class="op">:</span><span class="dv">3</span>))</span>
<span id="cb895-8"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-8"></a></span>
<span id="cb895-9"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-9"></a><span class="co"># now we&#39;re ready to make the primary data</span></span>
<span id="cb895-10"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-10"></a>d &lt;-</span>
<span id="cb895-11"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-11"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">-1.5</span>, <span class="dt">to =</span> <span class="fl">1.5</span>, <span class="dt">length.out =</span> <span class="dv">50</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb895-12"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-12"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">log-measurement</span><span class="st">`</span>      =<span class="st"> </span>alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta,</span>
<span id="cb895-13"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-13"></a>         <span class="st">`</span><span class="dt">original measurement</span><span class="st">`</span> =<span class="st"> </span><span class="kw">exp</span>(alpha <span class="op">+</span><span class="st"> </span>x <span class="op">*</span><span class="st"> </span>beta)) </span>
<span id="cb895-14"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-14"></a></span>
<span id="cb895-15"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-15"></a><span class="co"># now we make the individual plots</span></span>
<span id="cb895-16"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-16"></a>p1 &lt;-</span>
<span id="cb895-17"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-17"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb895-18"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-18"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="st">`</span><span class="dt">log-measurement</span><span class="st">`</span>)) <span class="op">+</span></span>
<span id="cb895-19"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-19"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">data =</span> lines,</span>
<span id="cb895-20"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-20"></a>             <span class="kw">aes</span>(<span class="dt">yintercept =</span> <span class="st">`</span><span class="dt">log-measurement</span><span class="st">`</span>),</span>
<span id="cb895-21"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-21"></a>             <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span></span>
<span id="cb895-22"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-22"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span></span>
<span id="cb895-23"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-23"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb895-24"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-24"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb895-25"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-25"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">5</span>]))</span>
<span id="cb895-26"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-26"></a></span>
<span id="cb895-27"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-27"></a>p2 &lt;-</span>
<span id="cb895-28"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-28"></a><span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb895-29"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-29"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="st">`</span><span class="dt">original measurement</span><span class="st">`</span>)) <span class="op">+</span></span>
<span id="cb895-30"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-30"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">data =</span> lines,</span>
<span id="cb895-31"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-31"></a>             <span class="kw">aes</span>(<span class="dt">yintercept =</span> <span class="st">`</span><span class="dt">original measurement</span><span class="st">`</span>),</span>
<span id="cb895-32"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-32"></a>             <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span></span>
<span id="cb895-33"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-33"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">color =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span></span>
<span id="cb895-34"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-34"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">position =</span> <span class="st">&quot;right&quot;</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>)) <span class="op">+</span></span>
<span id="cb895-35"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-35"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb895-36"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-36"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>(),</span>
<span id="cb895-37"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-37"></a>        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">ghibli_palette</span>(<span class="st">&quot;YesterdayMedium&quot;</span>)[<span class="dv">7</span>]))</span>
<span id="cb895-38"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-38"></a></span>
<span id="cb895-39"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-39"></a><span class="co"># combine the ggplots</span></span>
<span id="cb895-40"><a href="big-entropy-and-the-generalized-linear-model.html#cb895-40"></a>p1 <span class="op">|</span><span class="st"> </span>p2</span></code></pre></div>
<p><img src="09_files/figure-gfm/unnamed-chunk-41-1.png" width="576" /></p>
<blockquote>
<p>Using a log link for a linear model (left) implies an exponential scaling of the outcome with the predictor variable (right). Another way to think of this relationship is to remember that logarithms are <em>magnitudes</em>. An increase of one unit on the log scale means an increase of an order of magnitude on the untransformed scale. And this fact is reflected in the widening intervals between the horizontal lines in the right-hand plot of Figure 9.8. (p. 287, <em>emphasis</em> in the original)</p>
</blockquote>
</div>
<div id="absolute-and-relative-differences." class="section level3">
<h3><span class="header-section-number">9.2.3</span> Absolute and relative differences.</h3>
<p>Within the context of GLMs with non-identity link functions,</p>
<blockquote>
<p>parameter estimates do not by themselves tell you the importance of a predictor on the outcome. The reason is that each parameter represents a <em>relative</em> difference on the scale of the linear model, ignoring other parameters, while we are really interested in the <em>absolute</em> differences in the outcomes that must incorporate all parameters. (p. 288, <em>emphasis</em> in the original)</p>
</blockquote>
<p>This will make more sense after we start playing around with logistic regression, count regression, and so on. For now, just file it away.</p>
</div>
</div>
<div id="session-info-8" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode" id="cb896"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb896-1"><a href="big-entropy-and-the-generalized-linear-model.html#cb896-1"></a><span class="kw">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.3
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] brms_2.13.5          Rcpp_1.0.5           tidybayes_2.1.1      patchwork_1.0.1.9000
##  [5] ghibli_0.3.1         forcats_0.5.0        stringr_1.4.0        dplyr_1.0.1         
##  [9] purrr_0.3.4          readr_1.3.1          tidyr_1.1.1          tibble_3.0.3        
## [13] ggplot2_3.3.2        tidyverse_1.3.0     
## 
## loaded via a namespace (and not attached):
##   [1] TH.data_1.0-10       colorspace_1.4-1     ellipsis_0.3.1       ggridges_0.5.2      
##   [5] rsconnect_0.8.16     estimability_1.3     markdown_1.1         base64enc_0.1-3     
##   [9] fs_1.4.1             rstudioapi_0.11      farver_2.0.3         rstan_2.19.3        
##  [13] svUnit_1.0.3         DT_0.13              fansi_0.4.1          mvtnorm_1.1-0       
##  [17] lubridate_1.7.8      xml2_1.3.1           codetools_0.2-16     splines_3.6.3       
##  [21] bridgesampling_1.0-0 knitr_1.28           shinythemes_1.1.2    bayesplot_1.7.1     
##  [25] jsonlite_1.7.0       broom_0.5.5          dbplyr_1.4.2         ggdist_2.1.1        
##  [29] shiny_1.5.0          compiler_3.6.3       httr_1.4.1           emmeans_1.4.5       
##  [33] backports_1.1.9      assertthat_0.2.1     Matrix_1.2-18        fastmap_1.0.1       
##  [37] cli_2.0.2            later_1.1.0.1        prettyunits_1.1.1    htmltools_0.5.0     
##  [41] tools_3.6.3          igraph_1.2.5         coda_0.19-3          gtable_0.3.0        
##  [45] glue_1.4.2           reshape2_1.4.4       cellranger_1.1.0     vctrs_0.3.4         
##  [49] nlme_3.1-144         crosstalk_1.1.0.1    xfun_0.13            ps_1.3.4            
##  [53] rvest_0.3.5          mime_0.9             miniUI_0.1.1.1       lifecycle_0.2.0     
##  [57] gtools_3.8.2         MASS_7.3-51.5        zoo_1.8-7            scales_1.1.1        
##  [61] colourpicker_1.0     hms_0.5.3            promises_1.1.1       Brobdingnag_1.2-6   
##  [65] sandwich_2.5-1       parallel_3.6.3       inline_0.3.15        shinystan_2.5.0     
##  [69] yaml_2.2.1           gridExtra_2.3        StanHeaders_2.21.0-1 loo_2.3.1           
##  [73] stringi_1.4.6        dygraphs_1.1.1.6     pkgbuild_1.1.0       rlang_0.4.7         
##  [77] pkgconfig_2.0.3      matrixStats_0.56.0   evaluate_0.14        lattice_0.20-38     
##  [81] rstantools_2.1.1     htmlwidgets_1.5.1    labeling_0.3         processx_3.4.4      
##  [85] tidyselect_1.1.0     plyr_1.8.6           magrittr_1.5         bookdown_0.18       
##  [89] R6_2.4.1             generics_0.0.2       multcomp_1.4-13      DBI_1.1.0           
##  [93] pillar_1.4.6         haven_2.2.0          withr_2.2.0          xts_0.12-0          
##  [97] survival_3.1-12      abind_1.4-5          modelr_0.1.6         crayon_1.3.4        
## [101] arrayhelpers_1.1-0   utf8_1.1.4           rmarkdown_2.1        grid_3.6.3          
## [105] readxl_1.3.1         callr_3.4.4          threejs_0.3.3        reprex_0.3.0        
## [109] digest_0.6.25        xtable_1.8-4         httpuv_1.5.4         stats4_3.6.3        
## [113] munsell_0.5.0        shinyjs_1.1</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Bürkner2020Distributional">
<p>Bürkner, P.-C. (2020f). <em>Estimating distributional models with brms</em>. <a href="https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html">https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html</a></p>
</div>
<div id="ref-R-ghibli">
<p>Henderson, E. (2020). <em>ghibli: Studio ghibli colour palettes</em> [Manual]. <a href="https://CRAN.R-project.org/package=ghibli">https://CRAN.R-project.org/package=ghibli</a></p>
</div>
<div id="ref-kruschkeDoingBayesianData2015">
<p>Kruschke, J. K. (2015). <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>. Academic Press. <a href="https://sites.google.com/site/doingbayesiandataanalysis/">https://sites.google.com/site/doingbayesiandataanalysis/</a></p>
</div>
<div id="ref-kurzDoingBayesianData2020">
<p>Kurz, A. S. (2020a). <em>Doing Bayesian data analysis in brms and the tidyverse</em> (version 0.3.0). <a href="https://bookdown.org/content/3686/">https://bookdown.org/content/3686/</a></p>
</div>
<div id="ref-mcelreathStatisticalRethinkingBayesian2015">
<p>McElreath, R. (2015). <em>Statistical rethinking: A Bayesian course with examples in R and Stan</em>. CRC press. <a href="https://xcelab.net/rm/statistical-rethinking/">https://xcelab.net/rm/statistical-rethinking/</a></p>
</div>
<div id="ref-subramanianAverageTreatmentEffect2018a">
<p>Subramanian, S. V., Kim, R., &amp; Christakis, N. A. (2018). The “average” treatment effect: A construct ripe for retirement. A commentary on Deaton and Cartwright. <em>Social Science &amp; Medicine</em>, <em>210</em>, 77–82. <a href="https://doi.org/10.1016/j.socscimed.2018.04.027">https://doi.org/10.1016/j.socscimed.2018.04.027</a></p>
</div>
<div id="ref-williamsBayesianMultivariateMixedeffects2019a">
<p>Williams, D. R., Liu, S., Martin, S. R., &amp; Rast, P. (2019). <em>Bayesian multivariate mixed-effects location scale modeling of longitudinal relations among affective traits, states, and physical activity</em>. <a href="https://doi.org/10.31234/osf.io/4kfjp">https://doi.org/10.31234/osf.io/4kfjp</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="markov-chain-monte-carlo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="counting-and-classification.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
