<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistical Rethinking with brms, ggplot2, and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKURZ/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz">


<meta name="date" content="2018-09-26">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="adventures-in-covariance.html">
<link rel="next" href="horoscopes-insights.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>This is a love letter</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this"><i class="fa fa-check"></i>Why this?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#my-assumptions-about-you"><i class="fa fa-check"></i>My assumptions about you</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-and-understand-this-project"><i class="fa fa-check"></i>How to use and understand this project</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#you-can-do-this-too"><i class="fa fa-check"></i>You can do this, too</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html"><i class="fa fa-check"></i><b>1</b> The Golem of Prague</a><ul>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#reference"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html"><i class="fa fa-check"></i><b>2</b> Small Worlds and Large Worlds</a><ul>
<li class="chapter" data-level="2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#the-garden-of-forking-data"><i class="fa fa-check"></i><b>2.1</b> The garden of forking data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#counting-possibilities."><i class="fa fa-check"></i><b>2.1.1</b> Counting possibilities.</a></li>
<li class="chapter" data-level="2.1.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#using-prior-information."><i class="fa fa-check"></i><b>2.1.2</b> Using prior information.</a></li>
<li class="chapter" data-level="2.1.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#from-counts-to-probability."><i class="fa fa-check"></i><b>2.1.3</b> From counts to probability.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#building-a-model"><i class="fa fa-check"></i><b>2.2</b> Building a model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-data-story."><i class="fa fa-check"></i><b>2.2.1</b> A data story.</a></li>
<li class="chapter" data-level="2.2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayesian-updating."><i class="fa fa-check"></i><b>2.2.2</b> Bayesian updating.</a></li>
<li class="chapter" data-level="2.2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#evaluate."><i class="fa fa-check"></i><b>2.2.3</b> Evaluate.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#components-of-the-model"><i class="fa fa-check"></i><b>2.3</b> Components of the model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#likelihood."><i class="fa fa-check"></i><b>2.3.1</b> Likelihood.</a></li>
<li class="chapter" data-level="2.3.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#parameters."><i class="fa fa-check"></i><b>2.3.2</b> Parameters.</a></li>
<li class="chapter" data-level="2.3.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#prior."><i class="fa fa-check"></i><b>2.3.3</b> Prior.</a></li>
<li class="chapter" data-level="2.3.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#posterior."><i class="fa fa-check"></i><b>2.3.4</b> Posterior.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#making-the-model-go"><i class="fa fa-check"></i><b>2.4</b> Making the model go</a><ul>
<li class="chapter" data-level="2.4.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#grid-approximation."><i class="fa fa-check"></i><b>2.4.1</b> Grid approximation.</a></li>
<li class="chapter" data-level="2.4.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#quadratic-approximation."><i class="fa fa-check"></i><b>2.4.2</b> Quadratic approximation.</a></li>
<li class="chapter" data-level="2.4.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#markov-chain-monte-carlo."><i class="fa fa-check"></i><b>2.4.3</b> Markov chain Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#reference-1"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html"><i class="fa fa-check"></i><b>3</b> Sampling the Imaginary</a><ul>
<li class="chapter" data-level="3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-from-a-grid-like-approximate-posterior"><i class="fa fa-check"></i><b>3.1</b> Sampling from a grid-like approximate posterior</a></li>
<li class="chapter" data-level="3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-summarize"><i class="fa fa-check"></i><b>3.2</b> Sampling to summarize</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-boundaries."><i class="fa fa-check"></i><b>3.2.1</b> Intervals of defined boundaries.</a></li>
<li class="chapter" data-level="3.2.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-mass."><i class="fa fa-check"></i><b>3.2.2</b> Intervals of defined mass.</a></li>
<li class="chapter" data-level="3.2.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#point-estimates."><i class="fa fa-check"></i><b>3.2.3</b> Point estimates.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-simulate-prediction"><i class="fa fa-check"></i><b>3.3</b> Sampling to simulate prediction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#dummy-data."><i class="fa fa-check"></i><b>3.3.1</b> Dummy data.</a></li>
<li class="chapter" data-level="3.3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#model-checking."><i class="fa fa-check"></i><b>3.3.2</b> Model checking.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#summary-lets-practice-in-brms"><i class="fa fa-check"></i><b>3.4</b> <del>Summary</del> Let’s practice in brms</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#reference-2"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>4</b> Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-models.html"><a href="linear-models.html#why-normal-distributions-are-normal"><i class="fa fa-check"></i><b>4.1</b> Why normal distributions are normal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linear-models.html"><a href="linear-models.html#normal-by-addition."><i class="fa fa-check"></i><b>4.1.1</b> Normal by addition.</a></li>
<li class="chapter" data-level="4.1.2" data-path="linear-models.html"><a href="linear-models.html#normal-by-multiplication."><i class="fa fa-check"></i><b>4.1.2</b> Normal by multiplication.</a></li>
<li class="chapter" data-level="4.1.3" data-path="linear-models.html"><a href="linear-models.html#normal-by-log-multiplication."><i class="fa fa-check"></i><b>4.1.3</b> Normal by log-multiplication.</a></li>
<li class="chapter" data-level="4.1.4" data-path="linear-models.html"><a href="linear-models.html#using-gaussian-distributions."><i class="fa fa-check"></i><b>4.1.4</b> Using Gaussian distributions.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-models.html"><a href="linear-models.html#a-language-for-describing-models"><i class="fa fa-check"></i><b>4.2</b> A language for describing models</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-models.html"><a href="linear-models.html#re-describing-the-globe-tossing-model."><i class="fa fa-check"></i><b>4.2.1</b> Re-describing the globe tossing model.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-models.html"><a href="linear-models.html#a-gaussian-model-of-height"><i class="fa fa-check"></i><b>4.3</b> A Gaussian model of height</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linear-models.html"><a href="linear-models.html#the-data."><i class="fa fa-check"></i><b>4.3.1</b> The data.</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-models.html"><a href="linear-models.html#the-model."><i class="fa fa-check"></i><b>4.3.2</b> The model.</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-models.html"><a href="linear-models.html#grid-approximation-of-the-posterior-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Grid approximation of the posterior distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="linear-models.html"><a href="linear-models.html#sampling-from-the-posterior."><i class="fa fa-check"></i><b>4.3.4</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="4.3.5" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model-with-map-brm."><i class="fa fa-check"></i><b>4.3.5</b> Fitting the model with <del><code>map()</code></del> <code>brm()</code>.</a></li>
<li class="chapter" data-level="4.3.6" data-path="linear-models.html"><a href="linear-models.html#sampling-from-a-map-brm-fit."><i class="fa fa-check"></i><b>4.3.6</b> Sampling from a <del><code>map()</code></del> <code>brm()</code> fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-models.html"><a href="linear-models.html#adding-a-predictor"><i class="fa fa-check"></i><b>4.4</b> Adding a predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="linear-models.html"><a href="linear-models.html#the-linear-model-strategy"><i class="fa fa-check"></i><b>4.4.1</b> The linear model strategy</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model."><i class="fa fa-check"></i><b>4.4.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="4.4.3" data-path="linear-models.html"><a href="linear-models.html#interpreting-the-model-fit."><i class="fa fa-check"></i><b>4.4.3</b> Interpreting the model fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-models.html"><a href="linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>4.5</b> Polynomial regression</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#reference-3"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html"><i class="fa fa-check"></i><b>5</b> Multivariate Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#spurious-associations"><i class="fa fa-check"></i><b>5.1</b> Spurious associations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multivariate-notation."><i class="fa fa-check"></i><b>5.1.1</b> Multivariate notation.</a></li>
<li class="chapter" data-level="5.1.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#fitting-the-model.-1"><i class="fa fa-check"></i><b>5.1.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="5.1.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#plotting-multivariate-posteriors."><i class="fa fa-check"></i><b>5.1.3</b> Plotting multivariate posteriors.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#masked-relationship"><i class="fa fa-check"></i><b>5.2</b> Masked relationship</a></li>
<li class="chapter" data-level="5.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#when-adding-variables-hurts"><i class="fa fa-check"></i><b>5.3</b> When adding variables hurts</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-legs."><i class="fa fa-check"></i><b>5.3.1</b> Multicollinear legs.</a></li>
<li class="chapter" data-level="5.3.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-milk."><i class="fa fa-check"></i><b>5.3.2</b> Multicollinear <code>milk</code>.</a></li>
<li class="chapter" data-level="5.3.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#post-treatment-bias."><i class="fa fa-check"></i><b>5.3.3</b> Post-treatment bias.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#categorical-varaibles"><i class="fa fa-check"></i><b>5.4</b> Categorical varaibles</a><ul>
<li class="chapter" data-level="5.4.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#binary-categories."><i class="fa fa-check"></i><b>5.4.1</b> Binary categories.</a></li>
<li class="chapter" data-level="5.4.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#many-categories."><i class="fa fa-check"></i><b>5.4.2</b> Many categories.</a></li>
<li class="chapter" data-level="5.4.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#adding-regular-predictor-variables."><i class="fa fa-check"></i><b>5.4.3</b> Adding regular predictor variables.</a></li>
<li class="chapter" data-level="5.4.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#another-approach-unique-intercepts."><i class="fa fa-check"></i><b>5.4.4</b> Another approach: Unique intercepts.</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#ordinary-least-squares-and-lm"><i class="fa fa-check"></i><b>5.5</b> <del>Ordinary least squares and <code>lm()</code></del></a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#reference-4"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html"><i class="fa fa-check"></i><b>6</b> Overfitting, Regularization, and Information Criteria</a><ul>
<li class="chapter" data-level="6.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#the-problem-with-parameters"><i class="fa fa-check"></i><b>6.1</b> The problem with parameters</a><ul>
<li class="chapter" data-level="6.1.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#more-parameters-always-improve-fit."><i class="fa fa-check"></i><b>6.1.1</b> More parameters always improve fit.</a></li>
<li class="chapter" data-level="6.1.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#too-few-parameters-hurts-too."><i class="fa fa-check"></i><b>6.1.2</b> Too few parameters hurts, too.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-theory-and-model-performance"><i class="fa fa-check"></i><b>6.2</b> Information theory and model performance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#firing-the-weatherperson."><i class="fa fa-check"></i><b>6.2.1</b> Firing the weatherperson.</a></li>
<li class="chapter" data-level="6.2.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-and-uncertainty."><i class="fa fa-check"></i><b>6.2.2</b> Information and uncertainty.</a></li>
<li class="chapter" data-level="6.2.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-entropy-to-accuracy."><i class="fa fa-check"></i><b>6.2.3</b> From entropy to accuracy.</a></li>
<li class="chapter" data-level="6.2.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-divergence-to-deviance."><i class="fa fa-check"></i><b>6.2.4</b> From divergence to deviance.</a></li>
<li class="chapter" data-level="6.2.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-deviance-to-out-of-sample."><i class="fa fa-check"></i><b>6.2.5</b> From deviance to out-of-sample.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#regularization"><i class="fa fa-check"></i><b>6.3</b> Regularization</a></li>
<li class="chapter" data-level="6.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-criteria"><i class="fa fa-check"></i><b>6.4</b> Information criteria</a><ul>
<li class="chapter" data-level="6.4.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic."><i class="fa fa-check"></i><b>6.4.1</b> DIC.</a></li>
<li class="chapter" data-level="6.4.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#waic."><i class="fa fa-check"></i><b>6.4.2</b> WAIC.</a></li>
<li class="chapter" data-level="6.4.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic-and-waic-as-estimates-of-deviance."><i class="fa fa-check"></i><b>6.4.3</b> DIC and WAIC as estimates of deviance.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#using-information-criteria"><i class="fa fa-check"></i><b>6.5</b> Using information criteria</a><ul>
<li class="chapter" data-level="6.5.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-comparison."><i class="fa fa-check"></i><b>6.5.1</b> Model comparison.</a></li>
<li class="chapter" data-level="6.5.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-averaging."><i class="fa fa-check"></i><b>6.5.2</b> Model averaging.</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#summary-bonus-r2-talk"><i class="fa fa-check"></i><b>6.6</b> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#reference-5"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>7</b> Interactions</a><ul>
<li class="chapter" data-level="7.1" data-path="interactions.html"><a href="interactions.html#building-an-interaction."><i class="fa fa-check"></i><b>7.1</b> Building an interaction.</a><ul>
<li class="chapter" data-level="7.1.1" data-path="interactions.html"><a href="interactions.html#adding-a-dummy-variable-doesnt-work."><i class="fa fa-check"></i><b>7.1.1</b> Adding a dummy variable doesn’t work.</a></li>
<li class="chapter" data-level="7.1.2" data-path="interactions.html"><a href="interactions.html#adding-a-linear-interaction-does-work."><i class="fa fa-check"></i><b>7.1.2</b> Adding a linear interaction does work.</a></li>
<li class="chapter" data-level="7.1.3" data-path="interactions.html"><a href="interactions.html#plotting-the-interaction."><i class="fa fa-check"></i><b>7.1.3</b> Plotting the interaction.</a></li>
<li class="chapter" data-level="7.1.4" data-path="interactions.html"><a href="interactions.html#interpreting-an-interaction-estimate."><i class="fa fa-check"></i><b>7.1.4</b> Interpreting an interaction estimate.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="interactions.html"><a href="interactions.html#symmetry-of-the-linear-interaction."><i class="fa fa-check"></i><b>7.2</b> Symmetry of the linear interaction.</a><ul>
<li class="chapter" data-level="7.2.1" data-path="interactions.html"><a href="interactions.html#buridans-interaction."><i class="fa fa-check"></i><b>7.2.1</b> Buridan’s interaction.</a></li>
<li class="chapter" data-level="7.2.2" data-path="interactions.html"><a href="interactions.html#africa-depends-upon-ruggedness."><i class="fa fa-check"></i><b>7.2.2</b> Africa depends upon ruggedness.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="interactions.html"><a href="interactions.html#continuous-interactions"><i class="fa fa-check"></i><b>7.3</b> Continuous interactions</a><ul>
<li class="chapter" data-level="7.3.1" data-path="interactions.html"><a href="interactions.html#the-data.-1"><i class="fa fa-check"></i><b>7.3.1</b> The data.</a></li>
<li class="chapter" data-level="7.3.2" data-path="interactions.html"><a href="interactions.html#the-un-centered-models."><i class="fa fa-check"></i><b>7.3.2</b> The un-centered models.</a></li>
<li class="chapter" data-level="7.3.3" data-path="interactions.html"><a href="interactions.html#center-and-re-estimate."><i class="fa fa-check"></i><b>7.3.3</b> Center and re-estimate.</a></li>
<li class="chapter" data-level="7.3.4" data-path="interactions.html"><a href="interactions.html#plotting-implied-predictions."><i class="fa fa-check"></i><b>7.3.4</b> Plotting implied predictions.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="interactions.html"><a href="interactions.html#interactions-in-design-formulas"><i class="fa fa-check"></i><b>7.4</b> Interactions in design formulas</a></li>
<li class="chapter" data-level="7.5" data-path="interactions.html"><a href="interactions.html#summary-bonus-marginal_effects"><i class="fa fa-check"></i><b>7.5</b> <del>Summary</del> Bonus: <code>marginal_effects()</code></a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#reference-6"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>8</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#good-king-markov-and-his-island-kingdom"><i class="fa fa-check"></i><b>8.1</b> Good King Markov and His island kingdom</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-1"><i class="fa fa-check"></i><b>8.2</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#easy-hmc-map2stan-brm"><i class="fa fa-check"></i><b>8.3</b> Easy HMC: <del>map2stan</del> <code>brm()</code></a><ul>
<li class="chapter" data-level="8.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#preparation."><i class="fa fa-check"></i><b>8.3.1</b> Preparation.</a></li>
<li class="chapter" data-level="8.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#estimation."><i class="fa fa-check"></i><b>8.3.2</b> Estimation.</a></li>
<li class="chapter" data-level="8.3.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-again-in-parallel."><i class="fa fa-check"></i><b>8.3.3</b> Sampling again, in parallel.</a></li>
<li class="chapter" data-level="8.3.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#visualization."><i class="fa fa-check"></i><b>8.3.4</b> Visualization.</a></li>
<li class="chapter" data-level="8.3.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#using-the-samples."><i class="fa fa-check"></i><b>8.3.5</b> Using the samples.</a></li>
<li class="chapter" data-level="8.3.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#checking-the-chain."><i class="fa fa-check"></i><b>8.3.6</b> Checking the chain.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#care-and-feeding-of-your-markov-chain."><i class="fa fa-check"></i><b>8.4</b> Care and feeding of your Markov chain.</a><ul>
<li class="chapter" data-level="8.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-samples-do-you-need"><i class="fa fa-check"></i><b>8.4.1</b> How many samples do you need?</a></li>
<li class="chapter" data-level="8.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-chains-do-you-need"><i class="fa fa-check"></i><b>8.4.2</b> How many chains do you need?</a></li>
<li class="chapter" data-level="8.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#taming-a-wild-chain."><i class="fa fa-check"></i><b>8.4.3</b> Taming a wild chain.</a></li>
<li class="chapter" data-level="8.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#non-identifiable-parameters."><i class="fa fa-check"></i><b>8.4.4</b> Non-identifiable parameters.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#reference-7"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>9</b> Big Entropy and the Generalized Linear Model</a><ul>
<li class="chapter" data-level="9.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#maximum-entropy"><i class="fa fa-check"></i><b>9.1</b> Maximum entropy</a><ul>
<li class="chapter" data-level="9.1.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#gaussian."><i class="fa fa-check"></i><b>9.1.1</b> Gaussian.</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#binomial."><i class="fa fa-check"></i><b>9.1.2</b> Binomial.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#generalized-linear-models"><i class="fa fa-check"></i><b>9.2</b> Generalized linear models</a><ul>
<li class="chapter" data-level="9.2.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#meet-the-family."><i class="fa fa-check"></i><b>9.2.1</b> Meet the family.</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions."><i class="fa fa-check"></i><b>9.2.2</b> Linking linear models to distributions.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#reference-8"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="counting-and-classification.html"><a href="counting-and-classification.html"><i class="fa fa-check"></i><b>10</b> Counting and Classification</a><ul>
<li class="chapter" data-level="10.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#binomial-regression"><i class="fa fa-check"></i><b>10.1</b> Binomial regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#logistic-regression-prosocial-chimpanzees."><i class="fa fa-check"></i><b>10.1.1</b> Logistic regression: Prosocial chimpanzees.</a></li>
<li class="chapter" data-level="10.1.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-chimpanzees-again-condensed."><i class="fa fa-check"></i><b>10.1.2</b> Aggregated binomial: Chimpanzees again, condensed.</a></li>
<li class="chapter" data-level="10.1.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-graduate-school-admissions."><i class="fa fa-check"></i><b>10.1.3</b> Aggregated binomial: Graduate school admissions.</a></li>
<li class="chapter" data-level="10.1.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#fitting-binomial-regressions-with-glm."><i class="fa fa-check"></i><b>10.1.4</b> Fitting binomial regressions with <code>glm()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#poisson-regression"><i class="fa fa-check"></i><b>10.2</b> Poisson regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-oceanic-tool-complexity."><i class="fa fa-check"></i><b>10.2.1</b> Example: Oceanic tool complexity.</a></li>
<li class="chapter" data-level="10.2.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#mcmc-islands."><i class="fa fa-check"></i><b>10.2.2</b> MCMC islands.</a></li>
<li class="chapter" data-level="10.2.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-exposure-and-the-offset."><i class="fa fa-check"></i><b>10.2.3</b> Example: Exposure and the offset.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#other-count-regressions"><i class="fa fa-check"></i><b>10.3</b> Other count regressions</a><ul>
<li class="chapter" data-level="10.3.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#multinomial."><i class="fa fa-check"></i><b>10.3.1</b> Multinomial.</a></li>
<li class="chapter" data-level="10.3.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#geometric."><i class="fa fa-check"></i><b>10.3.2</b> Geometric.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#reference-9"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html"><i class="fa fa-check"></i><b>11</b> Monsters and Mixtures</a><ul>
<li class="chapter" data-level="11.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-outcomes"><i class="fa fa-check"></i><b>11.1</b> Ordered categorical outcomes</a><ul>
<li class="chapter" data-level="11.1.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-moral-intuition."><i class="fa fa-check"></i><b>11.1.1</b> Example: Moral intuition.</a></li>
<li class="chapter" data-level="11.1.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#describing-an-ordered-distribution-with-intercepts."><i class="fa fa-check"></i><b>11.1.2</b> Describing an ordered distribution with intercepts.</a></li>
<li class="chapter" data-level="11.1.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#adding-predictor-variables."><i class="fa fa-check"></i><b>11.1.3</b> Adding predictor variables.</a></li>
<li class="chapter" data-level="11.1.4" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#bonus-figure-11.3-alternative."><i class="fa fa-check"></i><b>11.1.4</b> Bonus: Figure 11.3 alternative.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#zero-inflated-outcomes"><i class="fa fa-check"></i><b>11.2</b> Zero-inflated outcomes</a><ul>
<li class="chapter" data-level="11.2.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-zero-inflated-poisson."><i class="fa fa-check"></i><b>11.2.1</b> Example: Zero-inflated Poisson.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersed-outcomes"><i class="fa fa-check"></i><b>11.3</b> Over-dispersed outcomes</a><ul>
<li class="chapter" data-level="11.3.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#beta-binomial."><i class="fa fa-check"></i><b>11.3.1</b> Beta-binomial.</a></li>
<li class="chapter" data-level="11.3.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#negative-binomial-or-gamma-poisson."><i class="fa fa-check"></i><b>11.3.2</b> Negative-binomial or gamma-Poisson.</a></li>
<li class="chapter" data-level="11.3.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersion-entropy-and-information-criteria."><i class="fa fa-check"></i><b>11.3.3</b> Over-dispersion, entropy, and information criteria.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#reference-10"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>12</b> Multilevel Models</a><ul>
<li class="chapter" data-level="12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-multilevel-tadpoles"><i class="fa fa-check"></i><b>12.1</b> Example: Multilevel tadpoles</a></li>
<li class="chapter" data-level="12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>12.2</b> Varying effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multilevel-models.html"><a href="multilevel-models.html#the-model.-1"><i class="fa fa-check"></i><b>12.2.1</b> The model.</a></li>
<li class="chapter" data-level="12.2.2" data-path="multilevel-models.html"><a href="multilevel-models.html#assign-values-to-the-parameters."><i class="fa fa-check"></i><b>12.2.2</b> Assign values to the parameters.</a></li>
<li class="chapter" data-level="12.2.3" data-path="multilevel-models.html"><a href="multilevel-models.html#sumulate-survivors."><i class="fa fa-check"></i><b>12.2.3</b> Sumulate survivors.</a></li>
<li class="chapter" data-level="12.2.4" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-no-pooling-estimates."><i class="fa fa-check"></i><b>12.2.4</b> Compute the no-pooling estimates.</a></li>
<li class="chapter" data-level="12.2.5" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-partial-pooling-estimates."><i class="fa fa-check"></i><b>12.2.5</b> Compute the partial-pooling estimates.</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multilevel-models.html"><a href="multilevel-models.html#more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>12.3</b> More than one type of cluster</a><ul>
<li class="chapter" data-level="12.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-chimpanzees."><i class="fa fa-check"></i><b>12.3.1</b> Multilevel chimpanzees.</a></li>
<li class="chapter" data-level="12.3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#two-types-of-cluster."><i class="fa fa-check"></i><b>12.3.2</b> Two types of cluster.</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-posterior-predictions"><i class="fa fa-check"></i><b>12.4</b> Multilevel posterior predictions</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-same-clusters."><i class="fa fa-check"></i><b>12.4.1</b> Posterior prediction for same clusters.</a></li>
<li class="chapter" data-level="12.4.2" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-new-clusters."><i class="fa fa-check"></i><b>12.4.2</b> Posterior prediction for new clusters.</a></li>
<li class="chapter" data-level="12.4.3" data-path="multilevel-models.html"><a href="multilevel-models.html#focus-and-multilevel-prediction."><i class="fa fa-check"></i><b>12.4.3</b> Focus and multilevel prediction.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#reference-11"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html"><i class="fa fa-check"></i><b>13</b> Adventures in Covariance</a><ul>
<li class="chapter" data-level="13.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-slopes-by-construction"><i class="fa fa-check"></i><b>13.1</b> Varying slopes by construction</a><ul>
<li class="chapter" data-level="13.1.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-the-population."><i class="fa fa-check"></i><b>13.1.1</b> Simulate the population.</a></li>
<li class="chapter" data-level="13.1.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-observations."><i class="fa fa-check"></i><b>13.1.2</b> Simulate observations.</a></li>
<li class="chapter" data-level="13.1.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#the-varying-slopes-model."><i class="fa fa-check"></i><b>13.1.3</b> The varying slopes model.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-admission-decisions-and-gender"><i class="fa fa-check"></i><b>13.2</b> Example: Admission decisions and gender</a><ul>
<li class="chapter" data-level="13.2.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-intercepts."><i class="fa fa-check"></i><b>13.2.1</b> Varying intercepts.</a></li>
<li class="chapter" data-level="13.2.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-effects-of-being-male."><i class="fa fa-check"></i><b>13.2.2</b> Varying effects of being <code>male</code>.</a></li>
<li class="chapter" data-level="13.2.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#shrinkage."><i class="fa fa-check"></i><b>13.2.3</b> Shrinkage.</a></li>
<li class="chapter" data-level="13.2.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#model-comparison.-1"><i class="fa fa-check"></i><b>13.2.4</b> Model comparison.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-cross-classified-chimpanzees-with-varying-slopes"><i class="fa fa-check"></i><b>13.3</b> Example: Cross-classified <code>chimpanzees</code> with varying slopes</a></li>
<li class="chapter" data-level="13.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#continuous-categories-and-the-gaussian-process"><i class="fa fa-check"></i><b>13.4</b> Continuous categories and the Gaussian process</a><ul>
<li class="chapter" data-level="13.4.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-spatial-autocorrelation-in-oceanic-tools."><i class="fa fa-check"></i><b>13.4.1</b> Example: Spatial autocorrelation in Oceanic tools.</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#summary-bonus-another-berkley-admissions-data-like-example."><i class="fa fa-check"></i><b>13.5</b> <del>Summary</del> Bonus: Another Berkley-admissions-data-like example.</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#reference-12"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html"><i class="fa fa-check"></i><b>14</b> Missing Data and Other Opportunities</a><ul>
<li class="chapter" data-level="14.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-error"><i class="fa fa-check"></i><b>14.1</b> Measurement error</a><ul>
<li class="chapter" data-level="14.1.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-the-outcome."><i class="fa fa-check"></i><b>14.1.1</b> Error on the outcome.</a></li>
<li class="chapter" data-level="14.1.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-both-outcome-and-predictor."><i class="fa fa-check"></i><b>14.1.2</b> Error on both outcome and predictor.</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#missing-data"><i class="fa fa-check"></i><b>14.2</b> Missing data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#imputing-neocortex"><i class="fa fa-check"></i><b>14.2.1</b> Imputing <code>neocortex</code></a></li>
<li class="chapter" data-level="14.2.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#improving-the-imputation-model"><i class="fa fa-check"></i><b>14.2.2</b> Improving the imputation model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#reference-13"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html"><i class="fa fa-check"></i><b>15</b> <del>Horoscopes</del> Insights</a><ul>
<li class="chapter" data-level="15.1" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-r-notebooks"><i class="fa fa-check"></i><b>15.1</b> Use R Notebooks</a></li>
<li class="chapter" data-level="15.2" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#save-your-model-fits"><i class="fa fa-check"></i><b>15.2</b> Save your model fits</a></li>
<li class="chapter" data-level="15.3" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#build-your-models-slowly"><i class="fa fa-check"></i><b>15.3</b> Build your models slowly</a></li>
<li class="chapter" data-level="15.4" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#look-at-your-data"><i class="fa fa-check"></i><b>15.4</b> Look at your data</a></li>
<li class="chapter" data-level="15.5" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-the-0-intercept-syntax"><i class="fa fa-check"></i><b>15.5</b> Use the <code>0 + intercept</code> syntax</a></li>
<li class="chapter" data-level="15.6" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-workflow"><i class="fa fa-check"></i><b>15.6</b> Annotate your workflow</a></li>
<li class="chapter" data-level="15.7" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-code"><i class="fa fa-check"></i><b>15.7</b> Annotate your code</a></li>
<li class="chapter" data-level="15.8" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#break-up-your-workflow"><i class="fa fa-check"></i><b>15.8</b> Break up your workflow</a></li>
<li class="chapter" data-level="15.9" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#read-gelmans-blog"><i class="fa fa-check"></i><b>15.9</b> Read Gelman’s blog</a></li>
<li class="chapter" data-level="15.10" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#check-out-other-social-media-too"><i class="fa fa-check"></i><b>15.10</b> Check out other social media, too</a></li>
<li class="chapter" data-level="15.11" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#parting-wisdom"><i class="fa fa-check"></i><b>15.11</b> Parting wisdom</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#reference-14"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical Rethinking</em> with brms, ggplot2, and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="missing-data-and-other-opportunities" class="section level1">
<h1><span class="header-section-number">14</span> Missing Data and Other Opportunities</h1>
<p>For the opening example, we’re playing with the conditional probability</p>
<p><span class="math display">\[
\text{Pr(burnt down | burnt up)} = \frac{\text{Pr(burnt up, burnt down)}}{\text{Pr(burnt up)}}
\]</span></p>
<p>It works out that</p>
<p><span class="math display">\[
\text{Pr(burnt down | burnt up)} = \frac{1/3}{1/2} = \frac{2}{3}
\]</span></p>
<p>We might express the math in the middle of page 423 in tibble form like this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)

p_pancake &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">3</span>

(
  d &lt;-
<span class="st">    </span><span class="kw">tibble</span>(<span class="dt">pancake    =</span> <span class="kw">c</span>(<span class="st">&quot;BB&quot;</span>, <span class="st">&quot;BU&quot;</span>, <span class="st">&quot;UU&quot;</span>),
           <span class="dt">p_burnt    =</span> <span class="kw">c</span>(<span class="dv">1</span>, .<span class="dv">5</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">p_burnt_up =</span> p_burnt <span class="op">*</span><span class="st"> </span>p_pancake)
) </code></pre></div>
<pre><code>## # A tibble: 3 x 3
##   pancake p_burnt p_burnt_up
##   &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;
## 1 BB          1        0.333
## 2 BU          0.5      0.167
## 3 UU          0        0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="st">`</span><span class="dt">p (burnt_down | burnt_up)</span><span class="st">`</span> =<span class="st"> </span>p_pancake <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(p_burnt_up))</code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   `p (burnt_down | burnt_up)`
##                         &lt;dbl&gt;
## 1                       0.667</code></pre>
<p>I understood McElreath’s simulation better after I broke it apart. The first part of <code>sim_pancake()</code> takes one random draw from the integers 1, 2, and 3. It just so happens that if we set <code>set.seed(1)</code>, the code returns a 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
<span class="kw">sample</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>So here’s what it looks like if we use seeds <code>2:11</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">take_sample &lt;-<span class="st"> </span><span class="cf">function</span>(seed){
 <span class="kw">set.seed</span>(seed)
  <span class="kw">sample</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">1</span>)
}

<span class="kw">tibble</span>(<span class="dt">seed =</span> <span class="dv">2</span><span class="op">:</span><span class="dv">11</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">value_returned =</span> <span class="kw">map</span>(seed, take_sample)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>()</code></pre></div>
<pre><code>## # A tibble: 10 x 2
##     seed value_returned
##    &lt;int&gt;          &lt;int&gt;
##  1     2              1
##  2     3              1
##  3     4              2
##  4     5              1
##  5     6              2
##  6     7              3
##  7     8              2
##  8     9              1
##  9    10              2
## 10    11              1</code></pre>
<p>Each of those <code>value_returned</code> values stands for one of the three pancakes: 1 = BB, 2 = BU, 3 = UU. In the next line, McElreath made slick use of a matrix to specify that. Here’s what the matrix looks like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]    1    1    0
## [2,]    1    0    0</code></pre>
<p>See how the three columns are identified as <code>[,1]</code>, <code>[,2]</code>, and <code>[,3]</code>? If, say, we wanted to subset the values in the second column, we’d execute</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)[, <span class="dv">2</span>]</code></pre></div>
<pre><code>## [1] 1 0</code></pre>
<p>which returns a numeric vector.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)[, <span class="dv">2</span>] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">str</span>()</code></pre></div>
<pre><code>##  num [1:2] 1 0</code></pre>
<p>And that <code>1 0</code> corresponds to the pancake with one burnt (i.e., 1) and one unburnt (i.e., 0) side. So when McElreath then executed <code>sample(sides)</code>, he randomly sampled from one of those two values. In the case of <code>pancake == 2</code>, he randomly sampled one the pancake with one burnt and one unburnt side. Had he sampled from <code>pancake == 1</code>, he would have sampled from the pancake with both sides burnt.</p>
<p>Going forward, let’s amend McElreath’s <code>sim_pancake()</code> function a bit. First, we’ll add a <code>seed</code> argument, with will allow us to make the output reproducible. We’ll be inserting <code>seed</code> into <code>set.seed()</code> in the two places preceding the <code>sample()</code> function. The second major change is that we’re going to convert the output of the <code>sim_pancake()</code> function to a tibble and adding a <code>side</code> column, which will contain the values <code>c(&quot;up&quot;, &quot;down&quot;)</code>. Just for pedagogical purposes, we’ll also add <code>pancake_n</code> and <code>pancake_chr</code> columns to help index which <code>pancake</code> the draws came from.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># simulate a pancake and return randomly ordered sides</span>
sim_pancake &lt;-<span class="st"> </span><span class="cf">function</span>(seed) {
  <span class="kw">set.seed</span>(seed)
  pancake &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dt">x =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">1</span>)
  sides   &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)[, pancake]
  
  <span class="kw">set.seed</span>(seed)
  <span class="kw">sample</span>(sides) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">side        =</span> <span class="kw">c</span>(<span class="st">&quot;up&quot;</span>, <span class="st">&quot;down&quot;</span>),
           <span class="dt">pancake_n   =</span> pancake,
           <span class="dt">pancake_chr =</span> <span class="kw">ifelse</span>(pancake <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="st">&quot;BB&quot;</span>,
                                <span class="kw">ifelse</span>(pancake <span class="op">==</span><span class="st"> </span><span class="dv">2</span>, <span class="st">&quot;BU&quot;</span>, <span class="st">&quot;UU&quot;</span>)))
}</code></pre></div>
<p>Let’s take this baby for a whirl.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># How many simulations would you like?</span>
n_sim &lt;-<span class="st"> </span><span class="fl">1e4</span>

(
  d &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">seed =</span> <span class="dv">1</span><span class="op">:</span>n_sim) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">r =</span> <span class="kw">map</span>(seed, sim_pancake)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>()
  )</code></pre></div>
<pre><code>## # A tibble: 20,000 x 5
##     seed value side  pancake_n pancake_chr
##    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;     &lt;int&gt; &lt;chr&gt;      
##  1     1     1 up            1 BB         
##  2     1     1 down          1 BB         
##  3     2     1 up            1 BB         
##  4     2     1 down          1 BB         
##  5     3     1 up            1 BB         
##  6     3     1 down          1 BB         
##  7     4     0 up            2 BU         
##  8     4     1 down          2 BU         
##  9     5     1 up            1 BB         
## 10     5     1 down          1 BB         
## # ... with 19,990 more rows</code></pre>
<p>And now we’ll <code>spread()</code> and <code>summarise()</code> to get the value we’ve been working for.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> side, <span class="dt">value =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="st">`</span><span class="dt">p (burnt_down | burnt_up)</span><span class="st">`</span> =<span class="st"> </span><span class="kw">sum</span>(up <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>down <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>( <span class="kw">sum</span>(up <span class="op">==</span><span class="st"> </span><span class="dv">1</span>)))</code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   `p (burnt_down | burnt_up)`
##                         &lt;dbl&gt;
## 1                       0.661</code></pre>
<p>The results are within rounding error of the ideal 2/3.</p>
<blockquote>
<p>Probability theory is not difficult mathematically. It’s just counting. But it is hard to interpret and apply. Doing so often seems to require some cleverness, and authors have an incentive to solve problems in clever ways, just to show off. But we don’t need that cleverness, if we ruthlessly apply conditional probability…</p>
<p>In this chapter, [we’ll] meet two commonplace applications of this assume-and-deduce strategy. The first is the incorporation of measurement error into our models. The second is the estimation of missing data through Bayesian imputation…</p>
<p>In neither application do [we] have to intuit the consequences of measurement errors nor the implications of missing values in order to design the models. All [we] have to do is state [the] information about the error or about the variables with missing values. Logic does the rest. (p. 424)</p>
</blockquote>
<div id="measurement-error" class="section level2">
<h2><span class="header-section-number">14.1</span> Measurement error</h2>
<p>First, let’s grab our <code>WaffleDivorce</code> data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">data</span>(WaffleDivorce)
d &lt;-<span class="st"> </span>WaffleDivorce
<span class="kw">rm</span>(WaffleDivorce)</code></pre></div>
<p>Switch out rethinking for brms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)</code></pre></div>
<p>The brms package currently supports <code>theme_black()</code>, which changes the default ggplot2 theme to a black background with white lines, text, and so forth. You can find the origins of the code, <a href="https://jonlefcheck.net/2013/03/11/black-theme-for-ggplot2-2/">here</a>.</p>
<p>Though I like the idea of brms including <code>theme_black()</code>, I’m not a fan of some of the default settings (e.g., it includes gridlines). Happily, data scientist <a href="https://github.com/trinker">Tyler Rinker</a> has some nice alternative <code>theme_black()</code> code you can find <a href="https://github.com/trinker/plotflow/blob/master/R/theme_black.R">here</a>. The version of <code>theme_black()</code> used for this chapter is based on his version, with a few amendments of my own.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">theme_black &lt;-<span class="st"> </span>
<span class="st">  </span><span class="cf">function</span>(<span class="dt">base_size=</span><span class="dv">12</span>, <span class="dt">base_family=</span><span class="st">&quot;&quot;</span>) {
    <span class="kw">theme_grey</span>(<span class="dt">base_size=</span>base_size, <span class="dt">base_family=</span>base_family) <span class="op">%+replace%</span>
<span class="st">        </span><span class="kw">theme</span>(
            <span class="co"># Specify axis options</span>
            <span class="dt">axis.line=</span><span class="kw">element_blank</span>(),
            <span class="co"># All text colors used to be &quot;grey55&quot;</span>
            <span class="dt">axis.text.x=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span><span class="fl">0.8</span>, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>,
                <span class="dt">lineheight=</span><span class="fl">0.9</span>, <span class="dt">vjust=</span><span class="dv">1</span>),
            <span class="dt">axis.text.y=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span><span class="fl">0.8</span>, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>,
                <span class="dt">lineheight=</span><span class="fl">0.9</span>,<span class="dt">hjust=</span><span class="dv">1</span>),
            <span class="dt">axis.ticks=</span><span class="kw">element_line</span>(<span class="dt">color=</span><span class="st">&quot;grey55&quot;</span>, <span class="dt">size =</span> <span class="fl">0.2</span>),
            <span class="dt">axis.title.x=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>, <span class="dt">vjust=</span><span class="dv">1</span>,
                <span class="dt">margin=</span>ggplot2<span class="op">::</span><span class="kw">margin</span>(.<span class="dv">5</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="st">&quot;lines&quot;</span>)),
            <span class="dt">axis.title.y=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>, <span class="dt">angle=</span><span class="dv">90</span>,
                <span class="dt">margin=</span>ggplot2<span class="op">::</span><span class="kw">margin</span>(.<span class="dv">5</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="st">&quot;lines&quot;</span>), <span class="dt">vjust=</span><span class="fl">0.5</span>),
            <span class="dt">axis.ticks.length=</span>grid<span class="op">::</span><span class="kw">unit</span>(<span class="fl">0.3</span>, <span class="st">&quot;lines&quot;</span>),

            <span class="co"># Specify legend options</span>
            <span class="dt">legend.background=</span><span class="kw">element_rect</span>(<span class="dt">color=</span><span class="ot">NA</span>, <span class="dt">fill=</span><span class="st">&quot;black&quot;</span>),
            <span class="dt">legend.key=</span><span class="kw">element_rect</span>(<span class="dt">color=</span><span class="st">&quot;grey55&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;black&quot;</span>),
            <span class="dt">legend.key.size=</span>grid<span class="op">::</span><span class="kw">unit</span>(<span class="fl">1.2</span>, <span class="st">&quot;lines&quot;</span>),
            <span class="dt">legend.key.height=</span><span class="ot">NULL</span>,
            <span class="dt">legend.key.width=</span><span class="ot">NULL</span>,
            <span class="dt">legend.text=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span><span class="fl">0.8</span>, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>),
            <span class="dt">legend.title=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span><span class="fl">0.8</span>, <span class="dt">face=</span><span class="st">&quot;bold&quot;</span>,<span class="dt">hjust=</span><span class="dv">0</span>,
                <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>),
            <span class="co"># legend.position=&quot;right&quot;,</span>
            <span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,
            <span class="dt">legend.text.align=</span><span class="ot">NULL</span>,
            <span class="dt">legend.title.align=</span><span class="ot">NULL</span>,
            <span class="dt">legend.direction=</span><span class="st">&quot;vertical&quot;</span>,
            <span class="dt">legend.box=</span><span class="ot">NULL</span>,
            <span class="co"># Specify panel options</span>
            <span class="dt">panel.background=</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&quot;black&quot;</span>, <span class="dt">color =</span> <span class="ot">NA</span>),
            <span class="dt">panel.border=</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="ot">NA</span>, <span class="dt">color=</span><span class="st">&quot;grey55&quot;</span>),
            <span class="dt">panel.grid.major=</span><span class="kw">element_blank</span>(),
            <span class="dt">panel.grid.minor=</span><span class="kw">element_blank</span>(),
            <span class="dt">panel.spacing=</span>grid<span class="op">::</span><span class="kw">unit</span>(<span class="fl">0.25</span>,<span class="st">&quot;lines&quot;</span>),
            <span class="co"># Specify facetting options</span>
            <span class="dt">strip.background=</span><span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">color=</span><span class="st">&quot;grey10&quot;</span>), <span class="co"># fill=&quot;grey30&quot;</span>
            <span class="dt">strip.text.x=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span><span class="fl">0.8</span>, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>),
            <span class="dt">strip.text.y=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span><span class="fl">0.8</span>, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>,
                <span class="dt">angle=</span><span class="op">-</span><span class="dv">90</span>),
            <span class="co"># Specify plot options</span>
            <span class="dt">plot.background=</span><span class="kw">element_rect</span>(<span class="dt">color=</span><span class="st">&quot;black&quot;</span>, <span class="dt">fill=</span><span class="st">&quot;black&quot;</span>),
            <span class="dt">plot.title=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span><span class="fl">1.2</span>, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>, <span class="dt">hjust =</span> <span class="dv">0</span>), <span class="co"># added hjust = 0</span>
            <span class="dt">plot.subtitle=</span><span class="kw">element_text</span>(<span class="dt">size=</span>base_size<span class="op">*</span>.<span class="dv">9</span>, <span class="dt">color=</span><span class="st">&quot;grey85&quot;</span>, <span class="dt">hjust =</span> <span class="dv">0</span>), <span class="co"># added line</span>
            <span class="co"># plot.margin=grid::unit(c(1, 1, 0.5, 0.5), &quot;lines&quot;)</span>
            <span class="dt">plot.margin=</span>grid<span class="op">::</span><span class="kw">unit</span>(<span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>), <span class="st">&quot;lines&quot;</span>)
    )
}</code></pre></div>
<p>One way to use our <code>theme_black()</code> is to make it part of the code for an individual plot, such as <code>ggplot() + geom_point() + theme_back()</code>. Another way is to make <code>theme_black()</code> the default setting with <code>bayesplot::theme_set()</code>. That’s the method we’ll use.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bayesplot)

<span class="kw">theme_set</span>(<span class="kw">theme_black</span>())

<span class="co"># To reset the default ggplot2 theme to its traditional parameters, use this code:</span>
<span class="co"># theme_set(theme_default()) </span></code></pre></div>
<p>In the <a href="https://cran.r-project.org/web/packages/brms/brms.pdf">brms reference manual</a>, Bürkner recommended complimenting <code>theme_black()</code> with color scheme “C” from the <a href="https://cran.r-project.org/web/packages/viridis/index.html">viridis package</a>, which provides a variety of <a href="https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html">colorblind-safe color palettes</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;viridis&quot;)</span>
<span class="kw">library</span>(viridis)</code></pre></div>
<p>The <code>viridis_pal()</code> function gives a list of colors within a given palette. The colors in each palette fall on a spectrum. Within <code>viridis_pal()</code>, the <code>option</code> argument allows one to select a given spectrum, “C”, in our case. The final parentheses, <code>()</code>, allows one to determine how many discrete colors one would like to break the spectrum up by. We’ll choose 7.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)</code></pre></div>
<pre><code>## [1] &quot;#0D0887FF&quot; &quot;#5D01A6FF&quot; &quot;#9C179EFF&quot; &quot;#CC4678FF&quot; &quot;#ED7953FF&quot; &quot;#FDB32FFF&quot; &quot;#F0F921FF&quot;</code></pre>
<p>With a little data wrangling, we can put the colors of our palette in a tibble and display them in a plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">color_number =</span> <span class="kw">str_c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>, <span class="st">&quot;. &quot;</span>, value),
         <span class="dt">number =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">factor</span>(<span class="dv">0</span>), <span class="dt">y =</span> <span class="kw">reorder</span>(color_number, number))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> <span class="kw">factor</span>(number))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="kw">factor</span>(number), <span class="dt">label =</span> color_number)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;black&quot;</span>, <span class="dt">times =</span> <span class="dv">4</span>), 
                                <span class="kw">rep</span>(<span class="st">&quot;white&quot;</span>, <span class="dt">times =</span> <span class="dv">3</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_viridis</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>, <span class="dt">discrete =</span> T, <span class="dt">direction =</span> <span class="op">-</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_discrete</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Behold: viridis C!&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-814-1.png" width="384" /></p>
<p>Now, let’s make use of our custom theme and reproduce/reimagine Figure 14.1.a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">7</span>]

d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> MedianAgeMarriage, 
             <span class="dt">y =</span> Divorce,
             <span class="dt">ymin =</span> Divorce <span class="op">-</span><span class="st"> </span>Divorce.SE, 
             <span class="dt">ymax =</span> Divorce <span class="op">+</span><span class="st"> </span>Divorce.SE)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">shape =</span> <span class="dv">20</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">color =</span> color) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Median age marriage&quot;</span> , 
       <span class="dt">y =</span> <span class="st">&quot;Divorce rate&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-815-1.png" width="384" /></p>
<p>Notice how <code>viridis_pal(option = &quot;C&quot;)(7)[7]</code> called the seventh color in the color scheme, <code>&quot;#F0F921FF&quot;</code>. For Figure 14.1.b, we’ll select the sixth color in the palette by coding <code>viridis_pal(option = &quot;C&quot;)(7)[6]</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">6</span>]

d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log</span>(Population), 
             <span class="dt">y =</span> Divorce,
             <span class="dt">ymin =</span> Divorce <span class="op">-</span><span class="st"> </span>Divorce.SE, 
             <span class="dt">ymax =</span> Divorce <span class="op">+</span><span class="st"> </span>Divorce.SE)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">shape =</span> <span class="dv">20</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">color =</span> color) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log population&quot;</span>, 
       <span class="dt">y =</span> <span class="st">&quot;Divorce rate&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-816-1.png" width="384" /></p>
<p>Just like in the text, our plot shows states with larger populations tend to have smaller measurement error.</p>
<div id="error-on-the-outcome." class="section level3">
<h3><span class="header-section-number">14.1.1</span> Error on the outcome.</h3>
<p>To get a better sense of what we’re about to do, imagine for a moment that each states’ divorce rate is normally distributed with a mean of <code>Divorce</code> and standard deviation <code>Divorce.SE</code>. Those distributions would be:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Divorce_distribution =</span> <span class="kw">str_c</span>(<span class="st">&quot;Divorce ~ Normal(&quot;</span>, Divorce, <span class="st">&quot;, &quot;</span>, Divorce.SE, <span class="st">&quot;)&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(Loc, Divorce_distribution) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>()</code></pre></div>
<pre><code>##   Loc         Divorce_distribution
## 1  AL Divorce ~ Normal(12.7, 0.79)
## 2  AK Divorce ~ Normal(12.5, 2.05)
## 3  AZ Divorce ~ Normal(10.8, 0.74)
## 4  AR Divorce ~ Normal(13.5, 1.22)
## 5  CA    Divorce ~ Normal(8, 0.24)
## 6  CO Divorce ~ Normal(11.6, 0.94)</code></pre>
<p>As in the text</p>
<blockquote>
<p>In [the following] example we’ll use a Gaussian distribution with mean equal to the observed value and standard deviation equal to the measurement’s standard error. This is the logical choice, because if all we know about the error is its standard deviation, then the maximum entropy distribution for it will be Gaussian…</p>
<p>Here’s how to define the distribution for each divorce rate. For each observed value <span class="math inline">\(D_{\text{OBS}i}\)</span>, there will be one parameter, <span class="math inline">\(D_{\text{EST}i}\)</span>, defined by:</p>
<p><span class="math display">\[D_{\text{OBS}i} \sim \text{Normal} (D_{\text{EST}i}, D_{\text{SE}i})\]</span></p>
<p>All this does is define the measurement <span class="math inline">\(D_{\text{OBS}i}\)</span> as having the specified Gaussian distribution centered on the unknown parameter <span class="math inline">\(D_{\text{EST}i}\)</span>. So the above defines a probability for each State <span class="math inline">\(i\)</span>’s observed divorce rate, given a known measurement error. (pp. 426–427)</p>
</blockquote>
<p>Now we’re ready to fit some models. In brms, there are at least two ways to accommodate measurement error in the criterion. The first way uses the <code>se()</code> syntax, following the form <code>&lt;response&gt; | se(&lt;se_response&gt;, sigma = TRUE)</code>. With this syntax, <code>se</code> stands for standard error, the loose frequentist analogue to the Bayesian posterior <span class="math inline">\(SD\)</span>. Unless you’re <a href="https://vuorre.netlify.com/post/2016/2016-09-29-bayesian-meta-analysis/">fitting a meta-analysis</a> on summary information, make sure to specify <code>sigma = TRUE</code>. Without that you’ll have no estimate for <span class="math inline">\(\sigma\)</span>! For more information on the <code>se()</code> method, go to the <a href="https://cran.r-project.org/web/packages/brms/brms.pdf">brms reference manual</a> and find the <em>Additional response information</em> subsection of the <code>brmsformula</code> section.</p>
<p>The second way uses the <code>mi()</code> syntax, following the form <code>&lt;response&gt; | mi(&lt;se_response&gt;)</code>. This follows a missing data logic, resulting in Bayesian missing data imputation for the criterion values. The <code>mi()</code> syntax is based on the newer missing data capabilities for brms. We will cover that in more detail in the second half of this chapter.</p>
<p>We’ll start off useing both methods. Our first model, <code>b14.1_se</code>, will follow the <code>se()</code> syntax; the second model, <code>b14.1_mi</code>, will follow the <code>mi()</code> syntax.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Put the data into a list</span>
dlist &lt;-<span class="st"> </span><span class="kw">list</span>(
    <span class="dt">div_obs =</span> d<span class="op">$</span>Divorce,
    <span class="dt">div_sd  =</span> d<span class="op">$</span>Divorce.SE,
    <span class="dt">R       =</span> d<span class="op">$</span>Marriage,
    <span class="dt">A       =</span> d<span class="op">$</span>MedianAgeMarriage)

<span class="co"># Here we specify the initial (i.e., starting) values</span>
inits      &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Yl =</span> dlist<span class="op">$</span>div_obs)
inits_list &lt;-<span class="st"> </span><span class="kw">list</span>(inits, inits)

<span class="co"># Fit the models</span>
b14.1_se &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> dlist, <span class="dt">family =</span> gaussian,
      div_obs <span class="op">|</span><span class="st"> </span><span class="kw">se</span>(div_sd, <span class="dt">sigma =</span> <span class="ot">TRUE</span>) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>intercept <span class="op">+</span><span class="st"> </span>R <span class="op">+</span><span class="st"> </span>A,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">5000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>,
                     <span class="dt">max_treedepth =</span> <span class="dv">12</span>),
      <span class="dt">inits =</span> inits_list)

b14.1_mi &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> dlist, <span class="dt">family =</span> gaussian,
      div_obs <span class="op">|</span><span class="st"> </span><span class="kw">mi</span>(div_sd) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>intercept <span class="op">+</span><span class="st"> </span>R <span class="op">+</span><span class="st"> </span>A,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">5000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>,
                     <span class="dt">max_treedepth =</span> <span class="dv">12</span>),
      <span class="dt">save_mevars =</span> <span class="ot">TRUE</span>,  <span class="co"># note this line for the `mi()` model</span>
      <span class="dt">inits =</span> inits_list)</code></pre></div>
<p>Before we dive into the model summaries, notice how the starting values (i.e., <code>inits</code>) differ by model. Even though we coded <code>inits = inits_list</code> for both models, the differ by <code>fit@inits</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b14.1_se<span class="op">$</span>fit<span class="op">@</span>inits</code></pre></div>
<pre><code>## [[1]]
## [[1]]$b
## [1]  0.2068648 -0.1441787 -1.2745083
## 
## [[1]]$sigma
## [1] 2.84125
## 
## 
## [[2]]
## [[2]]$b
## [1] 1.6530769 1.6304362 0.7857997
## 
## [[2]]$sigma
## [1] 1.833162</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b14.1_mi<span class="op">$</span>fit<span class="op">@</span>inits</code></pre></div>
<pre><code>## [[1]]
## [[1]]$Yl
##  [1] 12.7 12.5 10.8 13.5  8.0 11.6  6.7  8.9  6.3  8.5 11.5  8.3  7.7  8.0 11.0 10.2 10.6 12.6 11.0
## [20] 13.0  8.8  7.8  9.2  7.4 11.1  9.5  9.1  8.8 10.1  6.1 10.2  6.6  9.9  8.0  9.5 12.8 10.4  7.7
## [39]  9.4  8.1 10.9 11.4 10.0 10.2  9.6  8.9 10.0 10.9  8.3 10.3
## 
## [[1]]$b
## [1] -0.6843108  1.1501697  1.1976380
## 
## [[1]]$sigma
## [1] 0.4970607
## 
## 
## [[2]]
## [[2]]$Yl
##  [1] 12.7 12.5 10.8 13.5  8.0 11.6  6.7  8.9  6.3  8.5 11.5  8.3  7.7  8.0 11.0 10.2 10.6 12.6 11.0
## [20] 13.0  8.8  7.8  9.2  7.4 11.1  9.5  9.1  8.8 10.1  6.1 10.2  6.6  9.9  8.0  9.5 12.8 10.4  7.7
## [39]  9.4  8.1 10.9 11.4 10.0 10.2  9.6  8.9 10.0 10.9  8.3 10.3
## 
## [[2]]$b
## [1]  0.6437190 -0.8064231  0.1724876
## 
## [[2]]$sigma
## [1] 0.4096365</code></pre>
<p>As we explore further, it should become apparent why. Here are the primary model summaries.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b14.1_se)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: div_obs | se(div_sd, sigma = TRUE) ~ 0 + intercept + R + A 
##    Data: dlist (Number of observations: 50) 
## Samples: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## intercept    21.33      6.88     6.92    34.16       1713 1.00
## R             0.13      0.08    -0.02     0.28       2190 1.00
## A            -0.55      0.22    -0.96    -0.08       1772 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     1.13      0.22     0.75     1.60       2493 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b14.1_mi)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: div_obs | mi(div_sd) ~ 0 + intercept + R + A 
##    Data: dlist (Number of observations: 50) 
## Samples: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## intercept    21.35      6.60     7.97    33.82       2702 1.00
## R             0.13      0.08    -0.02     0.28       3008 1.00
## A            -0.55      0.21    -0.95    -0.11       2811 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     1.13      0.21     0.75     1.58       2386 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Based on the <code>print()</code>/<code>summary()</code> information, the main parameters for the models are about the same. However, the plot deepens when we summarize the models with the <code>broom::tidy()</code> method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(broom)

<span class="kw">tidy</span>(b14.1_se) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##          term estimate std.error   lower   upper
## 1 b_intercept    21.33      6.88    9.83   32.39
## 2         b_R     0.13      0.08    0.00    0.26
## 3         b_A    -0.55      0.22   -0.90   -0.17
## 4       sigma     1.13      0.22    0.80    1.51
## 5        lp__  -105.45      1.54 -108.38 -103.71</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(b14.1_mi) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##           term estimate std.error   lower   upper
## 1  b_intercept    21.35      6.60    9.93   31.88
## 2          b_R     0.13      0.08    0.00    0.26
## 3          b_A    -0.55      0.21   -0.89   -0.18
## 4        sigma     1.13      0.21    0.81    1.50
## 5        Yl[1]    11.79      0.68   10.69   12.92
## 6        Yl[2]    11.18      1.05    9.44   12.93
## 7        Yl[3]    10.46      0.62    9.45   11.48
## 8        Yl[4]    12.34      0.87   10.96   13.81
## 9        Yl[5]     8.05      0.24    7.66    8.44
## 10       Yl[6]    11.01      0.74    9.81   12.24
## 11       Yl[7]     7.24      0.64    6.18    8.26
## 12       Yl[8]     9.35      0.91    7.87   10.84
## 13       Yl[9]     7.00      1.09    5.21    8.82
## 14      Yl[10]     8.54      0.31    8.03    9.04
## 15      Yl[11]    11.15      0.53   10.28   12.02
## 16      Yl[12]     9.09      0.90    7.59   10.56
## 17      Yl[13]     9.69      0.91    8.16   11.19
## 18      Yl[14]     8.11      0.41    7.44    8.79
## 19      Yl[15]    10.69      0.55    9.78   11.60
## 20      Yl[16]    10.16      0.71    9.02   11.31
## 21      Yl[17]    10.51      0.78    9.22   11.79
## 22      Yl[18]    11.94      0.66   10.87   13.04
## 23      Yl[19]    10.48      0.70    9.32   11.64
## 24      Yl[20]    10.17      1.01    8.58   11.87
## 25      Yl[21]     8.75      0.59    7.80    9.72
## 26      Yl[22]     7.77      0.47    6.99    8.55
## 27      Yl[23]     9.15      0.49    8.35    9.96
## 28      Yl[24]     7.73      0.54    6.83    8.62
## 29      Yl[25]    10.44      0.77    9.17   11.71
## 30      Yl[26]     9.54      0.58    8.58   10.49
## 31      Yl[27]     9.44      0.99    7.80   11.08
## 32      Yl[28]     9.27      0.74    8.02   10.45
## 33      Yl[29]     9.18      0.94    7.66   10.75
## 34      Yl[30]     6.38      0.44    5.66    7.11
## 35      Yl[31]     9.97      0.78    8.70   11.26
## 36      Yl[32]     6.69      0.31    6.18    7.20
## 37      Yl[33]     9.88      0.44    9.17   10.61
## 38      Yl[34]     9.74      0.99    8.07   11.33
## 39      Yl[35]     9.43      0.42    8.73   10.11
## 40      Yl[36]    11.96      0.78   10.68   13.27
## 41      Yl[37]    10.08      0.65    9.00   11.16
## 42      Yl[38]     7.79      0.40    7.13    8.45
## 43      Yl[39]     8.21      1.03    6.57    9.96
## 44      Yl[40]     8.40      0.61    7.39    9.38
## 45      Yl[41]    10.01      1.06    8.28   11.75
## 46      Yl[42]    10.94      0.63    9.93   11.97
## 47      Yl[43]    10.02      0.34    9.45   10.59
## 48      Yl[44]    11.08      0.79    9.75   12.38
## 49      Yl[45]     8.90      1.02    7.25   10.62
## 50      Yl[46]     8.99      0.47    8.21    9.77
## 51      Yl[47]     9.95      0.57    9.04   10.91
## 52      Yl[48]    10.63      0.88    9.18   12.08
## 53      Yl[49]     8.47      0.51    7.63    9.31
## 54      Yl[50]    11.49      1.11    9.67   13.28
## 55        lp__  -152.80      6.57 -163.98 -142.45</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># you can get similar output with b14.1_mi$fit</span></code></pre></div>
<p>Again, from <code>b_intercept</code> to <code>sigma</code>, the output is about the same. But model <code>b14.1_mi</code>, based on the <code>mi()</code> syntax, contained posterior summaries for all 50 of the criterion values. The <code>se()</code> method gave us similar model result, but no posterior summaries for the 50 criterion values. The rethinking package indexed those additional 50 as <code>div_est[i]</code>; with the <code>mi()</code> method, brms indexed them as <code>Yl[i]</code>–no big deal. So while both brms methods accommodated measurement error, the <code>mi()</code> method appears to be the brms analogue to what McElreath did with his model <code>m14.1</code> in the text. Thus, it’s our <code>b14.1_mi</code> model that follows the form</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{Divorce}_{\text{estimated}, i} &amp; \sim &amp; \text{Normal} (\mu_i, \sigma) \\
\mu &amp; = &amp; \alpha + \beta_1 \text A_i + \beta_2 \text R_i \\
\text{Divorce}_{\text{observed}, i} &amp; \sim &amp; \text{Normal} (\text{Divorce}_{\text{estimated}, i}, \text{Divorce}_{\text{standard error}, i}) \\
\alpha &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta_1 &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta_2 &amp; \sim &amp; \text{Normal} (0, 10) \\
\sigma &amp; \sim &amp; \text{HalfCauchy} (0, 2.5)
\end{eqnarray}
\]</span></p>
<p><em>Note</em>. The <code>normal(0, 10)</code> prior McElreath used was <a href="https://github.com/paul-buerkner/brms/issues/114">quite informative and can lead to discrepancies between the rethinking and brms results</a> if you’re not careful. A large issue is the default way brms handles intercept priors. From the hyperlink, Bürkner wrote:</p>
<blockquote>
<p>The formula for the original intercept is <code>b_intercept = temp_intercept - dot_product(means_X, b)</code>, where <code>means_X</code> is the vector of means of the predictor variables and b is the vector of regression coefficients (fixed effects). That is, when transforming a prior on the intercept to an “equivalent” prior on the temporary intercept, you have to take the means of the predictors and well as the priors on the other coefficients into account.</p>
</blockquote>
<p>If this seems confusing, you have an alternative. The <code>0 + intercept</code> part of the brm formula kept the intercept in the metric of the untransformed data, leading to similar results to those from rethinking. When your priors are vague, this might not be much of an issue. And since many of the models in <em>Statistical Rethinking</em> use only weakly-regularizing priors, this hasn’t been much of an issue up to this point. But this model is quite sensitive to the intercept syntax. My general recommendation for applied data analysis is this: <strong>If your predictors aren’t mean centered, default to the</strong> <code>0 + intercept</code> <strong>syntax for the</strong> <code>formula</code> <strong>argument when using</strong> <code>brms::brm()</code>. Otherwise, your priors might not be doing what you think they’re doing.</p>
<p>Anyway, since our <code>mi()</code>-syntax <code>b14.1_mi</code> model appears to be the analogue to McElreath’s <code>m14.1</code>, we’ll use that one for our plots. Here’s our Figure 14.2.a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_error &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">fitted</span>(b14.1_mi) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(d)

color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">5</span>]

data_error <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Divorce.SE, <span class="dt">y =</span> Estimate <span class="op">-</span><span class="st"> </span>Divorce)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> color)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-821-1.png" width="384" /></p>
<p>Before we make Figure 14.2.b, we need to fit a model that ignores measurement error.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b14.1b &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> dlist, <span class="dt">family =</span> gaussian,
      div_obs <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>intercept <span class="op">+</span><span class="st"> </span>R <span class="op">+</span><span class="st"> </span>A,              
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">chains =</span> <span class="dv">2</span>, <span class="dt">iter =</span> <span class="dv">5000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">2</span>,
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.95</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b14.1b)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: div_obs ~ 0 + intercept + R + A 
##    Data: dlist (Number of observations: 50) 
## Samples: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## intercept    35.66      7.71    20.54    50.52       1986 1.00
## R            -0.05      0.08    -0.20     0.11       2372 1.00
## A            -0.96      0.25    -1.43    -0.48       2053 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     1.51      0.16     1.24     1.86       3489 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>With the ignore-measurement-error fit in hand, we’re ready for Figure 14.2.b.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nd &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">R      =</span> <span class="kw">mean</span>(d<span class="op">$</span>Marriage),
         <span class="dt">A      =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">22</span>, <span class="dt">to =</span> <span class="fl">30.2</span>, <span class="dt">length.out =</span> <span class="dv">30</span>),
         <span class="dt">div_sd =</span> <span class="kw">mean</span>(d<span class="op">$</span>Divorce.SE))

<span class="co"># red line</span>
fitd_error &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">fitted</span>(b14.1_mi, <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd)

<span class="co"># yellow line</span>
fitd_no_error &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">fitted</span>(b14.1b, <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd)

<span class="co"># white dots</span>
data_error &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">fitted</span>(b14.1_mi) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(b14.1_mi<span class="op">$</span>data)

color_y &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">7</span>]
color_r &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">4</span>]

<span class="co"># plot</span>
fitd_error <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> A, <span class="dt">y =</span> Estimate)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> fitd_no_error,
              <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2.<span class="dv">5</span>, <span class="dt">ymax =</span> Q97.<span class="dv">5</span>),
              <span class="dt">fill =</span> color_y, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> fitd_no_error,
            <span class="dt">color =</span> color_y, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> fitd_error,
              <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2.<span class="dv">5</span>, <span class="dt">ymax =</span> Q97.<span class="dv">5</span>),
              <span class="dt">fill =</span> color_r, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> fitd_error,
            <span class="dt">color =</span> color_r) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">data =</span> data_error,
                  <span class="kw">aes</span>(<span class="dt">ymin =</span> Estimate <span class="op">-</span><span class="st"> </span>Est.Error,
                      <span class="dt">ymax =</span> Estimate <span class="op">+</span><span class="st"> </span>Est.Error),
                  <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">shape =</span> <span class="dv">20</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">4</span>, <span class="dt">to =</span> <span class="dv">14</span>, <span class="dt">by =</span> <span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Median age marriage&quot;</span> , <span class="dt">y =</span> <span class="st">&quot;Divorce rate (posterior)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(data_error<span class="op">$</span>A), 
                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">15</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-823-1.png" width="384" /></p>
<p>In our plot, it’s the reddish regression line that accounts for measurement error.</p>
</div>
<div id="error-on-both-outcome-and-predictor." class="section level3">
<h3><span class="header-section-number">14.1.2</span> Error on both outcome and predictor.</h3>
<p>In brms, you can specify error on predictors with an <code>me()</code> statement in the form of <code>me(predictor, sd_predictor)</code> where <code>sd_predictor</code> is a vector in the data denoting the size of the measurement error, presumed to be in a standard-deviation metric.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The data</span>
dlist &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">div_obs =</span> d<span class="op">$</span>Divorce,
  <span class="dt">div_sd  =</span> d<span class="op">$</span>Divorce.SE,
  <span class="dt">mar_obs =</span> d<span class="op">$</span>Marriage,
  <span class="dt">mar_sd  =</span> d<span class="op">$</span>Marriage.SE,
  <span class="dt">A       =</span> d<span class="op">$</span>MedianAgeMarriage)

<span class="co"># The `inits`</span>
inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Yl =</span> dlist<span class="op">$</span>div_obs)
inits_list &lt;-<span class="st"> </span><span class="kw">list</span>(inits, inits)

<span class="co"># The models</span>
b14.2_se &lt;-
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> dlist, <span class="dt">family =</span> gaussian,
      div_obs <span class="op">|</span><span class="st"> </span><span class="kw">se</span>(div_sd, <span class="dt">sigma =</span> <span class="ot">TRUE</span>) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>intercept <span class="op">+</span><span class="st"> </span><span class="kw">me</span>(mar_obs, mar_sd) <span class="op">+</span><span class="st"> </span>A,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">5000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">3</span>, <span class="dt">cores =</span> <span class="dv">3</span>,
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.95</span>),
      <span class="dt">save_mevars =</span> <span class="ot">TRUE</span>) <span class="co"># Note the lack if `inits`. See below.</span>

b14.2_mi &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> dlist, <span class="dt">family =</span> gaussian,
      div_obs <span class="op">|</span><span class="st"> </span><span class="kw">mi</span>(div_sd) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>intercept <span class="op">+</span><span class="st"> </span><span class="kw">me</span>(mar_obs, mar_sd) <span class="op">+</span><span class="st"> </span>A,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="fl">2.5</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">5000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">2</span>, <span class="dt">chains =</span> <span class="dv">2</span>,
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>,
                     <span class="dt">max_treedepth =</span> <span class="dv">12</span>),
      <span class="dt">save_mevars =</span> <span class="ot">TRUE</span>,
      <span class="dt">inits =</span> inits_list)</code></pre></div>
<p>We already know including <code>inits</code> values for our <code>Yl[i]</code> estimates is a waste of time for our <code>se()</code> model. But note how we still defined our <code>inits</code> values as <code>inits &lt;- list(Yl = dlist$div_obs)</code> for the <code>mi()</code> model. Although it’s easy in brms to set the starting values for our <code>Yl[i]</code> estimates, much the way McElreath did, that isn’t the case when you have measurement error on the predictors. The brms package uses a non-centered parameterization for these, which requires users to have a deeper understanding of the underlying Stan code. This is where I get off the train, but if you want to go further, execute <code>stancode(b14.2_mi)</code>.</p>
<p>Here’s the two versions of the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b14.2_se)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: div_obs | se(div_sd, sigma = TRUE) ~ 0 + intercept + me(mar_obs, mar_sd) + A 
##    Data: dlist (Number of observations: 50) 
## Samples: 3 chains, each with iter = 5000; warmup = 1000; thin = 1;
##          total post-warmup samples = 12000
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## intercept          15.65      6.80     2.44    29.11       5338 1.00
## A                  -0.44      0.20    -0.84    -0.05       6120 1.00
## memar_obsmar_sd     0.27      0.11     0.07     0.49       5237 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     0.99      0.21     0.61     1.45      12000 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b14.2_mi)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: div_obs | mi(div_sd) ~ 0 + intercept + me(mar_obs, mar_sd) + A 
##    Data: dlist (Number of observations: 50) 
## Samples: 2 chains, each with iter = 5000; warmup = 1000; thin = 1;
##          total post-warmup samples = 8000
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## intercept          15.69      6.86     2.19    28.99       1958 1.00
## A                  -0.44      0.21    -0.83    -0.03       2212 1.00
## memar_obsmar_sd     0.27      0.11     0.07     0.49       1949 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma     0.99      0.21     0.61     1.43       1786 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>We’ll use <code>broom::tidy()</code>, again, to get a sense of <code>depth=2</code> summaries.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(b14.2_se) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)

<span class="kw">tidy</span>(b14.2_mi) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<p>Due to space concerns, I’m not going to show the results, here. You can do that on your own. Both methods yielded the posteriors for <code>Xme_memar_obs[1]</code>, but only the <code>b14.2_mi</code> model based on the <code>mi()</code> syntax yielded posteriors for the criterion, the <code>Yl[i]</code> summaries.</p>
<p>Note that you’ll need to specify <code>save_mevars = TRUE</code> in the <code>brm()</code> function order to save the posterior samples of error-adjusted variables obtained by using the <code>me()</code> argument. Without doing so, functions like <code>predict()</code> may give you trouble.</p>
<p>Here is the code for Figure 14.3.a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_error &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b14.2_mi) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(d)

color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">3</span>]

data_error <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Divorce.SE, <span class="dt">y =</span> Estimate <span class="op">-</span><span class="st"> </span>Divorce)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> color)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-826-1.png" width="384" /></p>
<p>To get the posterior samples for error-adjusted <code>Marriage</code> rate, we’ll use <code>posterior_samples</code>. If you examine the object with <code>glimpse()</code>, you’ll notice 50 <code>Xme_memar_obsmar_sd[i]</code> vectors, with <span class="math inline">\(i\)</span> ranging from 1 to 50, each corresponding to one of the 50 states. With a little data wrangling, you can get the mean of each to put in a plot. Once we have those summaries, we can make our version of Figure 14.4.b.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color_y &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">7</span>]
color_p &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;C&quot;</span>)(<span class="dv">7</span>)[<span class="dv">2</span>]

<span class="kw">posterior_samples</span>(b14.2_mi) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="kw">starts_with</span>(<span class="st">&quot;Xme&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># This extracts the numerals from the otherwise cumbersome names in key and saves them as integers</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">str_extract</span>(key, <span class="st">&quot;</span><span class="ch">\\</span><span class="st">d+&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.integer</span>()) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(value)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(data_error) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mean, <span class="dt">y =</span> Estimate)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">xend =</span> Marriage, <span class="dt">yend =</span> Divorce),
               <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">color =</span> color_y) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Marriage, <span class="dt">y =</span> Divorce), 
             <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">color =</span> color_p) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">4</span>, <span class="dt">to =</span> <span class="dv">14</span>, <span class="dt">by =</span> <span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Marriage rate (posterior)&quot;</span> , <span class="dt">y =</span> <span class="st">&quot;Divorce rate (posterior)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="fl">14.5</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-827-1.png" width="384" /></p>
<p>The yellow points are model-implied; the purple ones are of the original data. It turns out our brms model regularized more aggressively than McElreath’s rethinking model. I’m unsure of why. If you understand the difference, <a href="https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/issues">please share with the rest of the class</a>.</p>
<p>Anyway,</p>
<blockquote>
<p>the big take home point for this section is that when you have a distribution of values, don’t reduce it down to a single value to use in a regression. Instead, use the entire distribution. Anytime we use an average value, discarding the uncertainty around that average, we risk overconfidence and spurious inference. This doesn’t only apply to measurement error, but also to cases which data are averaged before analysis.</p>
<p>Do not average. Instead, model. (p. 431)</p>
</blockquote>
</div>
</div>
<div id="missing-data" class="section level2">
<h2><span class="header-section-number">14.2</span> Missing data</h2>
<p>Starting with the developer’s version 2.1.2, (or the official <a href="https://cran.r-project.org/web/packages/brms/index.html">version 2.3.1 available on CRAN</a>) brms now supports Bayesian missing data imputation using adaptations of the <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html">multivariate syntax</a>. Bürkner’s <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html"><em>Handle Missing Values with brms</em> vignette</a> is quite helpful.</p>
<div id="imputing-neocortex" class="section level3">
<h3><span class="header-section-number">14.2.1</span> Imputing <code>neocortex</code></h3>
<p>Once again, here are the <code>milk</code> data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">data</span>(milk)
d &lt;-<span class="st"> </span>milk

d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">neocortex.prop =</span> neocortex.perc<span class="op">/</span><span class="dv">100</span>,
         <span class="dt">logmass        =</span> <span class="kw">log</span>(mass))</code></pre></div>
<p>Now we’ll switch out rethinking for brms and do a little data wrangling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)
<span class="kw">rm</span>(milk)

<span class="co"># prep data</span>
data_list &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">list</span>(
    <span class="dt">kcal      =</span> d<span class="op">$</span>kcal.per.g,
    <span class="dt">neocortex =</span> d<span class="op">$</span>neocortex.prop,
    <span class="dt">logmass   =</span> d<span class="op">$</span>logmass)</code></pre></div>
<p>Here’s the structure of our data list.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">data_list</code></pre></div>
<pre><code>## $kcal
##  [1] 0.49 0.51 0.46 0.48 0.60 0.47 0.56 0.89 0.91 0.92 0.80 0.46 0.71 0.71 0.73 0.68 0.72 0.97 0.79
## [20] 0.84 0.48 0.62 0.51 0.54 0.49 0.53 0.48 0.55 0.71
## 
## $neocortex
##  [1] 0.5516     NA     NA     NA     NA 0.6454 0.6454 0.6764     NA 0.6885 0.5885 0.6169 0.6032
## [14]     NA     NA 0.6997     NA 0.7041     NA 0.7340     NA 0.6753     NA 0.7126 0.7260     NA
## [27] 0.7024 0.7630 0.7549
## 
## $logmass
##  [1]  0.6678294  0.7371641  0.9202828  0.4824261  0.7839015  1.6582281  1.6808279  0.9202828
##  [9] -0.3424903 -0.3856625 -2.1202635 -0.7550226 -1.1394343 -0.5108256  1.2441546  0.4382549
## [17]  1.9572739  1.1755733  2.0719133  2.5095993  2.0268316  1.6808279  2.3721112  3.5689692
## [25]  4.3748761  4.5821062  3.7072104  3.4998354  4.0064237</code></pre>
<p>Our statistical model follows the form</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{kcal}_i &amp; \sim &amp; \text{Normal} (\mu_i, \sigma) \\
\mu_i &amp; = &amp; \alpha + \beta_1 \text{neocortex}_i + \beta_2 \text{logmass}_i \\
\text{neocortex}_i &amp; \sim &amp; \text{Normal} (\nu, \sigma_\text{neocortex}) \\
\alpha &amp; \sim &amp; \text{Normal} (0, 100) \\
\beta_1 &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta_2 &amp; \sim &amp; \text{Normal} (0, 10) \\
\sigma &amp; \sim &amp; \text{HalfCauchy} (0, 1) \\
\nu &amp; \sim &amp; \text{Normal} (0.5, 1) \\
\sigma_\text{neocortex} &amp; \sim &amp; \text{HalfCauchy} (0, 1)
\end{eqnarray}
\]</span></p>
<p>When writing a multivariate model in brms, I find it easier to save the model code by itself and then insert it into the <code>brm()</code> function. Otherwise, things get cluttered in a hurry.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b_model &lt;-<span class="st"> </span>
<span class="st">  </span><span class="co"># Here&#39;s the primary `kcal` model</span>
<span class="st">  </span><span class="kw">bf</span>(kcal      <span class="op">|</span><span class="st"> </span><span class="kw">mi</span>() <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">mi</span>(neocortex) <span class="op">+</span><span class="st"> </span>logmass) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="co"># Here&#39;s the model for the missing `neocortex` data </span>
<span class="st">  </span><span class="kw">bf</span>(neocortex <span class="op">|</span><span class="st"> </span><span class="kw">mi</span>() <span class="op">~</span><span class="st"> </span><span class="dv">1</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="co"># Here we set the residual correlations for the two models to zero</span>
<span class="st">  </span><span class="kw">set_rescor</span>(<span class="ot">FALSE</span>)</code></pre></div>
<p>Note the <code>mi(neocortex)</code> syntax in the <code>kcal</code> model. This indicates that the predictor, <code>neocortex</code>, has missing values that are themselves being modeled.</p>
<p>To get a sense of how to specify the priors for such a model, use the <code>get_prior()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">get_prior</span>(<span class="dt">data =</span> data_list, 
          <span class="dt">family =</span> gaussian,
          b_model)</code></pre></div>
<pre><code>##                 prior     class        coef group      resp dpar nlpar bound
## 1                             b                                             
## 2                     Intercept                                             
## 3                             b                        kcal                 
## 4                             b     logmass            kcal                 
## 5                             b mineocortex            kcal                 
## 6 student_t(3, 1, 10) Intercept                        kcal                 
## 7 student_t(3, 0, 10)     sigma                        kcal                 
## 8 student_t(3, 1, 10) Intercept                   neocortex                 
## 9 student_t(3, 0, 10)     sigma                   neocortex</code></pre>
<p>With the one-step Bayesian imputation procedure in brms, you might need to use the <code>resp</code> argument when specifying non-defaut priors.</p>
<p>Anyway, here we fit the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b14.<span class="dv">3</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> data_list, 
      <span class="dt">family =</span> gaussian,
      b_model,  <span class="co"># here we insert the model</span>
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept, <span class="dt">resp =</span> kcal),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="fl">0.5</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept, <span class="dt">resp =</span> neocortex),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>),  <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>),   <span class="dt">class =</span> sigma,     <span class="dt">resp =</span> kcal),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>),   <span class="dt">class =</span> sigma,     <span class="dt">resp =</span> neocortex)),
      <span class="dt">iter =</span> <span class="fl">1e4</span>, <span class="dt">chains =</span> <span class="dv">2</span>, <span class="dt">cores =</span> <span class="dv">2</span>)</code></pre></div>
<p>The imputed <code>neocortex</code> values are indexed by occasion number from the original data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(b14.<span class="dv">3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##                     term estimate std.error lower upper
## 1       b_kcal_Intercept    -0.53      0.48 -1.31  0.28
## 2  b_neocortex_Intercept     0.67      0.01  0.65  0.69
## 3         b_kcal_logmass    -0.07      0.02 -0.11 -0.03
## 4   bsp_kcal_mineocortex     1.90      0.74  0.63  3.11
## 5             sigma_kcal     0.13      0.02  0.10  0.18
## 6        sigma_neocortex     0.06      0.01  0.05  0.08
## 7       Ymi_neocortex[2]     0.63      0.05  0.55  0.72
## 8       Ymi_neocortex[3]     0.63      0.05  0.54  0.71
## 9       Ymi_neocortex[4]     0.62      0.05  0.54  0.71
## 10      Ymi_neocortex[5]     0.65      0.05  0.57  0.73
## 11      Ymi_neocortex[9]     0.70      0.05  0.62  0.78
## 12     Ymi_neocortex[14]     0.66      0.05  0.58  0.74
## 13     Ymi_neocortex[15]     0.69      0.05  0.61  0.77
## 14     Ymi_neocortex[17]     0.70      0.05  0.62  0.78
## 15     Ymi_neocortex[19]     0.71      0.05  0.63  0.79
## 16     Ymi_neocortex[21]     0.65      0.05  0.57  0.73
## 17     Ymi_neocortex[23]     0.66      0.05  0.58  0.74
## 18     Ymi_neocortex[26]     0.70      0.05  0.61  0.77
## 19                  lp__    40.38      4.33 32.60 46.75</code></pre>
<p>Here’s the model that drops the cases with NAs on <code>neocortex</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b14.3cc &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> data_list, 
      <span class="dt">family =</span> gaussian,
      kcal <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>neocortex <span class="op">+</span><span class="st"> </span>logmass,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="fl">1e4</span>, <span class="dt">chains =</span> <span class="dv">2</span>, <span class="dt">cores =</span> <span class="dv">2</span>)</code></pre></div>
<p>The parameters:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(b14.3cc) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##          term estimate std.error lower upper
## 1 b_Intercept    -1.06      0.58 -2.00 -0.12
## 2 b_neocortex     2.76      0.90  1.27  4.21
## 3   b_logmass    -0.10      0.03 -0.14 -0.05
## 4       sigma     0.14      0.03  0.10  0.19
## 5        lp__    -4.23      1.60 -7.33 -2.35</code></pre>
<p>In order to make our versions of Figure 14.4, we’ll need to do a little data wrangling with <code>fitted()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nd &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">neocortex =</span> <span class="kw">seq</span>(<span class="dt">from =</span> .<span class="dv">5</span>, <span class="dt">to =</span> .<span class="dv">85</span>, <span class="dt">length.out =</span> <span class="dv">30</span>),
         <span class="dt">logmass   =</span> <span class="kw">median</span>(data_list<span class="op">$</span>logmass))

f_b14.<span class="dv">3</span> &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b14.<span class="dv">3</span>, <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd)

f_b14.<span class="dv">3</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 30
## Variables: 10
## $ Estimate.kcal       &lt;dbl&gt; 0.3304664, 0.3533606, 0.3762547, 0.3991489, 0.4220431, 0.4449372, 0...
## $ Est.Error.kcal      &lt;dbl&gt; 0.12720301, 0.11846516, 0.10976767, 0.10112096, 0.09253927, 0.08404...
## $ Q2.5.kcal           &lt;dbl&gt; 0.07988178, 0.11954155, 0.16020737, 0.20032220, 0.24093396, 0.28176...
## $ Q97.5.kcal          &lt;dbl&gt; 0.5912997, 0.5955131, 0.6007122, 0.6050263, 0.6098755, 0.6159543, 0...
## $ Estimate.neocortex  &lt;dbl&gt; 0.6713599, 0.6713599, 0.6713599, 0.6713599, 0.6713599, 0.6713599, 0...
## $ Est.Error.neocortex &lt;dbl&gt; 0.01397784, 0.01397784, 0.01397784, 0.01397784, 0.01397784, 0.01397...
## $ Q2.5.neocortex      &lt;dbl&gt; 0.6436987, 0.6436987, 0.6436987, 0.6436987, 0.6436987, 0.6436987, 0...
## $ Q97.5.neocortex     &lt;dbl&gt; 0.6989923, 0.6989923, 0.6989923, 0.6989923, 0.6989923, 0.6989923, 0...
## $ neocortex           &lt;dbl&gt; 0.5000000, 0.5120690, 0.5241379, 0.5362069, 0.5482759, 0.5603448, 0...
## $ logmass             &lt;dbl&gt; 1.244155, 1.244155, 1.244155, 1.244155, 1.244155, 1.244155, 1.24415...</code></pre>
<p>To include the imputed <code>neocortex</code> values in the plot, we’ll extract the information from <code>broom::tidy()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_b14.3_mi &lt;-
<span class="st">  </span><span class="kw">tidy</span>(b14.<span class="dv">3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(term, <span class="st">&quot;Ymi&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(data_list <span class="op">%&gt;%</span>
<span class="st">              </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">              </span><span class="kw">filter</span>(<span class="kw">is.na</span>(neocortex))
            )

<span class="co"># Here&#39;s what we did</span>
f_b14.3_mi <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">head</span>()</code></pre></div>
<pre><code>##                term  estimate  std.error     lower     upper kcal neocortex    logmass
## 1  Ymi_neocortex[2] 0.6327715 0.05080760 0.5522504 0.7188094 0.51        NA  0.7371641
## 2  Ymi_neocortex[3] 0.6251508 0.05110562 0.5428096 0.7105406 0.46        NA  0.9202828
## 3  Ymi_neocortex[4] 0.6223428 0.05213301 0.5399048 0.7102340 0.48        NA  0.4824261
## 4  Ymi_neocortex[5] 0.6527304 0.04902977 0.5740584 0.7338760 0.60        NA  0.7839015
## 5  Ymi_neocortex[9] 0.7014745 0.04943863 0.6226482 0.7822191 0.91        NA -0.3424903
## 6 Ymi_neocortex[14] 0.6564597 0.04911862 0.5788738 0.7400665 0.71        NA -0.5108256</code></pre>
<p>Data wrangling done–here’s our code for Figure 14.4.a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;D&quot;</span>)(<span class="dv">7</span>)[<span class="dv">4</span>]

f_b14.<span class="dv">3</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> neocortex,
             <span class="dt">y =</span> Estimate.kcal)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q2.<span class="fl">5.</span>kcal,
                  <span class="dt">ymax =</span> Q97.<span class="fl">5.</span>kcal),
              <span class="dt">fill =</span> color, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> color) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> data_list <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>(),
             <span class="kw">aes</span>(<span class="dt">y =</span> kcal),
             <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> f_b14.3_mi,
             <span class="kw">aes</span>(<span class="dt">x =</span> estimate, <span class="dt">y =</span> kcal),
             <span class="dt">color =</span> color, <span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">data =</span> f_b14.3_mi, 
               <span class="kw">aes</span>(<span class="dt">x =</span> lower, <span class="dt">xend =</span> upper,
                   <span class="dt">y =</span> kcal, <span class="dt">yend =</span> kcal),
             <span class="dt">color =</span> color, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(.<span class="dv">55</span>, .<span class="dv">8</span>),
                  <span class="dt">ylim =</span> <span class="kw">range</span>(data_list<span class="op">$</span>kcal, <span class="dt">na.rm =</span> T)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Note: For the regression line in this plot, log(mass)</span><span class="ch">\n</span><span class="st">has been set to its median, 1.244.&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;neocortex proportion&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;kcal per gram&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-837-1.png" width="384" /></p>
<p>Figure 14.4.b.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;D&quot;</span>)(<span class="dv">7</span>)[<span class="dv">4</span>]

data_list <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> logmass, <span class="dt">y =</span> neocortex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">data =</span> f_b14.3_mi,
                  <span class="kw">aes</span>(<span class="dt">x =</span> logmass, <span class="dt">y =</span> estimate,
                      <span class="dt">ymin =</span> lower, <span class="dt">ymax =</span> upper),
             <span class="dt">color =</span> color, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="op">-</span><span class="dv">2</span><span class="op">:</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(data_list<span class="op">$</span>logmass, <span class="dt">na.rm =</span> T),
                  <span class="dt">ylim =</span> <span class="kw">c</span>(.<span class="dv">55</span>, .<span class="dv">8</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log(mass)&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;neocortex proportion&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-838-1.png" width="384" /></p>
</div>
<div id="improving-the-imputation-model" class="section level3">
<h3><span class="header-section-number">14.2.2</span> Improving the imputation model</h3>
<p>Like McElreath, we’ll update the imputation line of our statistical model to:</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{neocortex}_i &amp; \sim &amp; \text{Normal} (\nu_i, \sigma_\text{neocortex}) \\
\nu_i &amp; = &amp; \alpha_\text{neocortex} + \gamma_1 \text{logmass}_i \\
\end{eqnarray}
\]</span> which includes the updated priors</p>
<p><span class="math display">\[
\begin{eqnarray}
\alpha_\text{neocortex} &amp; \sim &amp; \text{Normal} (0.5, 1) \\
\gamma_1 &amp; \sim &amp; \text{Normal} (0, 10)
\end{eqnarray}
\]</span></p>
<p>As far as the brms code goes, adding <code>logmass</code> as a predictor to the <code>neocortex</code> submodel is pretty simple.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The model</span>
b_model &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">bf</span>(kcal      <span class="op">|</span><span class="st"> </span><span class="kw">mi</span>() <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">mi</span>(neocortex) <span class="op">+</span><span class="st"> </span>logmass) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bf</span>(neocortex <span class="op">|</span><span class="st"> </span><span class="kw">mi</span>() <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>logmass) <span class="op">+</span><span class="st"> </span><span class="co"># Here&#39;s the big difference</span>
<span class="st">  </span><span class="kw">set_rescor</span>(<span class="ot">FALSE</span>)

<span class="co"># Fit the model</span>
b14.<span class="dv">4</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> data_list, 
      <span class="dt">family =</span> gaussian,
      b_model,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept, <span class="dt">resp =</span> kcal),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="fl">0.5</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept, <span class="dt">resp =</span> neocortex),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>),  <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>),   <span class="dt">class =</span> sigma,     <span class="dt">resp =</span> kcal),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>),   <span class="dt">class =</span> sigma,     <span class="dt">resp =</span> neocortex)),
      <span class="dt">iter =</span> <span class="fl">1e4</span>, <span class="dt">chains =</span> <span class="dv">2</span>, <span class="dt">cores =</span> <span class="dv">2</span>,
      <span class="co"># There were a couple divergent transitions with the default `adapt_delta = 0.8`</span>
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.9</span>))</code></pre></div>
<p>The parameter estimates:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(b14.<span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##                     term estimate std.error lower upper
## 1       b_kcal_Intercept    -0.86      0.49 -1.63 -0.05
## 2  b_neocortex_Intercept     0.64      0.01  0.62  0.66
## 3         b_kcal_logmass    -0.09      0.02 -0.13 -0.05
## 4    b_neocortex_logmass     0.02      0.01  0.01  0.03
## 5   bsp_kcal_mineocortex     2.43      0.76  1.15  3.63
## 6             sigma_kcal     0.13      0.02  0.10  0.17
## 7        sigma_neocortex     0.04      0.01  0.03  0.06
## 8       Ymi_neocortex[2]     0.63      0.03  0.57  0.69
## 9       Ymi_neocortex[3]     0.63      0.04  0.57  0.69
## 10      Ymi_neocortex[4]     0.62      0.04  0.56  0.68
## 11      Ymi_neocortex[5]     0.65      0.03  0.59  0.70
## 12      Ymi_neocortex[9]     0.66      0.04  0.60  0.72
## 13     Ymi_neocortex[14]     0.63      0.04  0.57  0.68
## 14     Ymi_neocortex[15]     0.68      0.03  0.62  0.74
## 15     Ymi_neocortex[17]     0.70      0.03  0.64  0.75
## 16     Ymi_neocortex[19]     0.71      0.03  0.66  0.77
## 17     Ymi_neocortex[21]     0.66      0.04  0.60  0.72
## 18     Ymi_neocortex[23]     0.68      0.03  0.62  0.74
## 19     Ymi_neocortex[26]     0.74      0.04  0.68  0.80
## 20                  lp__    48.77      4.15 41.17 54.65</code></pre>
<p>Here’s our pre-Figure 14.5 data wrangling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_b14.<span class="dv">4</span> &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b14.<span class="dv">4</span>, <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd)

f_b14.4_mi &lt;-
<span class="st">  </span><span class="kw">tidy</span>(b14.<span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(<span class="kw">str_detect</span>(term, <span class="st">&quot;Ymi&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(data_list <span class="op">%&gt;%</span>
<span class="st">              </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">              </span><span class="kw">filter</span>(<span class="kw">is.na</span>(neocortex))
            )

f_b14.<span class="dv">4</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 30
## Variables: 10
## $ Estimate.kcal       &lt;dbl&gt; 0.2416885, 0.2710504, 0.3004123, 0.3297742, 0.3591361, 0.3884980, 0...
## $ Est.Error.kcal      &lt;dbl&gt; 0.12999064, 0.12103147, 0.11210661, 0.10322496, 0.09439872, 0.08564...
## $ Q2.5.kcal           &lt;dbl&gt; -0.005757169, 0.040048457, 0.085978561, 0.132036308, 0.178190782, 0...
## $ Q97.5.kcal          &lt;dbl&gt; 0.5059238, 0.5173685, 0.5281662, 0.5390743, 0.5502195, 0.5618652, 0...
## $ Estimate.neocortex  &lt;dbl&gt; 0.6671348, 0.6671348, 0.6671348, 0.6671348, 0.6671348, 0.6671348, 0...
## $ Est.Error.neocortex &lt;dbl&gt; 0.009529979, 0.009529979, 0.009529979, 0.009529979, 0.009529979, 0....
## $ Q2.5.neocortex      &lt;dbl&gt; 0.6480756, 0.6480756, 0.6480756, 0.6480756, 0.6480756, 0.6480756, 0...
## $ Q97.5.neocortex     &lt;dbl&gt; 0.6859895, 0.6859895, 0.6859895, 0.6859895, 0.6859895, 0.6859895, 0...
## $ neocortex           &lt;dbl&gt; 0.5000000, 0.5120690, 0.5241379, 0.5362069, 0.5482759, 0.5603448, 0...
## $ logmass             &lt;dbl&gt; 1.244155, 1.244155, 1.244155, 1.244155, 1.244155, 1.244155, 1.24415...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">f_b14.4_mi <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 12
## Variables: 8
## $ term      &lt;chr&gt; &quot;Ymi_neocortex[2]&quot;, &quot;Ymi_neocortex[3]&quot;, &quot;Ymi_neocortex[4]&quot;, &quot;Ymi_neocortex[5]...
## $ estimate  &lt;dbl&gt; 0.6315583, 0.6293565, 0.6198302, 0.6465987, 0.6631728, 0.6274336, 0.6799432, ...
## $ std.error &lt;dbl&gt; 0.03497748, 0.03521781, 0.03502643, 0.03362197, 0.03572891, 0.03537715, 0.034...
## $ lower     &lt;dbl&gt; 0.5743664, 0.5715597, 0.5621254, 0.5921901, 0.6042473, 0.5698326, 0.6231185, ...
## $ upper     &lt;dbl&gt; 0.6886370, 0.6876339, 0.6776145, 0.7012781, 0.7216406, 0.6846492, 0.7358647, ...
## $ kcal      &lt;dbl&gt; 0.51, 0.46, 0.48, 0.60, 0.91, 0.71, 0.73, 0.72, 0.79, 0.48, 0.51, 0.53
## $ neocortex &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA
## $ logmass   &lt;dbl&gt; 0.7371641, 0.9202828, 0.4824261, 0.7839015, -0.3424903, -0.5108256, 1.2441546...</code></pre>
<p>For our final plots, let’s play around with colors from <code>viridis_pal(option = &quot;D&quot;)</code>. Figure 14.5.a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;D&quot;</span>)(<span class="dv">7</span>)[<span class="dv">3</span>]

f_b14.<span class="dv">4</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> neocortex,
             <span class="dt">y =</span> Estimate.kcal)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q2.<span class="fl">5.</span>kcal,
                  <span class="dt">ymax =</span> Q97.<span class="fl">5.</span>kcal),
              <span class="dt">fill =</span> color, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> color) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> data_list <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>(),
             <span class="kw">aes</span>(<span class="dt">y =</span> kcal),
             <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> f_b14.4_mi,
             <span class="kw">aes</span>(<span class="dt">x =</span> estimate, <span class="dt">y =</span> kcal),
             <span class="dt">color =</span> color, <span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">data =</span> f_b14.4_mi, 
               <span class="kw">aes</span>(<span class="dt">x =</span> lower, <span class="dt">xend =</span> upper,
                   <span class="dt">y =</span> kcal, <span class="dt">yend =</span> kcal),
             <span class="dt">color =</span> color, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(.<span class="dv">55</span>, .<span class="dv">8</span>),
                  <span class="dt">ylim =</span> <span class="kw">range</span>(data_list<span class="op">$</span>kcal, <span class="dt">na.rm =</span> T)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;Note: For the regression line in this plot, log(mass)</span><span class="ch">\n</span><span class="st">has been set to its median, 1.244.&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;neocortex proportion&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;kcal per gram&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-841-1.png" width="384" /></p>
<p>Figure 14.5.b.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">color &lt;-<span class="st"> </span><span class="kw">viridis_pal</span>(<span class="dt">option =</span> <span class="st">&quot;D&quot;</span>)(<span class="dv">7</span>)[<span class="dv">3</span>]

data_list <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> logmass, <span class="dt">y =</span> neocortex)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">data =</span> f_b14.4_mi,
                  <span class="kw">aes</span>(<span class="dt">x =</span> logmass, <span class="dt">y =</span> estimate,
                      <span class="dt">ymin =</span> lower, <span class="dt">ymax =</span> upper),
             <span class="dt">color =</span> color, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="op">-</span><span class="dv">2</span><span class="op">:</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(data_list<span class="op">$</span>logmass, <span class="dt">na.rm =</span> T),
                  <span class="dt">ylim =</span> <span class="kw">c</span>(.<span class="dv">55</span>, .<span class="dv">8</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;log(mass)&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;neocortex proportion&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-842-1.png" width="384" /></p>
<p>If modern missing data methods are new to you, you might also check out van Burren’s great online text <a href="https://stefvanbuuren.name/fimd/"><em>Flexible Imputation of Missing Data. Second Edition</em></a>. I’m also a fan of Enders’ <a href="http://www.appliedmissingdata.com"><em>Applied Missing Data Analysis</em></a>, for which you can find a free sample chapter <a href="http://www.appliedmissingdata.com/sample-chapter.pdf">here</a>. I’ll also quickly mention that <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html">brms accommodates multiple imputation</a>, too.</p>
</div>
</div>
<div id="reference-13" class="section level2 unnumbered">
<h2>Reference</h2>
<p><a href="https://xcelab.net/rm/statistical-rethinking/">McElreath, R. (2016). <em>Statistical rethinking: A Bayesian course with examples in R and Stan.</em> Chapman &amp; Hall/CRC Press.</a></p>
</div>
<div id="session-info-13" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] grid      parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] broom_0.4.5        viridis_0.5.1      viridisLite_0.3.0  bayesplot_1.6.0    brms_2.5.0        
##  [6] Rcpp_0.12.18       rstan_2.17.3       StanHeaders_2.17.2 forcats_0.3.0      stringr_1.3.1     
## [11] dplyr_0.7.6        purrr_0.2.5        readr_1.1.1        tidyr_0.8.1        tibble_1.4.2      
## [16] ggplot2_3.0.0      tidyverse_1.2.1   
## 
## loaded via a namespace (and not attached):
##   [1] pacman_0.4.6              utf8_1.1.4                ggstance_0.3             
##   [4] tidyselect_0.2.4          htmlwidgets_1.2           munsell_0.5.0            
##   [7] codetools_0.2-15          nleqslv_3.3.2             DT_0.4                   
##  [10] miniUI_0.1.1.1            withr_2.1.2               Brobdingnag_1.2-5        
##  [13] colorspace_1.3-2          highr_0.7                 knitr_1.20               
##  [16] rstudioapi_0.7            stats4_3.5.1              Rttf2pt1_1.3.7           
##  [19] labeling_0.3              mnormt_1.5-5              bridgesampling_0.4-0     
##  [22] rprojroot_1.3-2           coda_0.19-1               xfun_0.3                 
##  [25] R6_2.2.2                  markdown_0.8              HDInterval_0.2.0         
##  [28] reshape_0.8.7             assertthat_0.2.0          promises_1.0.1           
##  [31] scales_0.5.0              beeswarm_0.2.3            gtable_0.2.0             
##  [34] rlang_0.2.1               extrafontdb_1.0           lazyeval_0.2.1           
##  [37] inline_0.3.15             yaml_2.1.19               reshape2_1.4.3           
##  [40] abind_1.4-5               modelr_0.1.2              threejs_0.3.1            
##  [43] crosstalk_1.0.0           backports_1.1.2           httpuv_1.4.4.2           
##  [46] rsconnect_0.8.8           extrafont_0.17            tools_3.5.1              
##  [49] bookdown_0.7              psych_1.8.4               RColorBrewer_1.1-2       
##  [52] ggridges_0.5.0            plyr_1.8.4                base64enc_0.1-3          
##  [55] progress_1.2.0            prettyunits_1.0.2         zoo_1.8-2                
##  [58] LaplacesDemon_16.1.1      haven_1.1.2               magrittr_1.5             
##  [61] colourpicker_1.0          mvtnorm_1.0-8             matrixStats_0.54.0       
##  [64] hms_0.4.2                 shinyjs_1.0               mime_0.5                 
##  [67] evaluate_0.10.1           arrayhelpers_1.0-20160527 xtable_1.8-2             
##  [70] shinystan_2.5.0           readxl_1.1.0              gridExtra_2.3            
##  [73] rstantools_1.5.0          compiler_3.5.1            maps_3.3.0               
##  [76] crayon_1.3.4              htmltools_0.3.6           later_0.7.3              
##  [79] lubridate_1.7.4           MASS_7.3-50               Matrix_1.2-14            
##  [82] cli_1.0.0                 bindr_0.1.1               igraph_1.2.1             
##  [85] pkgconfig_2.0.1           foreign_0.8-70            xml2_1.2.0               
##  [88] svUnit_0.7-12             dygraphs_1.1.1.5          vipor_0.4.5              
##  [91] rvest_0.3.2               digest_0.6.15             rmarkdown_1.10           
##  [94] cellranger_1.1.0          shiny_1.1.0               gtools_3.8.1             
##  [97] nlme_3.1-137              jsonlite_1.5              bindrcpp_0.2.2           
## [100] mapproj_1.2.6             pillar_1.2.3              lattice_0.20-35          
## [103] loo_2.0.0                 httr_1.3.1                glue_1.2.0               
## [106] xts_0.10-2                shinythemes_1.1.1         pander_0.6.2             
## [109] stringi_1.2.3</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="adventures-in-covariance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="horoscopes-insights.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
