<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>6 Overfitting, Regularization, and Information Criteria | Statistical Rethinking with brms, ggplot2, and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="6 Overfitting, Regularization, and Information Criteria | Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKURZ/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Overfitting, Regularization, and Information Criteria | Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz">


<meta name="date" content="2019-04-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="multivariate-linear-models.html">
<link rel="next" href="interactions.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>This is a love letter</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#updates"><i class="fa fa-check"></i>Updates</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this"><i class="fa fa-check"></i>Why this?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#my-assumptions-about-you"><i class="fa fa-check"></i>My assumptions about you</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-and-understand-this-project"><i class="fa fa-check"></i>How to use and understand this project</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#you-can-do-this-too"><i class="fa fa-check"></i>You can do this, too</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html"><i class="fa fa-check"></i><b>1</b> The Golem of Prague</a><ul>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#reference"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html"><i class="fa fa-check"></i><b>2</b> Small Worlds and Large Worlds</a><ul>
<li class="chapter" data-level="2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#the-garden-of-forking-data"><i class="fa fa-check"></i><b>2.1</b> The garden of forking data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#counting-possibilities."><i class="fa fa-check"></i><b>2.1.1</b> Counting possibilities.</a></li>
<li class="chapter" data-level="2.1.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#using-prior-information."><i class="fa fa-check"></i><b>2.1.2</b> Using prior information.</a></li>
<li class="chapter" data-level="2.1.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#from-counts-to-probability."><i class="fa fa-check"></i><b>2.1.3</b> From counts to probability.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#building-a-model"><i class="fa fa-check"></i><b>2.2</b> Building a model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-data-story."><i class="fa fa-check"></i><b>2.2.1</b> A data story.</a></li>
<li class="chapter" data-level="2.2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayesian-updating."><i class="fa fa-check"></i><b>2.2.2</b> Bayesian updating.</a></li>
<li class="chapter" data-level="2.2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#evaluate."><i class="fa fa-check"></i><b>2.2.3</b> Evaluate.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#components-of-the-model"><i class="fa fa-check"></i><b>2.3</b> Components of the model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#likelihood."><i class="fa fa-check"></i><b>2.3.1</b> Likelihood.</a></li>
<li class="chapter" data-level="2.3.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#parameters."><i class="fa fa-check"></i><b>2.3.2</b> Parameters.</a></li>
<li class="chapter" data-level="2.3.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#prior."><i class="fa fa-check"></i><b>2.3.3</b> Prior.</a></li>
<li class="chapter" data-level="2.3.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#posterior."><i class="fa fa-check"></i><b>2.3.4</b> Posterior.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#making-the-model-go"><i class="fa fa-check"></i><b>2.4</b> Making the model go</a><ul>
<li class="chapter" data-level="2.4.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#grid-approximation."><i class="fa fa-check"></i><b>2.4.1</b> Grid approximation.</a></li>
<li class="chapter" data-level="2.4.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#quadratic-approximation."><i class="fa fa-check"></i><b>2.4.2</b> Quadratic approximation.</a></li>
<li class="chapter" data-level="2.4.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#markov-chain-monte-carlo."><i class="fa fa-check"></i><b>2.4.3</b> Markov chain Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#reference-1"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html"><i class="fa fa-check"></i><b>3</b> Sampling the Imaginary</a><ul>
<li class="chapter" data-level="3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-from-a-grid-like-approximate-posterior"><i class="fa fa-check"></i><b>3.1</b> Sampling from a grid-like approximate posterior</a></li>
<li class="chapter" data-level="3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-summarize"><i class="fa fa-check"></i><b>3.2</b> Sampling to summarize</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-boundaries."><i class="fa fa-check"></i><b>3.2.1</b> Intervals of defined boundaries.</a></li>
<li class="chapter" data-level="3.2.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-mass."><i class="fa fa-check"></i><b>3.2.2</b> Intervals of defined mass.</a></li>
<li class="chapter" data-level="3.2.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#point-estimates."><i class="fa fa-check"></i><b>3.2.3</b> Point estimates.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-simulate-prediction"><i class="fa fa-check"></i><b>3.3</b> Sampling to simulate prediction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#dummy-data."><i class="fa fa-check"></i><b>3.3.1</b> Dummy data.</a></li>
<li class="chapter" data-level="3.3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#model-checking."><i class="fa fa-check"></i><b>3.3.2</b> Model checking.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#summary-lets-practice-in-brms"><i class="fa fa-check"></i><b>3.4</b> <del>Summary</del> Let’s practice in brms</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#reference-2"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>4</b> Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-models.html"><a href="linear-models.html#why-normal-distributions-are-normal"><i class="fa fa-check"></i><b>4.1</b> Why normal distributions are normal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linear-models.html"><a href="linear-models.html#normal-by-addition."><i class="fa fa-check"></i><b>4.1.1</b> Normal by addition.</a></li>
<li class="chapter" data-level="4.1.2" data-path="linear-models.html"><a href="linear-models.html#normal-by-multiplication."><i class="fa fa-check"></i><b>4.1.2</b> Normal by multiplication.</a></li>
<li class="chapter" data-level="4.1.3" data-path="linear-models.html"><a href="linear-models.html#normal-by-log-multiplication."><i class="fa fa-check"></i><b>4.1.3</b> Normal by log-multiplication.</a></li>
<li class="chapter" data-level="4.1.4" data-path="linear-models.html"><a href="linear-models.html#using-gaussian-distributions."><i class="fa fa-check"></i><b>4.1.4</b> Using Gaussian distributions.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-models.html"><a href="linear-models.html#a-language-for-describing-models"><i class="fa fa-check"></i><b>4.2</b> A language for describing models</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-models.html"><a href="linear-models.html#re-describing-the-globe-tossing-model."><i class="fa fa-check"></i><b>4.2.1</b> Re-describing the globe tossing model.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-models.html"><a href="linear-models.html#a-gaussian-model-of-height"><i class="fa fa-check"></i><b>4.3</b> A Gaussian model of height</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linear-models.html"><a href="linear-models.html#the-data."><i class="fa fa-check"></i><b>4.3.1</b> The data.</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-models.html"><a href="linear-models.html#the-model."><i class="fa fa-check"></i><b>4.3.2</b> The model.</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-models.html"><a href="linear-models.html#grid-approximation-of-the-posterior-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Grid approximation of the posterior distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="linear-models.html"><a href="linear-models.html#sampling-from-the-posterior."><i class="fa fa-check"></i><b>4.3.4</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="4.3.5" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model-with-map-brm."><i class="fa fa-check"></i><b>4.3.5</b> Fitting the model with <del><code>map()</code></del> <code>brm()</code>.</a></li>
<li class="chapter" data-level="4.3.6" data-path="linear-models.html"><a href="linear-models.html#sampling-from-a-map-brm-fit."><i class="fa fa-check"></i><b>4.3.6</b> Sampling from a <del><code>map()</code></del> <code>brm()</code> fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-models.html"><a href="linear-models.html#adding-a-predictor"><i class="fa fa-check"></i><b>4.4</b> Adding a predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="linear-models.html"><a href="linear-models.html#the-linear-model-strategy"><i class="fa fa-check"></i><b>4.4.1</b> The linear model strategy</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model."><i class="fa fa-check"></i><b>4.4.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="4.4.3" data-path="linear-models.html"><a href="linear-models.html#interpreting-the-model-fit."><i class="fa fa-check"></i><b>4.4.3</b> Interpreting the model fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-models.html"><a href="linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>4.5</b> Polynomial regression</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#reference-3"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html"><i class="fa fa-check"></i><b>5</b> Multivariate Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#spurious-associations"><i class="fa fa-check"></i><b>5.1</b> Spurious associations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multivariate-notation."><i class="fa fa-check"></i><b>5.1.1</b> Multivariate notation.</a></li>
<li class="chapter" data-level="5.1.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#fitting-the-model.-1"><i class="fa fa-check"></i><b>5.1.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="5.1.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#plotting-multivariate-posteriors."><i class="fa fa-check"></i><b>5.1.3</b> Plotting multivariate posteriors.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#masked-relationship"><i class="fa fa-check"></i><b>5.2</b> Masked relationship</a></li>
<li class="chapter" data-level="5.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinearity"><i class="fa fa-check"></i><b>5.3</b> Multicollinearity</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-legs."><i class="fa fa-check"></i><b>5.3.1</b> Multicollinear legs.</a></li>
<li class="chapter" data-level="5.3.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-milk."><i class="fa fa-check"></i><b>5.3.2</b> Multicollinear <code>milk</code>.</a></li>
<li class="chapter" data-level="5.3.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#post-treatment-bias."><i class="fa fa-check"></i><b>5.3.3</b> Post-treatment bias.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#categorical-varaibles"><i class="fa fa-check"></i><b>5.4</b> Categorical varaibles</a><ul>
<li class="chapter" data-level="5.4.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#binary-categories."><i class="fa fa-check"></i><b>5.4.1</b> Binary categories.</a></li>
<li class="chapter" data-level="5.4.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#many-categories."><i class="fa fa-check"></i><b>5.4.2</b> Many categories.</a></li>
<li class="chapter" data-level="5.4.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#adding-regular-predictor-variables."><i class="fa fa-check"></i><b>5.4.3</b> Adding regular predictor variables.</a></li>
<li class="chapter" data-level="5.4.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#another-approach-unique-intercepts."><i class="fa fa-check"></i><b>5.4.4</b> Another approach: Unique intercepts.</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#ordinary-least-squares-and-lm"><i class="fa fa-check"></i><b>5.5</b> <del>Ordinary least squares and <code>lm()</code></del></a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#reference-4"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html"><i class="fa fa-check"></i><b>6</b> Overfitting, Regularization, and Information Criteria</a><ul>
<li class="chapter" data-level="6.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#the-problem-with-parameters"><i class="fa fa-check"></i><b>6.1</b> The problem with parameters</a><ul>
<li class="chapter" data-level="6.1.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#more-parameters-always-improve-fit."><i class="fa fa-check"></i><b>6.1.1</b> More parameters always improve fit.</a></li>
<li class="chapter" data-level="6.1.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#too-few-parameters-hurts-too."><i class="fa fa-check"></i><b>6.1.2</b> Too few parameters hurts, too.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-theory-and-model-performance"><i class="fa fa-check"></i><b>6.2</b> Information theory and model performance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#firing-the-weatherperson."><i class="fa fa-check"></i><b>6.2.1</b> Firing the weatherperson.</a></li>
<li class="chapter" data-level="6.2.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-and-uncertainty."><i class="fa fa-check"></i><b>6.2.2</b> Information and uncertainty.</a></li>
<li class="chapter" data-level="6.2.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-entropy-to-accuracy."><i class="fa fa-check"></i><b>6.2.3</b> From entropy to accuracy.</a></li>
<li class="chapter" data-level="6.2.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-divergence-to-deviance."><i class="fa fa-check"></i><b>6.2.4</b> From divergence to deviance.</a></li>
<li class="chapter" data-level="6.2.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-deviance-to-out-of-sample."><i class="fa fa-check"></i><b>6.2.5</b> From deviance to out-of-sample.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#regularization"><i class="fa fa-check"></i><b>6.3</b> Regularization</a></li>
<li class="chapter" data-level="6.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-criteria"><i class="fa fa-check"></i><b>6.4</b> Information criteria</a><ul>
<li class="chapter" data-level="6.4.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic."><i class="fa fa-check"></i><b>6.4.1</b> DIC.</a></li>
<li class="chapter" data-level="6.4.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#waic."><i class="fa fa-check"></i><b>6.4.2</b> WAIC.</a></li>
<li class="chapter" data-level="6.4.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic-and-waic-as-estimates-of-deviance."><i class="fa fa-check"></i><b>6.4.3</b> DIC and WAIC as estimates of deviance.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#using-information-criteria"><i class="fa fa-check"></i><b>6.5</b> Using information criteria</a><ul>
<li class="chapter" data-level="6.5.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-comparison."><i class="fa fa-check"></i><b>6.5.1</b> Model comparison.</a></li>
<li class="chapter" data-level="6.5.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-averaging."><i class="fa fa-check"></i><b>6.5.2</b> Model averaging.</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#summary-bonus-r2-talk"><i class="fa fa-check"></i><b>6.6</b> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#reference-5"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>7</b> Interactions</a><ul>
<li class="chapter" data-level="7.1" data-path="interactions.html"><a href="interactions.html#building-an-interaction."><i class="fa fa-check"></i><b>7.1</b> Building an interaction.</a><ul>
<li class="chapter" data-level="7.1.1" data-path="interactions.html"><a href="interactions.html#adding-a-dummy-variable-doesnt-work."><i class="fa fa-check"></i><b>7.1.1</b> Adding a dummy variable doesn’t work.</a></li>
<li class="chapter" data-level="7.1.2" data-path="interactions.html"><a href="interactions.html#adding-a-linear-interaction-does-work."><i class="fa fa-check"></i><b>7.1.2</b> Adding a linear interaction does work.</a></li>
<li class="chapter" data-level="7.1.3" data-path="interactions.html"><a href="interactions.html#plotting-the-interaction."><i class="fa fa-check"></i><b>7.1.3</b> Plotting the interaction.</a></li>
<li class="chapter" data-level="7.1.4" data-path="interactions.html"><a href="interactions.html#interpreting-an-interaction-estimate."><i class="fa fa-check"></i><b>7.1.4</b> Interpreting an interaction estimate.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="interactions.html"><a href="interactions.html#symmetry-of-the-linear-interaction."><i class="fa fa-check"></i><b>7.2</b> Symmetry of the linear interaction.</a><ul>
<li class="chapter" data-level="7.2.1" data-path="interactions.html"><a href="interactions.html#buridans-interaction."><i class="fa fa-check"></i><b>7.2.1</b> Buridan’s interaction.</a></li>
<li class="chapter" data-level="7.2.2" data-path="interactions.html"><a href="interactions.html#africa-depends-upon-ruggedness."><i class="fa fa-check"></i><b>7.2.2</b> Africa depends upon ruggedness.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="interactions.html"><a href="interactions.html#continuous-interactions"><i class="fa fa-check"></i><b>7.3</b> Continuous interactions</a><ul>
<li class="chapter" data-level="7.3.1" data-path="interactions.html"><a href="interactions.html#the-data.-1"><i class="fa fa-check"></i><b>7.3.1</b> The data.</a></li>
<li class="chapter" data-level="7.3.2" data-path="interactions.html"><a href="interactions.html#the-un-centered-models."><i class="fa fa-check"></i><b>7.3.2</b> The un-centered models.</a></li>
<li class="chapter" data-level="7.3.3" data-path="interactions.html"><a href="interactions.html#center-and-re-estimate."><i class="fa fa-check"></i><b>7.3.3</b> Center and re-estimate.</a></li>
<li class="chapter" data-level="7.3.4" data-path="interactions.html"><a href="interactions.html#plotting-implied-predictions."><i class="fa fa-check"></i><b>7.3.4</b> Plotting implied predictions.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="interactions.html"><a href="interactions.html#interactions-in-design-formulas"><i class="fa fa-check"></i><b>7.4</b> Interactions in design formulas</a></li>
<li class="chapter" data-level="7.5" data-path="interactions.html"><a href="interactions.html#summary-bonus-marginal_effects"><i class="fa fa-check"></i><b>7.5</b> <del>Summary</del> Bonus: <code>marginal_effects()</code></a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#reference-6"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>8</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#good-king-markov-and-his-island-kingdom"><i class="fa fa-check"></i><b>8.1</b> Good King Markov and His island kingdom</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-1"><i class="fa fa-check"></i><b>8.2</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#easy-hmc-map2stan-brm"><i class="fa fa-check"></i><b>8.3</b> Easy HMC: <del>map2stan</del> <code>brm()</code></a><ul>
<li class="chapter" data-level="8.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#preparation."><i class="fa fa-check"></i><b>8.3.1</b> Preparation.</a></li>
<li class="chapter" data-level="8.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#estimation."><i class="fa fa-check"></i><b>8.3.2</b> Estimation.</a></li>
<li class="chapter" data-level="8.3.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-again-in-parallel."><i class="fa fa-check"></i><b>8.3.3</b> Sampling again, in parallel.</a></li>
<li class="chapter" data-level="8.3.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#visualization."><i class="fa fa-check"></i><b>8.3.4</b> Visualization.</a></li>
<li class="chapter" data-level="8.3.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#using-the-samples."><i class="fa fa-check"></i><b>8.3.5</b> Using the samples.</a></li>
<li class="chapter" data-level="8.3.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#checking-the-chain."><i class="fa fa-check"></i><b>8.3.6</b> Checking the chain.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#care-and-feeding-of-your-markov-chain."><i class="fa fa-check"></i><b>8.4</b> Care and feeding of your Markov chain.</a><ul>
<li class="chapter" data-level="8.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-samples-do-you-need"><i class="fa fa-check"></i><b>8.4.1</b> How many samples do you need?</a></li>
<li class="chapter" data-level="8.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-chains-do-you-need"><i class="fa fa-check"></i><b>8.4.2</b> How many chains do you need?</a></li>
<li class="chapter" data-level="8.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#taming-a-wild-chain."><i class="fa fa-check"></i><b>8.4.3</b> Taming a wild chain.</a></li>
<li class="chapter" data-level="8.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#non-identifiable-parameters."><i class="fa fa-check"></i><b>8.4.4</b> Non-identifiable parameters.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#reference-7"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>9</b> Big Entropy and the Generalized Linear Model</a><ul>
<li class="chapter" data-level="9.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#maximum-entropy"><i class="fa fa-check"></i><b>9.1</b> Maximum entropy</a><ul>
<li class="chapter" data-level="9.1.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#gaussian."><i class="fa fa-check"></i><b>9.1.1</b> Gaussian.</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#binomial."><i class="fa fa-check"></i><b>9.1.2</b> Binomial.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#generalized-linear-models"><i class="fa fa-check"></i><b>9.2</b> Generalized linear models</a><ul>
<li class="chapter" data-level="9.2.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#meet-the-family."><i class="fa fa-check"></i><b>9.2.1</b> Meet the family.</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions."><i class="fa fa-check"></i><b>9.2.2</b> Linking linear models to distributions.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#reference-8"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="counting-and-classification.html"><a href="counting-and-classification.html"><i class="fa fa-check"></i><b>10</b> Counting and Classification</a><ul>
<li class="chapter" data-level="10.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#binomial-regression"><i class="fa fa-check"></i><b>10.1</b> Binomial regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#logistic-regression-prosocial-chimpanzees."><i class="fa fa-check"></i><b>10.1.1</b> Logistic regression: Prosocial chimpanzees.</a></li>
<li class="chapter" data-level="10.1.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-chimpanzees-again-condensed."><i class="fa fa-check"></i><b>10.1.2</b> Aggregated binomial: Chimpanzees again, condensed.</a></li>
<li class="chapter" data-level="10.1.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-graduate-school-admissions."><i class="fa fa-check"></i><b>10.1.3</b> Aggregated binomial: Graduate school admissions.</a></li>
<li class="chapter" data-level="10.1.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#fitting-binomial-regressions-with-glm."><i class="fa fa-check"></i><b>10.1.4</b> Fitting binomial regressions with <code>glm()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#poisson-regression"><i class="fa fa-check"></i><b>10.2</b> Poisson regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-oceanic-tool-complexity."><i class="fa fa-check"></i><b>10.2.1</b> Example: Oceanic tool complexity.</a></li>
<li class="chapter" data-level="10.2.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#mcmc-islands."><i class="fa fa-check"></i><b>10.2.2</b> MCMC islands.</a></li>
<li class="chapter" data-level="10.2.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-exposure-and-the-offset."><i class="fa fa-check"></i><b>10.2.3</b> Example: Exposure and the offset.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#other-count-regressions"><i class="fa fa-check"></i><b>10.3</b> Other count regressions</a><ul>
<li class="chapter" data-level="10.3.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#multinomial."><i class="fa fa-check"></i><b>10.3.1</b> Multinomial.</a></li>
<li class="chapter" data-level="10.3.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#geometric."><i class="fa fa-check"></i><b>10.3.2</b> Geometric.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#reference-9"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html"><i class="fa fa-check"></i><b>11</b> Monsters and Mixtures</a><ul>
<li class="chapter" data-level="11.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-outcomes"><i class="fa fa-check"></i><b>11.1</b> Ordered categorical outcomes</a><ul>
<li class="chapter" data-level="11.1.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-moral-intuition."><i class="fa fa-check"></i><b>11.1.1</b> Example: Moral intuition.</a></li>
<li class="chapter" data-level="11.1.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#describing-an-ordered-distribution-with-intercepts."><i class="fa fa-check"></i><b>11.1.2</b> Describing an ordered distribution with intercepts.</a></li>
<li class="chapter" data-level="11.1.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#adding-predictor-variables."><i class="fa fa-check"></i><b>11.1.3</b> Adding predictor variables.</a></li>
<li class="chapter" data-level="11.1.4" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#bonus-figure-11.3-alternative."><i class="fa fa-check"></i><b>11.1.4</b> Bonus: Figure 11.3 alternative.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#zero-inflated-outcomes"><i class="fa fa-check"></i><b>11.2</b> Zero-inflated outcomes</a><ul>
<li class="chapter" data-level="11.2.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-zero-inflated-poisson."><i class="fa fa-check"></i><b>11.2.1</b> Example: Zero-inflated Poisson.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersed-outcomes"><i class="fa fa-check"></i><b>11.3</b> Over-dispersed outcomes</a><ul>
<li class="chapter" data-level="11.3.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#beta-binomial."><i class="fa fa-check"></i><b>11.3.1</b> Beta-binomial.</a></li>
<li class="chapter" data-level="11.3.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#negative-binomial-or-gamma-poisson."><i class="fa fa-check"></i><b>11.3.2</b> Negative-binomial or gamma-Poisson.</a></li>
<li class="chapter" data-level="11.3.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersion-entropy-and-information-criteria."><i class="fa fa-check"></i><b>11.3.3</b> Over-dispersion, entropy, and information criteria.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#reference-10"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>12</b> Multilevel Models</a><ul>
<li class="chapter" data-level="12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-multilevel-tadpoles"><i class="fa fa-check"></i><b>12.1</b> Example: Multilevel tadpoles</a></li>
<li class="chapter" data-level="12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>12.2</b> Varying effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multilevel-models.html"><a href="multilevel-models.html#the-model.-1"><i class="fa fa-check"></i><b>12.2.1</b> The model.</a></li>
<li class="chapter" data-level="12.2.2" data-path="multilevel-models.html"><a href="multilevel-models.html#assign-values-to-the-parameters."><i class="fa fa-check"></i><b>12.2.2</b> Assign values to the parameters.</a></li>
<li class="chapter" data-level="12.2.3" data-path="multilevel-models.html"><a href="multilevel-models.html#sumulate-survivors."><i class="fa fa-check"></i><b>12.2.3</b> Sumulate survivors.</a></li>
<li class="chapter" data-level="12.2.4" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-no-pooling-estimates."><i class="fa fa-check"></i><b>12.2.4</b> Compute the no-pooling estimates.</a></li>
<li class="chapter" data-level="12.2.5" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-partial-pooling-estimates."><i class="fa fa-check"></i><b>12.2.5</b> Compute the partial-pooling estimates.</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multilevel-models.html"><a href="multilevel-models.html#more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>12.3</b> More than one type of cluster</a><ul>
<li class="chapter" data-level="12.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-chimpanzees."><i class="fa fa-check"></i><b>12.3.1</b> Multilevel chimpanzees.</a></li>
<li class="chapter" data-level="12.3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#two-types-of-cluster."><i class="fa fa-check"></i><b>12.3.2</b> Two types of cluster.</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-posterior-predictions"><i class="fa fa-check"></i><b>12.4</b> Multilevel posterior predictions</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-same-clusters."><i class="fa fa-check"></i><b>12.4.1</b> Posterior prediction for same clusters.</a></li>
<li class="chapter" data-level="12.4.2" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-new-clusters."><i class="fa fa-check"></i><b>12.4.2</b> Posterior prediction for new clusters.</a></li>
<li class="chapter" data-level="12.4.3" data-path="multilevel-models.html"><a href="multilevel-models.html#focus-and-multilevel-prediction."><i class="fa fa-check"></i><b>12.4.3</b> Focus and multilevel prediction.</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="multilevel-models.html"><a href="multilevel-models.html#summary-bonus-tidybayesspread_draws"><i class="fa fa-check"></i><b>12.5</b> <del>Summary</del> Bonus: <code>tidybayes::spread_draws()</code></a><ul>
<li class="chapter" data-level="12.5.1" data-path="multilevel-models.html"><a href="multilevel-models.html#intercepts-only-models-with-one-or-two-grouping-variables"><i class="fa fa-check"></i><b>12.5.1</b> Intercepts-only models with one or two grouping variables</a></li>
<li class="chapter" data-level="12.5.2" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsposterior_samples"><i class="fa fa-check"></i><b>12.5.2</b> <code>brms::posterior_samples()</code></a></li>
<li class="chapter" data-level="12.5.3" data-path="multilevel-models.html"><a href="multilevel-models.html#brmscoef"><i class="fa fa-check"></i><b>12.5.3</b> <code>brms::coef()</code></a></li>
<li class="chapter" data-level="12.5.4" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsfitted"><i class="fa fa-check"></i><b>12.5.4</b> <code>brms::fitted()</code></a></li>
<li class="chapter" data-level="12.5.5" data-path="multilevel-models.html"><a href="multilevel-models.html#tidybayesspread_draws"><i class="fa fa-check"></i><b>12.5.5</b> <code>tidybayes::spread_draws()</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#reference-11"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html"><i class="fa fa-check"></i><b>13</b> Adventures in Covariance</a><ul>
<li class="chapter" data-level="13.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-slopes-by-construction"><i class="fa fa-check"></i><b>13.1</b> Varying slopes by construction</a><ul>
<li class="chapter" data-level="13.1.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-the-population."><i class="fa fa-check"></i><b>13.1.1</b> Simulate the population.</a></li>
<li class="chapter" data-level="13.1.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-observations."><i class="fa fa-check"></i><b>13.1.2</b> Simulate observations.</a></li>
<li class="chapter" data-level="13.1.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#the-varying-slopes-model."><i class="fa fa-check"></i><b>13.1.3</b> The varying slopes model.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-admission-decisions-and-gender"><i class="fa fa-check"></i><b>13.2</b> Example: Admission decisions and gender</a><ul>
<li class="chapter" data-level="13.2.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-intercepts."><i class="fa fa-check"></i><b>13.2.1</b> Varying intercepts.</a></li>
<li class="chapter" data-level="13.2.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-effects-of-being-male."><i class="fa fa-check"></i><b>13.2.2</b> Varying effects of being <code>male</code>.</a></li>
<li class="chapter" data-level="13.2.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#shrinkage."><i class="fa fa-check"></i><b>13.2.3</b> Shrinkage.</a></li>
<li class="chapter" data-level="13.2.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#model-comparison.-1"><i class="fa fa-check"></i><b>13.2.4</b> Model comparison.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-cross-classified-chimpanzees-with-varying-slopes"><i class="fa fa-check"></i><b>13.3</b> Example: Cross-classified <code>chimpanzees</code> with varying slopes</a></li>
<li class="chapter" data-level="13.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#continuous-categories-and-the-gaussian-process"><i class="fa fa-check"></i><b>13.4</b> Continuous categories and the Gaussian process</a><ul>
<li class="chapter" data-level="13.4.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-spatial-autocorrelation-in-oceanic-tools."><i class="fa fa-check"></i><b>13.4.1</b> Example: Spatial autocorrelation in Oceanic tools.</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#summary-bonus-another-berkley-admissions-data-like-example."><i class="fa fa-check"></i><b>13.5</b> <del>Summary</del> Bonus: Another Berkley-admissions-data-like example.</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#reference-12"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html"><i class="fa fa-check"></i><b>14</b> Missing Data and Other Opportunities</a><ul>
<li class="chapter" data-level="14.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-error"><i class="fa fa-check"></i><b>14.1</b> Measurement error</a><ul>
<li class="chapter" data-level="14.1.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-the-outcome."><i class="fa fa-check"></i><b>14.1.1</b> Error on the outcome.</a></li>
<li class="chapter" data-level="14.1.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-both-outcome-and-predictor."><i class="fa fa-check"></i><b>14.1.2</b> Error on both outcome and predictor.</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#missing-data"><i class="fa fa-check"></i><b>14.2</b> Missing data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#imputing-neocortex"><i class="fa fa-check"></i><b>14.2.1</b> Imputing <code>neocortex</code></a></li>
<li class="chapter" data-level="14.2.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#improving-the-imputation-model"><i class="fa fa-check"></i><b>14.2.2</b> Improving the imputation model</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#summary-bonus-meta-analysis"><i class="fa fa-check"></i><b>14.3</b> <del>Summary</del> Bonus: Meta-analysis</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#reference-13"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html"><i class="fa fa-check"></i><b>15</b> <del>Horoscopes</del> Insights</a><ul>
<li class="chapter" data-level="15.1" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-r-notebooks"><i class="fa fa-check"></i><b>15.1</b> Use R Notebooks</a></li>
<li class="chapter" data-level="15.2" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#save-your-model-fits"><i class="fa fa-check"></i><b>15.2</b> Save your model fits</a></li>
<li class="chapter" data-level="15.3" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#build-your-models-slowly"><i class="fa fa-check"></i><b>15.3</b> Build your models slowly</a></li>
<li class="chapter" data-level="15.4" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#look-at-your-data"><i class="fa fa-check"></i><b>15.4</b> Look at your data</a></li>
<li class="chapter" data-level="15.5" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-the-0-intercept-syntax"><i class="fa fa-check"></i><b>15.5</b> Use the <code>0 + intercept</code> syntax</a></li>
<li class="chapter" data-level="15.6" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-workflow"><i class="fa fa-check"></i><b>15.6</b> Annotate your workflow</a></li>
<li class="chapter" data-level="15.7" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-code"><i class="fa fa-check"></i><b>15.7</b> Annotate your code</a></li>
<li class="chapter" data-level="15.8" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#break-up-your-workflow"><i class="fa fa-check"></i><b>15.8</b> Break up your workflow</a></li>
<li class="chapter" data-level="15.9" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#read-gelmans-blog"><i class="fa fa-check"></i><b>15.9</b> Read Gelman’s blog</a></li>
<li class="chapter" data-level="15.10" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#check-out-other-social-media-too"><i class="fa fa-check"></i><b>15.10</b> Check out other social media, too</a></li>
<li class="chapter" data-level="15.11" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#parting-wisdom"><i class="fa fa-check"></i><b>15.11</b> Parting wisdom</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#reference-14"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical Rethinking</em> with brms, ggplot2, and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="overfitting-regularization-and-information-criteria" class="section level1">
<h1><span class="header-section-number">6</span> Overfitting, Regularization, and Information Criteria</h1>
<p>In this chapter we contend with two contrasting kinds of statistical error:</p>
<ul>
<li>overfitting, “which leads to poor prediction by learning too <em>much</em> from the data”</li>
<li>underfitting, “which leads to poor prediction by learning too <em>little</em> from the data” (p. 166, <em>emphasis</em> added)</li>
</ul>
<div id="the-problem-with-parameters" class="section level2">
<h2><span class="header-section-number">6.1</span> The problem with parameters</h2>
<p>The <span class="math inline">\(R^2\)</span> is a popular way to measure how well you can retrodict the data. It traditionally follows the form</p>
<p><span class="math display">\[R^2 = \frac{\text{var(outcome)} - \text{var(residuals)}}{\text{var(outcome)}} = 1 - \frac{\text{var(residuals)}}{\text{var(outcome)}}\]</span></p>
<p>By <span class="math inline">\(\text{var()}\)</span>, of course, we meant variance (i.e., the <code>var()</code> function in R).</p>
<p>McElreath’s not a fan of the <span class="math inline">\(R^2\)</span>. But it’s important in my field, so instead of a summary at the end of the chapter, we will cover the Bayesian version of <span class="math inline">\(R^2\)</span> and how to use it in brms.</p>
<div id="more-parameters-always-improve-fit." class="section level3">
<h3><span class="header-section-number">6.1.1</span> More parameters always improve fit.</h3>
<p>We’ll start off by making the data with brain size and body size for seven <code>species</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)

(
  d &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">species =</span> <span class="kw">c</span>(<span class="st">&quot;afarensis&quot;</span>, <span class="st">&quot;africanus&quot;</span>, <span class="st">&quot;habilis&quot;</span>, <span class="st">&quot;boisei&quot;</span>, <span class="st">&quot;rudolfensis&quot;</span>, <span class="st">&quot;ergaster&quot;</span>, <span class="st">&quot;sapiens&quot;</span>), 
         <span class="dt">brain   =</span> <span class="kw">c</span>(<span class="dv">438</span>, <span class="dv">452</span>, <span class="dv">612</span>, <span class="dv">521</span>, <span class="dv">752</span>, <span class="dv">871</span>, <span class="dv">1350</span>), 
         <span class="dt">mass    =</span> <span class="kw">c</span>(<span class="fl">37.0</span>, <span class="fl">35.5</span>, <span class="fl">34.5</span>, <span class="fl">41.5</span>, <span class="fl">55.5</span>, <span class="fl">61.0</span>, <span class="fl">53.5</span>))
  )</code></pre></div>
<pre><code>## # A tibble: 7 x 3
##   species     brain  mass
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;
## 1 afarensis     438  37  
## 2 africanus     452  35.5
## 3 habilis       612  34.5
## 4 boisei        521  41.5
## 5 rudolfensis   752  55.5
## 6 ergaster      871  61  
## 7 sapiens      1350  53.5</code></pre>
<p>Let’s get ready for Figure 6.2. The plots in this chapter will be characterized by <code>theme_classic() + theme(text = element_text(family = &quot;Courier&quot;))</code>. Our color palette will come from the <a href="https://cran.r-project.org/web/packages/rcartocolor/index.html">rcartocolor package</a>, which provides color schemes <a href="https://carto.com/carto-colors/">designed by ‘CARTO’</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;rcartocolor&quot;, dependencies = T)</span>
<span class="kw">library</span>(rcartocolor)</code></pre></div>
<p>The specific palette we’ll be using is “BurgYl.” In addition to palettes, the rcartocolor package offers a few convenience functions which make it easier to use their palettes. The <code>carto_pal()</code> function will return the HEX numbers associated with a given palette’s colors and the <code>display_carto_pal()</code> function will display the actual colors.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)</code></pre></div>
<pre><code>## [1] &quot;#fbe6c5&quot; &quot;#f5ba98&quot; &quot;#ee8a82&quot; &quot;#dc7176&quot; &quot;#c8586c&quot; &quot;#9c3f5d&quot; &quot;#70284a&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">display_carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-3-1.png" width="576" /></p>
<p>We’ll be using a diluted version of the third color for the panel background (i.e., <code>theme(panel.background = element_rect(fill = alpha(carto_pal(7, &quot;BurgYl&quot;)[3], 1/4)))</code>) and the darker purples for other plot elements. Here’s the plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggrepel)

d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span>  mass, <span class="dt">y =</span> brain, <span class="dt">label =</span> species)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text_repel</span>(<span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>, <span class="dt">seed =</span> <span class="dv">438</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">30</span><span class="op">:</span><span class="dv">65</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;body mass (kg)&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;brain volume (cc)&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;Average brain volume by body</span><span class="ch">\n</span><span class="st">mass for six hominin species&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-4-1.png" width="336" /></p>
<p>Let’s fit the first six models in bulk. First we’ll make a custom function, <code>fit_lm()</code>, into which we’ll feed the desired names and formulas of our models. We’ll make a tibble initially composed of those names (i.e., <code>model</code>) and formulas (i.e., <code>formula</code>). Via <code>purrr::map2()</code> within <code>mutate()</code>, we’ll then fit the models and save the model objects within the tibble. The <a href="https://cran.r-project.org/web/packages/broom/index.html">broom package</a> provides an array of convenience functions to convert statistical analysis summaries into tidy data objects. We’ll employ <code>broom::tidy()</code> and <code>broom::glance()</code> to extract information from the model fits.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(broom)

fit_lm &lt;-<span class="st"> </span><span class="cf">function</span>(model, formula){
  model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> d, <span class="dt">formula =</span> formula)
}

fits &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">model   =</span> <span class="kw">str_c</span>(<span class="st">&quot;b6.&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">6</span>),
         <span class="dt">formula =</span> <span class="kw">c</span>(<span class="st">&quot;brain ~ mass&quot;</span>, 
                     <span class="st">&quot;brain ~ mass + I(mass^2)&quot;</span>, 
                     <span class="st">&quot;brain ~ mass + I(mass^2) + I(mass^3)&quot;</span>, 
                     <span class="st">&quot;brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4)&quot;</span>, 
                     <span class="st">&quot;brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(mass^5)&quot;</span>, 
                     <span class="st">&quot;brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(mass^5) + I(mass^6)&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">fit     =</span> <span class="kw">map2</span>(model, formula, fit_lm)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">tidy    =</span> <span class="kw">map</span>(fit, tidy),
         <span class="dt">glance  =</span> <span class="kw">map</span>(fit, glance))

<span class="co"># what did we just do?</span>
<span class="kw">print</span>(fits)</code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   model formula                                                 fit     tidy          glance        
##   &lt;chr&gt; &lt;chr&gt;                                                   &lt;list&gt;  &lt;list&gt;        &lt;list&gt;        
## 1 b6.1  brain ~ mass                                            &lt;S3: l… &lt;tibble [2 ×… &lt;tibble [1 × …
## 2 b6.2  brain ~ mass + I(mass^2)                                &lt;S3: l… &lt;tibble [3 ×… &lt;tibble [1 × …
## 3 b6.3  brain ~ mass + I(mass^2) + I(mass^3)                    &lt;S3: l… &lt;tibble [4 ×… &lt;tibble [1 × …
## 4 b6.4  brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4)        &lt;S3: l… &lt;tibble [5 ×… &lt;tibble [1 × …
## 5 b6.5  brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(m… &lt;S3: l… &lt;tibble [6 ×… &lt;tibble [1 × …
## 6 b6.6  brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(m… &lt;S3: l… &lt;tibble [7 ×… &lt;tibble [1 × …</code></pre>
<p>Our <code>fits</code> object is a <a href="https://tidyr.tidyverse.org/reference/nest.html">nested tibble</a>. To learn more about this bulk approach to fitting models, check out Hadley Wickham’s talk <a href="https://www.youtube.com/watch?v=rz3_FDVt9eg&amp;t=2339s&amp;frags=pl%2Cwn">Managing many models with R</a>. As you might learn in the talk, we can extract the <span class="math inline">\(R^2\)</span> from each model with <code>map_dbl(&quot;r.squared&quot;)</code>, which we’ll then display in a plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fits &lt;-
<span class="st">  </span>fits <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">r2      =</span> glance <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">map_dbl</span>(<span class="st">&quot;r.squared&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">r2_text =</span> <span class="kw">round</span>(r2, <span class="dt">digits =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.character</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">str_replace</span>(., <span class="st">&quot;0.&quot;</span>, <span class="st">&quot;.&quot;</span>))

fits <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> r2, <span class="dt">y =</span> formula, <span class="dt">label =</span> r2_text)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">size =</span> <span class="fl">3.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="kw">expression</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>), <span class="dt">limits =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>, <span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>),
        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),
        <span class="dt">text         =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-6-1.png" width="768" /></p>
<p>If we wanted to look at the model coefficients, we could <code>unnest(tidy)</code> and wrangle a bit.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fits <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(tidy) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(model, term<span class="op">:</span>estimate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate_if</span>(is.double, round, <span class="dt">digits =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">complete</span>(<span class="dt">term =</span> <span class="kw">distinct</span>(., term), model) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> term, <span class="dt">value =</span> estimate) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(model, <span class="st">`</span><span class="dt">(Intercept)</span><span class="st">`</span>, mass, <span class="kw">everything</span>())</code></pre></div>
<pre><code>## # A tibble: 6 x 8
##   model `(Intercept)`       mass `I(mass^2)` `I(mass^3)` `I(mass^4)` `I(mass^5)` `I(mass^6)`
##   &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
## 1 b6.1          -228.       20.7        NA          NA          NA          NA            NA
## 2 b6.2         -2618.      127.         -1.1        NA          NA          NA            NA
## 3 b6.3         21990.    -1474.         32.8        -0.2        NA          NA            NA
## 4 b6.4        322887.   -27946.        892.        -12.4         0.1        NA            NA
## 5 b6.5      -1535342.   180049       -8325.        190.         -2.1         0            NA
## 6 b6.6      10849891. -1473228.      82777       -2463.         40.9        -0.4           0</code></pre>
<p>For Figure 6.3, we’ll make each plot individually and them glue them together with <code>gridExtra::grid.arrange()</code>. Since they all share a common stucture, we’ll start by specifying a base plot which we’ll save as <code>p</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mass, <span class="dt">y =</span> brain)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;body mass (kg)&quot;</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">33</span>, <span class="dv">62</span>), <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">300</span>, <span class="dv">1500</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;brain volume (cc)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p>Now for each subplot, we’ll tack the subplot-specific components onto <code>p</code>. The main action is in <code>stat_smooth()</code>. For each subplot, the first three lines in <code>stat_smooth()</code> are identical, with only the bottom <code>formula</code> line differing. Like McElreath did in the text, we also adjust the y-axis range for the last two plots.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># linear</span>
p1 &lt;-<span class="st"> </span>
<span class="st">  </span>p <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange =</span> <span class="ot">TRUE</span>, <span class="dt">level =</span> .<span class="dv">89</span>,  <span class="co"># Note our rare use of 89% confidence intervals</span>
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], 
              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,
              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span>x) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="ot">NULL</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = .49&quot;</span>)))
  
<span class="co"># quadratic</span>
p2 &lt;-
<span class="st">  </span>p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange =</span> <span class="ot">TRUE</span>, <span class="dt">level =</span> .<span class="dv">89</span>,
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], 
              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,              
              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="ot">NULL</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = .54&quot;</span>)))

<span class="co"># cubic</span>
p3 &lt;-
<span class="st">  </span>p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange =</span> <span class="ot">TRUE</span>, <span class="dt">level =</span> .<span class="dv">89</span>,
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], 
              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,              
              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">3</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="ot">NULL</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = .68&quot;</span>)))

<span class="co"># fourth-order polynomial</span>
p4 &lt;-
<span class="st">  </span>p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange =</span> <span class="ot">TRUE</span>, <span class="dt">level =</span> .<span class="dv">89</span>,
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], 
              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,              
              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">4</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="ot">NULL</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = .81&quot;</span>)))

<span class="co"># fifth-order polynomial</span>
p5 &lt;-
<span class="st">  </span>p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange =</span> <span class="ot">TRUE</span>, <span class="dt">level =</span> .<span class="dv">89</span>,
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], 
              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,              
              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">150</span>, <span class="dv">1900</span>)) <span class="op">+</span><span class="st">  </span><span class="co"># We&#39;re adjusting the y-axis range for this plot (and the next)</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="ot">NULL</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = .99&quot;</span>)))
  
<span class="co"># sixth-order polynomial</span>
p6 &lt;-
<span class="st">  </span>p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">2</span>], <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st">  </span><span class="co"># to mark off 0 on the y-axis</span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange =</span> <span class="ot">TRUE</span>, <span class="dt">level =</span> .<span class="dv">89</span>,
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], 
              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,              
              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x, <span class="dv">6</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">300</span>, <span class="dv">1500</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="ot">NULL</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = 1&quot;</span>)))</code></pre></div>
<p>Okay, now we’re ready to combine the six subplots and produce our version of Figure 6.3.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gridExtra)

<span class="kw">grid.arrange</span>(p1, p2, p3, p4, p5, p6, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-10-1.png" width="576" /></p>
</div>
<div id="too-few-parameters-hurts-too." class="section level3">
<h3><span class="header-section-number">6.1.2</span> Too few parameters hurts, too.</h3>
<p>Fit the intercept only model, <code>b6.7</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b6.<span class="dv">7</span> &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">data =</span> d, 
           brain <span class="op">~</span><span class="st"> </span><span class="dv">1</span>)

<span class="kw">summary</span>(b6.<span class="dv">7</span>)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = brain ~ 1, data = d)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -275.71 -227.21 -101.71   97.79  636.29 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)    713.7      121.8    5.86  0.00109 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 322.2 on 6 degrees of freedom</code></pre>
<p>With the intercept-only model, we didn’t even get an <span class="math inline">\(R^2\)</span> value in the summary.<code>broom::glance()</code> offers a quick way to get one.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">glance</span>(b6.<span class="dv">7</span>)</code></pre></div>
<pre><code>## # A tibble: 1 x 11
##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC deviance df.residual
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;
## 1         0             0  322.        NA      NA     1  -49.8  104.  104.  623061.           6</code></pre>
<p>Zero. Our intercept-only <code>b6.7</code> explained exactly zero variance in <code>brain</code>. All it did was tell us what the unconditional mean and variance (i.e., ‘Residual standard error’) were. I hope that makes sense. They were the only things in the model: <span class="math inline">\(\text{brain}_i \sim \text{Normal}(\mu = \alpha, \sigma)\)</span>. To get the intercept-only model for Figure 6.4, we plug <code>formula = y ~ 1</code> into the <code>stat_smooth()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">fullrange =</span> <span class="ot">TRUE</span>, <span class="dt">level =</span> .<span class="dv">89</span>,
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], 
              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,              
              <span class="dt">formula =</span> y <span class="op">~</span><span class="st"> </span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="ot">NULL</span>, <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(R)<span class="op">^</span><span class="dv">2</span>, <span class="st">&quot; = 0&quot;</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-13-1.png" width="288" /></p>
<div id="overthinking-dropping-rows." class="section level4">
<h4><span class="header-section-number">6.1.2.1</span> Overthinking: Dropping rows.</h4>
<p>You can <code>filter()</code> by <code>row_number()</code> to drop rows in a <a href="https://dplyr.tidyverse.org/reference/slice.html">tidyverse kind of way</a>. For example, we can drop the second row of <code>d</code> like this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> d <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">row_number</span>() <span class="op">!=</span><span class="st"> </span><span class="dv">2</span>)</code></pre></div>
<pre><code>## # A tibble: 6 x 3
##   species     brain  mass
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;
## 1 afarensis     438  37  
## 2 habilis       612  34.5
## 3 boisei        521  41.5
## 4 rudolfensis   752  55.5
## 5 ergaster      871  61  
## 6 sapiens      1350  53.5</code></pre>
<p>We can then extend that logic into a custom function, <code>make_lines()</code>, that will drop a row from <code>d</code>, fit the simple model <code>brain ~ mass</code>, and then use base R <code>predict()</code> to return the model-implied trajectory over new data values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># because these lines are straight, we only need new data over two points of `mass`</span>
nd &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">mass =</span> <span class="kw">c</span>(<span class="dv">30</span>, <span class="dv">70</span>))

make_lines &lt;-<span class="st"> </span><span class="cf">function</span>(row){
  my_fit &lt;-
<span class="st">    </span>d <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">row_number</span>() <span class="op">!=</span><span class="st"> </span>row) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">lm</span>(<span class="dt">formula =</span> brain <span class="op">~</span><span class="st"> </span>mass)

  <span class="kw">predict</span>(my_fit, nd) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">rename</span>(<span class="dt">brain =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">bind_cols</span>(nd)
}</code></pre></div>
<p>Here we’ll make a tibble, <code>lines</code>, which will specify rows 1 through 7 in the <code>row</code> column. We’ll then feed those <code>row</code> numbers into our custom <code>make_lines()</code> function, which will return the predicted values and their corresponding <code>mass</code> values, per model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(
  lines &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">row =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p =</span> <span class="kw">map</span>(row, make_lines)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(p)
  )</code></pre></div>
<pre><code>## # A tibble: 14 x 3
##      row brain  mass
##    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1     1  436.    30
##  2     1 1201.    70
##  3     2  421.    30
##  4     2 1205.    70
##  5     3  323.    30
##  6     3 1264.    70
##  7     4  423.    30
##  8     4 1221.    70
##  9     5  376.    30
## 10     5 1335.    70
## 11     6  332.    30
## 12     6 1433.    70
## 13     7  412.    30
## 14     7  964.    70</code></pre>
<p>Now we’re ready to plot the left panel of Figure 6.5.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> lines, 
            <span class="kw">aes</span>(<span class="dt">x =</span> mass, <span class="dt">y =</span> brain, <span class="dt">group =</span> row),
            <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-17-1.png" width="336" /></p>
<p>To make the right panel for Figure 6.5, we’ll need to increase the number of <code>mass</code> points in our <code>nd</code> data and redefine the <code>make_lines()</code> function to fit the sixth-order-polynomial model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># because these lines will be very curvy, we&#39;ll need new data over many points of `mass`</span>
nd &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">mass =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">30</span>, <span class="dt">to =</span> <span class="dv">65</span>, <span class="dt">length.out =</span> <span class="dv">200</span>))

<span class="co"># redifine the function</span>
make_lines &lt;-<span class="st"> </span><span class="cf">function</span>(row){
  my_fit &lt;-
<span class="st">    </span>d <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(<span class="kw">row_number</span>() <span class="op">!=</span><span class="st"> </span>row) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">lm</span>(<span class="dt">formula =</span> brain <span class="op">~</span><span class="st"> </span>mass <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mass<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mass<span class="op">^</span><span class="dv">3</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mass<span class="op">^</span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mass<span class="op">^</span><span class="dv">5</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(mass<span class="op">^</span><span class="dv">6</span>))

  <span class="kw">predict</span>(my_fit, nd) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">rename</span>(<span class="dt">brain =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">bind_cols</span>(nd)
}

<span class="co"># make our new tibble</span>
lines &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">row =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p =</span> <span class="kw">map</span>(row, make_lines)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(p)

<span class="co"># plot!</span>
p <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> lines, 
            <span class="kw">aes</span>(<span class="dt">group =</span> row),
            <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="op">-</span><span class="dv">300</span><span class="op">:</span><span class="dv">2000</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="336" /></p>
</div>
</div>
</div>
<div id="information-theory-and-model-performance" class="section level2">
<h2><span class="header-section-number">6.2</span> Information theory and model performance</h2>
<blockquote>
<p>Whether you end up using regularization or information criteria or both, the first thing you must do is pick a criterion of model performance. What do you want the model to do well at? We’ll call this criterion the <em>target</em>, and in this section you’ll see how information theory provides a common and useful target, the out-of-sample <em>deviance</em>. (p. 174, <em>emphasis</em> in the original)</p>
</blockquote>
<div id="firing-the-weatherperson." class="section level3">
<h3><span class="header-section-number">6.2.1</span> Firing the weatherperson.</h3>
<p>If you let rain = 1 and sun = 0, here’s a way to make a plot of the first table of page 175, the weatherperson’s predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weatherperson &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">day        =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,
         <span class="dt">prediction =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="fl">0.6</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">7</span>)),
         <span class="dt">observed   =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">7</span>))) 

weatherperson <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>day) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> day, <span class="dt">y =</span> key, <span class="dt">fill =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> value, <span class="dt">color =</span> value <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_discrete</span>(<span class="ot">NULL</span>, <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">direction =</span> <span class="op">-</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;white&quot;</span>, <span class="st">&quot;black&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),
        <span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-19-1.png" width="576" /></p>
<p>Here’s how the newcomer fared:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">newcomer &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">day        =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,
         <span class="dt">prediction =</span> <span class="dv">0</span>,
         <span class="dt">observed   =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="dt">times =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">7</span>)))

newcomer <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>day) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> day, <span class="dt">y =</span> key, <span class="dt">fill =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_tile</span>(<span class="dt">color =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> value, <span class="dt">color =</span> value <span class="op">==</span><span class="st"> </span><span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_discrete</span>(<span class="ot">NULL</span>, <span class="dt">expand =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">direction =</span> <span class="op">-</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;white&quot;</span>, <span class="st">&quot;black&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),
        <span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-20-1.png" width="576" /></p>
<p>If we do the math entailed in the tibbles, we’ll see why the newcomer could boast “I’m the best person for the job” (p. 175).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weatherperson <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_rows</span>(newcomer) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">person =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;weatherperson&quot;</span>, <span class="st">&quot;newcomer&quot;</span>), <span class="dt">each =</span> <span class="kw">n</span>()<span class="op">/</span><span class="dv">2</span>),
         <span class="dt">hit    =</span> <span class="kw">ifelse</span>(prediction <span class="op">==</span><span class="st"> </span>observed, <span class="dv">1</span>, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prediction <span class="op">-</span><span class="st"> </span>observed)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(person) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">hit_rate =</span> <span class="kw">mean</span>(hit))</code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   person        hit_rate
##   &lt;chr&gt;            &lt;dbl&gt;
## 1 newcomer          0.7 
## 2 weatherperson     0.58</code></pre>
<div id="costs-and-benefits." class="section level4">
<h4><span class="header-section-number">6.2.1.1</span> Costs and benefits.</h4>
<p>Our new <code>points</code> variable doesn’t fit into the nice color-based <code>geom_tile()</code> plots from above. But we can still do the math.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weatherperson <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_rows</span>(newcomer) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">person =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;weatherperson&quot;</span>, <span class="st">&quot;newcomer&quot;</span>), <span class="dt">each =</span> <span class="kw">n</span>()<span class="op">/</span><span class="dv">2</span>),
         <span class="dt">points =</span> <span class="kw">ifelse</span>(observed <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>prediction <span class="op">!=</span><span class="st"> </span><span class="dv">1</span>, <span class="op">-</span><span class="dv">5</span>,
                         <span class="kw">ifelse</span>(observed <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>prediction <span class="op">==</span><span class="st"> </span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>,
                                <span class="op">-</span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span>prediction))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(person) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">happiness =</span> <span class="kw">sum</span>(points))</code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   person        happiness
##   &lt;chr&gt;             &lt;dbl&gt;
## 1 newcomer          -15  
## 2 weatherperson      -7.2</code></pre>
</div>
<div id="measuring-accuracy." class="section level4">
<h4><span class="header-section-number">6.2.1.2</span> Measuring accuracy.</h4>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">weatherperson <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_rows</span>(newcomer) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">person =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;weatherperson&quot;</span>, <span class="st">&quot;newcomer&quot;</span>), <span class="dt">each =</span> <span class="kw">n</span>() <span class="op">/</span><span class="st"> </span><span class="dv">2</span>),
         <span class="dt">hit    =</span> <span class="kw">ifelse</span>(prediction <span class="op">==</span><span class="st"> </span>observed, <span class="dv">1</span>, <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>prediction <span class="op">-</span><span class="st"> </span>observed)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(person, hit) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">count</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">power =</span> hit <span class="op">^</span><span class="st"> </span>n,
         <span class="dt">term  =</span> <span class="kw">rep</span>(letters[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dt">times =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(person, term, power) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> term, <span class="dt">value =</span> power) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">probability_correct_sequence =</span> a <span class="op">*</span><span class="st"> </span>b)</code></pre></div>
<pre><code>## # A tibble: 2 x 4
##   person              a     b probability_correct_sequence
##   &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;                        &lt;dbl&gt;
## 1 newcomer      0           1                      0      
## 2 weatherperson 0.00164     1                      0.00164</code></pre>
</div>
</div>
<div id="information-and-uncertainty." class="section level3">
<h3><span class="header-section-number">6.2.2</span> Information and uncertainty.</h3>
<p>The formula for information entropy is:</p>
<p><span class="math display">\[H(p) = - \text{E log} (p_i) = - \sum_{i = 1}^n p_i \text{log} (p_i)\]</span></p>
<p>McElreath put it in words as “the uncertainty contained in a probability distribution is the average log-probability of the event” (p. 178). We’ll compute the information entropy for weather at the first unnamed location, which we’ll call <code>McElreath's house</code>, and <code>Abu Dhabi</code> at once.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">place  =</span> <span class="kw">c</span>(<span class="st">&quot;McElreath&#39;s house&quot;</span>, <span class="st">&quot;Abu Dhabi&quot;</span>),
       <span class="dt">p_rain =</span> <span class="kw">c</span>(.<span class="dv">3</span>, .<span class="dv">01</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_shine =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_rain) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(place) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">H_p =</span> (p_rain <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_rain) <span class="op">+</span><span class="st"> </span>p_shine <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_shine)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mean</span>() <span class="op">*</span><span class="st"> </span><span class="op">-</span><span class="dv">1</span>)</code></pre></div>
<pre><code>## # A tibble: 2 x 4
## # Groups:   place [2]
##   place             p_rain p_shine    H_p
##   &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 McElreath&#39;s house   0.3     0.7  0.611 
## 2 Abu Dhabi           0.01    0.99 0.0560</code></pre>
<p>The uncertainty is less in Abu Dhabi because it rarely rains, there. If you have sun, rain and snow, the entropy for weather is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">7</span>, .<span class="dv">15</span>, .<span class="dv">15</span>)
<span class="op">-</span><span class="kw">sum</span>(p <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p))</code></pre></div>
<pre><code>## [1] 0.8188085</code></pre>
</div>
<div id="from-entropy-to-accuracy." class="section level3">
<h3><span class="header-section-number">6.2.3</span> From entropy to accuracy.</h3>
<p>The formula for the Kullback-Leibler divergence (i.e., K-L divergence) is</p>
<p><span class="math display">\[D_{\text{KL}} (p, q) = \sum_i p_i \big ( \text{log} (p_i) - \text{log} (q_i) \big ) = \sum_i p_i \text{log} \Bigg ( \frac{p_i}{q_i} \Bigg )\]</span></p>
<p>which, in plainer language, is what McElreath described as “the average difference in log probability between the target (p) and model (q)” (p. 179).</p>
<p>In McElreath’s example</p>
<ul>
<li><span class="math inline">\(p_1 = .3\)</span></li>
<li><span class="math inline">\(p_2 = .7\)</span></li>
<li><span class="math inline">\(q_1 = .25\)</span></li>
<li><span class="math inline">\(q_2 = .75\)</span></li>
</ul>
<p>With those values, we can compute <span class="math inline">\(D_{\text{KL}} (p, q)\)</span> within a tibble like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">p_1    =</span> .<span class="dv">3</span>,
       <span class="dt">p_2    =</span> .<span class="dv">7</span>,
       <span class="dt">q_1    =</span> .<span class="dv">25</span>,
       <span class="dt">q_2    =</span> .<span class="dv">75</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d_kl =</span> (p_<span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span>(p_<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">2</span>)))</code></pre></div>
<pre><code>## # A tibble: 1 x 5
##     p_1   p_2   q_1   q_2    d_kl
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
## 1   0.3   0.7  0.25  0.75 0.00640</code></pre>
<p>Our systems in this section are binary (e.g., <span class="math inline">\(q = \lbrace q_i, q_2 \rbrace\)</span>). Thus if you know <span class="math inline">\(q_1 = .3\)</span> you know of a necessity <span class="math inline">\(q_2 = 1 - q_1\)</span>. Therefore we can code the tibble for the next example of when <span class="math inline">\(p = q\)</span> like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">p_1    =</span> .<span class="dv">3</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_2  =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_<span class="dv">1</span>,
         <span class="dt">q_1  =</span> p_<span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">q_2  =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>q_<span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d_kl =</span> (p_<span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span>(p_<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">2</span>)))</code></pre></div>
<pre><code>## # A tibble: 1 x 5
##     p_1   p_2   q_1   q_2  d_kl
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   0.3   0.7   0.3   0.7     0</code></pre>
<p>Building off of that, you can make the data required for Figure 6.6 like this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">p_1  =</span> .<span class="dv">3</span>,
         <span class="dt">p_2  =</span> .<span class="dv">7</span>,
         <span class="dt">q_1  =</span> <span class="kw">seq</span>(<span class="dt">from =</span> .<span class="dv">01</span>, <span class="dt">to =</span> .<span class="dv">99</span>, <span class="dt">by =</span> .<span class="dv">01</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">q_2  =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>q_<span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d_kl =</span> (p_<span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span>(p_<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">2</span>)))

<span class="kw">head</span>(t)</code></pre></div>
<pre><code>## # A tibble: 6 x 5
##     p_1   p_2   q_1   q_2  d_kl
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   0.3   0.7  0.01  0.99 0.778
## 2   0.3   0.7  0.02  0.98 0.577
## 3   0.3   0.7  0.03  0.97 0.462
## 4   0.3   0.7  0.04  0.96 0.383
## 5   0.3   0.7  0.05  0.95 0.324
## 6   0.3   0.7  0.06  0.94 0.276</code></pre>
<p>Now we have the data, plotting Figure 6.6 is a just <code>geom_line()</code> with stylistic flourishes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">t <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> q_<span class="dv">1</span>, <span class="dt">y =</span> d_kl)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> .<span class="dv">3</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">annotate</span>(<span class="dt">geom =</span> <span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> .<span class="dv">4</span>, <span class="dt">y =</span> <span class="fl">1.5</span>, <span class="dt">label =</span> <span class="st">&quot;q = p&quot;</span>,
           <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>, <span class="dt">size =</span> <span class="fl">3.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;q[1]&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;Divergence of q from p&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-29-1.png" width="288" /></p>
<div id="rethinking-divergence-depends-upon-direction." class="section level4">
<h4><span class="header-section-number">6.2.3.1</span> Rethinking: Divergence depends upon direction.</h4>
<p>Here we see <span class="math inline">\(H(p, q) \neq H(q, p)\)</span>. That is, direction matters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">direction =</span> <span class="kw">c</span>(<span class="st">&quot;Earth to Mars&quot;</span>, <span class="st">&quot;Mars to Earth&quot;</span>),
       <span class="dt">p_1    =</span> <span class="kw">c</span>(.<span class="dv">01</span>, .<span class="dv">7</span>),
       <span class="dt">q_1    =</span> <span class="kw">c</span>(.<span class="dv">7</span>, .<span class="dv">01</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_2  =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>p_<span class="dv">1</span>,
         <span class="dt">q_2  =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>q_<span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">d_kl =</span> (p_<span class="dv">1</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">1</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">1</span>)) <span class="op">+</span><span class="st"> </span>(p_<span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p_<span class="dv">2</span> <span class="op">/</span><span class="st"> </span>q_<span class="dv">2</span>)))</code></pre></div>
<pre><code>## # A tibble: 2 x 6
##   direction       p_1   q_1   p_2   q_2  d_kl
##   &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 Earth to Mars  0.01  0.7   0.99  0.3   1.14
## 2 Mars to Earth  0.7   0.01  0.3   0.99  2.62</code></pre>
<p>The <span class="math inline">\(D_{\text{KL}}\)</span> was double when applying Martian estimates to Terran estimates.</p>
</div>
</div>
<div id="from-divergence-to-deviance." class="section level3">
<h3><span class="header-section-number">6.2.4</span> From divergence to deviance.</h3>
<blockquote>
<p>The point of all the preceding material about information theory and divergence is to establish both:</p>
<ol style="list-style-type: decimal">
<li><p>How to measure the distance of a model from our target. Information theory gives us the distance measure we need, the K-L divergence.</p></li>
<li><p>How to estimate the divergence. Having identified the right measure of distance, we now need a way to estimate it in real statistical modeling tasks. (p. 181)</p></li>
</ol>
</blockquote>
<p>Now we’ll start working on item #2.</p>
<p>We define deviance as:</p>
<p><span class="math display">\[D(q) = -2 \sum_i \text{log}(p_i)\]</span></p>
<p>In the formula, <span class="math inline">\(i\)</span> indexes each case and <span class="math inline">\(q_i\)</span> is the likelihood for each case. Here’s the deviance from model <code>b6.1</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lm</span>(<span class="dt">data =</span> d,
   brain <span class="op">~</span><span class="st"> </span>mass) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">logLik</span>() <span class="op">*</span><span class="st"> </span><span class="op">-</span><span class="dv">2</span></code></pre></div>
<pre><code>## &#39;log Lik.&#39; 94.92499 (df=3)</code></pre>
<div id="overthinking-computing-deviance." class="section level4">
<h4><span class="header-section-number">6.2.4.1</span> Overthinking: Computing deviance.</h4>
<p>To follow along with the text, we’ll need to standardize <code>mass</code> before we compute deviance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">mass_s =</span> (mass <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(mass)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(mass))</code></pre></div>
<p>Open brms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(brms)</code></pre></div>
<p>Now we’ll specify the initial values and fit the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Here we specify our starting values</span>
inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Intercept =</span> <span class="kw">mean</span>(d<span class="op">$</span>brain),
              <span class="dt">mass_s    =</span> <span class="dv">0</span>,
              <span class="dt">sigma     =</span> <span class="kw">sd</span>(d<span class="op">$</span>brain))

inits_list &lt;-<span class="st"> </span><span class="kw">list</span>(inits, inits, inits, inits)

<span class="co"># The model</span>
b6.<span class="dv">8</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> gaussian,
      brain <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>mass_s,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1000</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1000</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">inits =</span> inits_list,  <span class="co"># here we insert our start values</span>
      <span class="dt">seed =</span> <span class="dv">6</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b6.<span class="dv">8</span>)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: brain ~ 1 + mass_s 
##    Data: d (Number of observations: 7) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept   709.49    105.07   502.06   922.93       2804 1.00
## mass_s      220.64    109.71    -0.21   439.82       2893 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma   263.87     94.86   148.87   495.15       1746 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p><strong>Details about <code>inits</code></strong>: You don’t have to specify your <code>inits</code> lists outside of the <code>brm()</code> function the way we did, here. This is just how I currently prefer. When you specify start values for the parameters in your Stan models, you need to do so with a list of lists. You need as many lists as HMC chains–four in this example. And then you put your–in this case–four lists inside a list. Lists within lists. Also, we were lazy and specified the same start values across all our chains. You can mix them up across chains if you want.</p>
<p>Anyway, the brms function <code>log_lik()</code> returns a matrix. Each occasion gets a column and each HMC chain iteration gets a row. To make it easier to understand the output, we’ll name the columns by <code>species</code> using the <a href="https://tibble.tidyverse.org/reference/name-repair.html"><code>.name_repair</code> argument</a> within the <code>as_tibble()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ll &lt;-
<span class="st">  </span>b6.<span class="dv">8</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">log_lik</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>(<span class="dt">.name_repair =</span> <span class="op">~</span><span class="st"> </span>d<span class="op">$</span>species)

ll <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 4,000
## Variables: 7
## $ afarensis   &lt;dbl&gt; -6.533346, -7.364236, -6.354499, -6.591231, -6.198465, -6.605723, -6.428844, …
## $ africanus   &lt;dbl&gt; -6.529212, -7.318601, -6.380887, -6.501201, -6.204924, -6.630343, -6.489288, …
## $ habilis     &lt;dbl&gt; -6.684437, -7.078882, -6.924421, -6.465999, -6.729976, -6.965095, -7.075861, …
## $ boisei      &lt;dbl&gt; -6.543591, -7.261918, -6.397131, -6.604107, -6.196515, -6.603495, -6.416063, …
## $ rudolfensis &lt;dbl&gt; -6.947669, -7.070620, -7.095121, -6.729509, -6.196600, -6.611958, -6.591881, …
## $ ergaster    &lt;dbl&gt; -7.387421, -7.009474, -7.415504, -6.694015, -6.203039, -6.609322, -6.669332, …
## $ sapiens     &lt;dbl&gt; -11.396992, -7.490887, -7.742427, -8.074139, -11.303673, -8.671387, -8.576077…</code></pre>
<p>Deviance is the sum of the occasion-level LLs multiplied by -2. Why by -2? “The -2 in front doesn’t do anything important. It’s there for historical reasons” (p. 182). If you follow footnote 93 at the end of that sentence in the text, you’ll learn “under somewhat general conditions, for many common model types, a difference between two deviances has a chi-squared distribution. The factor of 2 is there to scale it that way” (p. 451).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ll &lt;-
<span class="st">  </span>ll <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sums     =</span> <span class="kw">rowSums</span>(.),
         <span class="dt">deviance =</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sums)</code></pre></div>
<p>Because we used HMC, deviance is a distribution rather than a single number.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidybayes)

ll <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> deviance, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>],
                <span class="dt">point_interval =</span> median_qi, <span class="dt">.width =</span> .<span class="dv">95</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">quantile</span>(ll<span class="op">$</span>deviance, <span class="kw">c</span>(.<span class="dv">025</span>, .<span class="dv">5</span>, .<span class="dv">975</span>)),
                     <span class="dt">labels =</span> <span class="kw">quantile</span>(ll<span class="op">$</span>deviance, <span class="kw">c</span>(.<span class="dv">025</span>, .<span class="dv">5</span>, .<span class="dv">975</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;The deviance distribution&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-37-1.png" width="360" /></p>
<p>But notice our deviance distribution was centered right around the sole value McElreath reported in the text.</p>
</div>
</div>
<div id="from-deviance-to-out-of-sample." class="section level3">
<h3><span class="header-section-number">6.2.5</span> From deviance to out-of-sample.</h3>
<blockquote>
<p>Deviance is a principled way to measure distance from the target. But deviance as computed in the previous section has the same flaw as <span class="math inline">\(R^2\)</span>: It always improves as the model gets more complex, at least for the types of models we have considered so far. Just like <span class="math inline">\(R^2\)</span>, deviance in-sample is a measure of retrodictive accuracy, not predictive accuracy.</p>
</blockquote>
<p>In the next subsection, we’ll see this in a simulation.</p>
<div id="overthinking-simulated-training-and-testing." class="section level4">
<h4><span class="header-section-number">6.2.5.1</span> Overthinking: Simulated training and testing.</h4>
<p>I find the <code>rethinking::sim.train.test()</code> function opaque. If you’re curious, you can find McElreath’s code <a href="https://github.com/rmcelreath/rethinking/blob/a309712d904d1db7af1e08a76c521ab994006fd5/R/sim_train_test.R">here</a>. Let’s simulate and see what happens.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)

n       &lt;-<span class="st"> </span><span class="dv">20</span>
kseq    &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">5</span>
<span class="co"># I&#39;ve reduced this number by one order of magnitude to reduce computation time</span>
n_sim   &lt;-<span class="st"> </span><span class="fl">1e3</span>
n_cores &lt;-<span class="st"> </span><span class="dv">4</span>

<span class="co"># here&#39;s our dev object based on `N &lt;- 20`</span>
dev_<span class="dv">20</span> &lt;-
<span class="st">  </span><span class="kw">sapply</span>(kseq, <span class="cf">function</span>(k) {
    <span class="kw">print</span>(k);
    r &lt;-<span class="st"> </span><span class="kw">mcreplicate</span>(n_sim, <span class="kw">sim.train.test</span>(<span class="dt">N =</span> n, <span class="dt">k =</span> k),
                     <span class="dt">mc.cores =</span> n_cores);
    <span class="kw">c</span>(<span class="kw">mean</span>(r[<span class="dv">1</span>, ]), <span class="kw">mean</span>(r[<span class="dv">2</span>, ]), <span class="kw">sd</span>(r[<span class="dv">1</span>, ]), <span class="kw">sd</span>(r[<span class="dv">2</span>, ]))
    })

<span class="co"># here&#39;s our dev object based on N &lt;- 100</span>
n       &lt;-<span class="st"> </span><span class="dv">100</span>
dev_<span class="dv">100</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">sapply</span>(kseq, <span class="cf">function</span>(k) {
    <span class="kw">print</span>(k);
    r &lt;-<span class="st"> </span><span class="kw">mcreplicate</span>(n_sim, <span class="kw">sim.train.test</span>(<span class="dt">N =</span> n, <span class="dt">k =</span> k), 
                     <span class="dt">mc.cores =</span> n_cores);
    <span class="kw">c</span>(<span class="kw">mean</span>(r[<span class="dv">1</span>, ]), <span class="kw">mean</span>(r[<span class="dv">2</span>, ]), <span class="kw">sd</span>(r[<span class="dv">1</span>, ]), <span class="kw">sd</span>(r[<span class="dv">2</span>, ]))
    })</code></pre></div>
<p>If you didn’t quite catch it, the simulation yields <code>dev_20</code> and <code>dev_100</code>. We’ll want to convert them to tibbles, bind them together, and wrangle extensively before we’re ready to plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dev_tibble &lt;-
<span class="st">  </span>dev_<span class="dv">20</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_rows</span>(
    dev_<span class="dv">100</span> <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">as_tibble</span>()
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n         =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;n = 20&quot;</span>, <span class="st">&quot;n = 100&quot;</span>), <span class="dt">each =</span> <span class="dv">4</span>),
         <span class="dt">statistic =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;sd&quot;</span>), <span class="dt">each =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rep</span>(., <span class="dt">times =</span> <span class="dv">2</span>),
         <span class="dt">sample    =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;in&quot;</span>, <span class="st">&quot;out&quot;</span>), <span class="dt">times =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rep</span>(., <span class="dt">times =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(n_par, value, <span class="op">-</span>n, <span class="op">-</span>statistic, <span class="op">-</span>sample) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> statistic, <span class="dt">value =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n     =</span> <span class="kw">factor</span>(n, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;n = 20&quot;</span>, <span class="st">&quot;n = 100&quot;</span>)),
         <span class="dt">n_par =</span> <span class="kw">str_remove</span>(n_par, <span class="st">&quot;V&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.double</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_par =</span> <span class="kw">ifelse</span>(sample <span class="op">==</span><span class="st"> &quot;in&quot;</span>, n_par <span class="op">-</span><span class="st"> </span>.<span class="dv">075</span>, n_par <span class="op">+</span><span class="st"> </span>.<span class="dv">075</span>))</code></pre></div>
<pre><code>## Warning: `as_tibble.matrix()` requires a matrix with column names or a `.name_repair` argument. Using compatibility `.name_repair`.
## This warning is displayed once per session.</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(dev_tibble)</code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   n       sample n_par  mean    sd
##   &lt;fct&gt;   &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 n = 100 in     0.925  283.  14.1
## 2 n = 100 in     1.92   279.  13.9
## 3 n = 100 in     2.92   263.  11.1
## 4 n = 100 in     3.92   263.  11.2
## 5 n = 100 in     4.92   262.  11.2
## 6 n = 100 out    1.08   285.  14.4</code></pre>
<p>Now we’re ready to make Figure 6.7.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># this intermediary tibble will make `geom_text()` easier</span>
dev_text &lt;-
<span class="st">  </span>dev_tibble <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(n_par <span class="op">&gt;</span><span class="st"> </span><span class="fl">1.5</span>, 
         n_par <span class="op">&lt;</span><span class="st"> </span><span class="fl">2.5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_par =</span> <span class="kw">ifelse</span>(sample <span class="op">==</span><span class="st"> &quot;in&quot;</span>, n_par <span class="op">-</span><span class="st"> </span>.<span class="dv">2</span>, n_par <span class="op">+</span><span class="st"> </span>.<span class="dv">28</span>))
  
<span class="co"># the plot</span>
dev_tibble <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x     =</span> n_par, <span class="dt">y =</span> mean,
             <span class="dt">ymin  =</span> mean <span class="op">-</span><span class="st"> </span>sd, <span class="dt">ymax =</span> mean <span class="op">+</span><span class="st"> </span>sd,
             <span class="dt">group =</span> sample,
             <span class="dt">color =</span> sample, 
             <span class="dt">fill  =</span> sample)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> dev_text,
            <span class="kw">aes</span>(<span class="dt">label =</span> sample)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>])) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values  =</span> <span class="kw">c</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>])) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;number of parameters&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;deviance&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text             =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">legend.position  =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">1</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>), <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>n, <span class="dt">scale =</span> <span class="st">&quot;free_y&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-41-1.png" width="576" /></p>
<p>Even with a substantially smaller <span class="math inline">\(N\)</span>, our simulation results matched up well with those in the text.</p>
</div>
</div>
</div>
<div id="regularization" class="section level2">
<h2><span class="header-section-number">6.3</span> Regularization</h2>
<blockquote>
<p>The root of overfitting is a model’s tendency to get overexcited by the training sample… One way to prevent a model from getting too excited by the training sample is to give it a skeptical prior. By “skeptical,” I mean a prior that slows the rate of learning from the sample. (p. 186)</p>
</blockquote>
<p>In case you were curious, here’s how you might do Figure 6.8 with ggplot2. All the action is in the <code>geom_ribbon()</code> portions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="op">-</span><span class="st"> </span><span class="fl">3.5</span>, 
               <span class="dt">to   =</span> <span class="fl">3.5</span>, 
               <span class="dt">by   =</span> .<span class="dv">01</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">ymin =</span> <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymax =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="fl">0.2</span>)), 
              <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymax =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="fl">0.5</span>)), 
              <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymax =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)), 
              <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;parameter value&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-42-1.png" width="288" /></p>
<p>In our version of the plot, darker purple = more regularizing.</p>
<p>But to prepare for Figure 6.9, let’s simulate. This time we’ll wrap the basic simulation code we used before into a function we’ll call <code>make_sim()</code>. Our <code>make_sim()</code> function has two parameters, <code>N</code> and <code>b_sigma</code>, both of which come from McElreath’s simulation code. So you’ll note that instead of hard coding the values for <code>N</code> and <code>b_sigma</code> within the simulation, we’re leaving them adjustable (i.e., <code>sim.train.test(N = n, k = k, b_sigma = b_sigma)</code>). Also notice that instead of saving the simulation results as objects, like before, we’re just converting them to tibbles with the <code>as_tibble()</code> function at the bottom. Our goal is to use <code>make_sim()</code> within a <code>purrr::map2()</code> statement. The result will be a nested tibble into which we’ve saved the results of 6 simulations based off of two sample sizes (i.e., <code>n = c(20, 100)</code>) and three values of <span class="math inline">\(\sigma\)</span> for our Gaussian <span class="math inline">\(\beta\)</span> prior (i.e., <code>b_sigma = c(1, .5, .2)</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)

<span class="co"># I&#39;ve reduced this number by one order of magnitude to reduce computation time</span>
n_sim &lt;-<span class="st"> </span><span class="fl">1e3</span>

make_sim &lt;-<span class="st"> </span><span class="cf">function</span>(n, b_sigma){
  <span class="kw">sapply</span>(kseq, <span class="cf">function</span>(k) {
    <span class="kw">print</span>(k);
    r &lt;-<span class="st"> </span><span class="kw">mcreplicate</span>(n_sim, <span class="kw">sim.train.test</span>(<span class="dt">N =</span> n, <span class="dt">k =</span> k, <span class="dt">b_sigma =</span> b_sigma),  <span class="co"># this is an augmented line of code</span>
                     <span class="dt">mc.cores =</span> n_cores);
    <span class="kw">c</span>(<span class="kw">mean</span>(r[<span class="dv">1</span>, ]), <span class="kw">mean</span>(r[<span class="dv">2</span>, ]), <span class="kw">sd</span>(r[<span class="dv">1</span>, ]), <span class="kw">sd</span>(r[<span class="dv">2</span>, ])) }) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>
<span class="st">    </span><span class="co"># this is a new line of code</span>
<span class="st">    </span><span class="kw">as_tibble</span>()
}

s &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">n       =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">20</span>, <span class="dv">100</span>), <span class="dt">each =</span> <span class="dv">3</span>),
         <span class="dt">b_sigma =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">1</span>, .<span class="dv">5</span>, .<span class="dv">2</span>), <span class="dt">times =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim     =</span> <span class="kw">map2</span>(n, b_sigma, make_sim)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>()</code></pre></div>
<p>We’ll follow the same principles for wrangling these data as we did those from the previous simulation, <code>dev_tibble</code>. And after wrangling, we’ll feed the data directly into the code for our version of Figure 6.9.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># wrangle the simulation data</span>
s <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">statistic =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;sd&quot;</span>), <span class="dt">each =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rep</span>(., <span class="dt">times =</span> <span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span>),
         <span class="dt">sample    =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;in&quot;</span>, <span class="st">&quot;out&quot;</span>), <span class="dt">times =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rep</span>(., <span class="dt">times =</span> <span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(n_par, value, <span class="op">-</span>n, <span class="op">-</span>b_sigma, <span class="op">-</span>statistic, <span class="op">-</span>sample) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> statistic, <span class="dt">value =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n     =</span> <span class="kw">str_c</span>(<span class="st">&quot;n = &quot;</span>, n) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">factor</span>(., <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;n = 20&quot;</span>, <span class="st">&quot;n = 100&quot;</span>)),
         <span class="dt">n_par =</span> <span class="kw">str_remove</span>(n_par, <span class="st">&quot;V&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.double</span>())  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># now plot</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n_par, <span class="dt">y =</span> mean,
             <span class="dt">group =</span> <span class="kw">interaction</span>(sample, b_sigma))) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> sample, <span class="dt">size =</span> b_sigma <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.character</span>())) <span class="op">+</span>
<span class="st">  </span><span class="co"># this function contains the data from the previous simulation</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> dev_tibble, 
             <span class="kw">aes</span>(<span class="dt">group =</span> sample, <span class="dt">fill =</span> sample),
             <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">size =</span> <span class="fl">2.5</span>, <span class="dt">stroke =</span> .<span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>])) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>])) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_size_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="dv">1</span>, .<span class="dv">5</span>, .<span class="dv">2</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;number of parameters&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;deviance&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text             =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">legend.position  =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">1</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>), <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>n, <span class="dt">scale =</span> <span class="st">&quot;free_y&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-45-1.png" width="576" /></p>
<p>Our results don’t perfectly align with those in the text. I suspect his is because we used <code>1e3</code> iterations, rather than the <code>1e4</code> of the text. If you’d like to wait all night long for the simulation to yield more stable results, be my guest.</p>
<blockquote>
<p>Regularizing priors are great, because they reduce overfitting. But if they are too skeptical, they prevent the model from learning from the data. So to use them effectively, you need some way to tune them. Tuning them isn’t always easy. (p. 187)</p>
</blockquote>
<p>For more on this how to choose your priors, consider Gelman, Simpson, and Betancourt’s <a href="https://arxiv.org/abs/1708.07487"><em>The prior can generally only be understood in the context of the likelihood</em></a>, a paper that will probably make more sense after Chapter 8. And if you’re feeling feisty, also check out Simpson’s related blog post <a href="http://andrewgelman.com/2017/09/05/never-total-eclipse-prior/"><em>(It’s never a) Total Eclipse of the Prior</em></a>.</p>
<div id="rethinking-ridge-regression." class="section level4">
<h4><span class="header-section-number">6.3.0.1</span> Rethinking: Ridge regression.</h4>
<p>Within the brms framework, you can do something like this with the horseshoe prior via the <code>horseshoe()</code> function. You can learn all about it from the <code>horseshoe</code> section of the <a href="https://cran.r-project.org/web/packages/brms/brms.pdf">brms reference manual (version 2.8.0)</a>. Here’s an extract from the section:</p>
<blockquote>
<p>The horseshoe prior is a special shrinkage prior initially proposed by <a href="http://proceedings.mlr.press/v5/carvalho09a/carvalho09a.pdf">Carvalho et al. (2009)</a>. It is symmetric around zero with fat tails and an infinitely large spike at zero. This makes it ideal for sparse models that have many regression coefficients, although only a minority of them is non- zero. The horseshoe prior can be applied on all population-level effects at once (excluding the intercept) by using <code>set_prior(&quot;horseshoe(1)&quot;)</code>. (p. 70)</p>
</blockquote>
<p>And to dive even deeper into the horseshoe prior, check out Michael Betancourt’s tutorial, <a href="https://betanalpha.github.io/assets/case_studies/bayes_sparse_regression.html#35_the_horseshoe"><em>Bayes Sparse Regression</em></a>.</p>
</div>
</div>
<div id="information-criteria" class="section level2">
<h2><span class="header-section-number">6.4</span> Information criteria</h2>
<p>The data from our initial simulation isn’t formatted well to plot Figure 6.10. We’ll have to wrangle a little.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(
  dev_tibble &lt;-
<span class="st">  </span>dev_tibble <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>sd) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_par  =</span> <span class="kw">ifelse</span>(sample <span class="op">==</span><span class="st"> &quot;in&quot;</span>, n_par <span class="op">+</span><span class="st"> </span>.<span class="dv">075</span>, n_par <span class="op">-</span><span class="st"> </span>.<span class="dv">075</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> sample, <span class="dt">value =</span> mean) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">height =</span> (out <span class="op">-</span><span class="st"> `</span><span class="dt">in</span><span class="st">`</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.character</span>(),
         <span class="dt">dash   =</span> <span class="st">`</span><span class="dt">in</span><span class="st">`</span> <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>n_par)
)</code></pre></div>
<pre><code>## # A tibble: 10 x 6
##    n       n_par  `in`   out height  dash
##    &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;
##  1 n = 20      1  55.6  57.4 1.8     57.6
##  2 n = 20      2  54.4  58.1 3.7     58.4
##  3 n = 20      3  50.6  55.9 5.3     56.6
##  4 n = 20      4  49.5  57.7 8.1     57.5
##  5 n = 20      5  49.0  58.8 9.8     59.0
##  6 n = 100     1 283.  285.  2.6    285. 
##  7 n = 100     2 279.  283.  3.6    283. 
##  8 n = 100     3 263.  268.  5.2    269. 
##  9 n = 100     4 263.  269.  6      271. 
## 10 n = 100     5 262.  270.  8      272.</code></pre>
<p>Now we’re ready to plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dev_tibble  <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n_par)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> dash),
            <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> <span class="st">`</span><span class="dt">in</span><span class="st">`</span>),
             <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> out),
             <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n_par <span class="op">+</span><span class="st"> </span>.<span class="dv">15</span>,
                    <span class="dt">ymin =</span> <span class="st">`</span><span class="dt">in</span><span class="st">`</span>, <span class="dt">ymax =</span> out),
                <span class="dt">width =</span> .<span class="dv">1</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n_par <span class="op">+</span><span class="st"> </span>.<span class="dv">4</span>,
                <span class="dt">y =</span> (out <span class="op">+</span><span class="st"> `</span><span class="dt">in</span><span class="st">`</span>) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>,
                <span class="dt">label =</span> height),
            <span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>, <span class="dt">size =</span> <span class="dv">3</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;number of parameters&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;deviance&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text             =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">1</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>), <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>n, <span class="dt">scale =</span> <span class="st">&quot;free_y&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-47-1.png" width="576" /></p>
<p>Again, our numbers aren’t the exact same as McElreath’s because a) this is a simulation and b) our number of simulations was an order of magnitude smaller than his. But the overall pattern is the same. More to the point, the distances between the in- and out-of-sample points</p>
<blockquote>
<p>are nearly the same, for each model, at both <span class="math inline">\(N = 20\)</span> (left) and <span class="math inline">\(N = 100\)</span> (right). Each distance is nearly twice the number of parameters, as labeled on the horizontal axis. The dashed lines show exactly the [dark purple] points plus twice the number of parameters, tracing closely along the average out-of-sample deviance for each model.</p>
<p>This is the phenomenon behind information criteria. (p. 189)</p>
</blockquote>
<p>In the text, McElreach focused on the DIC and WAIC. As you’ll see, the LOO has increased in popularity since he published the text. Going forward, we’ll juggle the WAIC and the LOO in this project. But we will respect the text and work in a little DIC talk.</p>
<div id="dic." class="section level3">
<h3><span class="header-section-number">6.4.1</span> DIC.</h3>
<p>The DIC has been widely used for some time, now. For a great talk on the DIC, check out the authoritative David Spiegelhalter’s <a href="https://www.youtube.com/watch?v=H-59eqmHuuQ&amp;frags=pl%2Cwn"><em>Retrospective read paper: Bayesian measure of model complexity and fit</em></a>. If we define <span class="math inline">\(D\)</span> as the deviance’s posterior distribution, <span class="math inline">\(\bar{D}\)</span> as its mean and <span class="math inline">\(\hat{D}\)</span> as the deviance when computed at the posterior mean, then we define the DIC as</p>
<p><span class="math display">\[\text{DIC} = \bar{D} + (\bar{D} + \hat{D}) + \bar{D} + p_D\]</span></p>
<p>And <span class="math inline">\(p_D\)</span> is the number of effective parameters in the model, which is also sometimes referred to as the penalty term. As you’ll see, you can get the <span class="math inline">\(p_D\)</span> for <code>brms::brm()</code> models. However, I’m not aware of a way to that brms or the loo package–to be introduced shortly–offer convenience functions that yield the DIC.</p>
</div>
<div id="waic." class="section level3">
<h3><span class="header-section-number">6.4.2</span> WAIC.</h3>
<p>It’s okay that the brms and loo packages don’t yield the DIC because</p>
<blockquote>
<p>even better than the DIC is the Widely Applicable Information Criterion (WAIC)…</p>
<p>Define <span class="math inline">\(\text{Pr} (y_i)\)</span> as the average likelihood of observation <span class="math inline">\(i\)</span> in the training sample. This means we compute the likelihood of <span class="math inline">\(y_i\)</span> for each set of parameters sampled from the posterior distribution. Then we average the likelihoods for each observation <span class="math inline">\(i\)</span> and finally sum over all observations. This produces the first part of WAIC, the log-pointwise-predictive-density, lppd:</p>
<p><span class="math display">\[\text{lppd} = \sum_{i = 1}^N \text{log Pr} (y_i)\]</span></p>
<p>You might say this out loud as:</p>
<blockquote>
<p><em>The log-pointwise-predictive-density is the total across observations of the logarithm of the average likelihood of each observation.</em></p>
</blockquote>
<p>… The second piece of WAIC is the effect number of parameters <span class="math inline">\(p_{\text{WAIC}}\)</span>. Define <span class="math inline">\(V(y_i)\)</span> as the variance in log-likelihood for observation <span class="math inline">\(i\)</span> in the training sample. This means we compute the log-likelihood for observation <span class="math inline">\(y_i\)</span> for each sample from the posterior distribution. Then we take the variance of those values. This is <span class="math inline">\(V(y_i)\)</span>. Now <span class="math inline">\(p_{\text{WAIC}}\)</span> is defined as:</p>
<p><span class="math display">\[p_{\text{WAIC}} = \sum_{i=1}^N V (y_i)\]</span></p>
<p>Now WAIC is defined as:</p>
<p><span class="math display">\[\text{WAIC} = -2 (\text{lppd} - p_{\text{WAIC}})\]</span></p>
<p>And this value is yet another estimate of out-of-sample deviance. (pp. 191–192)</p>
</blockquote>
<p>You’ll see how to compute the WAIC in brms in just a bit.</p>
<div id="overthinking-waic-calculation." class="section level4">
<h4><span class="header-section-number">6.4.2.1</span> Overthinking: WAIC calculation.</h4>
<p>Here is how to fit the pre-WAIC model in brms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(cars)

b &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> cars, <span class="dt">family =</span> gaussian,
      dist <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>speed,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">30</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">seed =</span> <span class="dv">6</span>)</code></pre></div>
<p>Here’s the summary.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b)</code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: dist ~ 1 + speed 
##    Data: cars (Number of observations: 50) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept   -17.40      7.07   -30.97    -3.67       1920 1.00
## speed         3.92      0.44     3.07     4.75       1783 1.00
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sigma    15.83      1.69    12.98    19.47       2068 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>In brms, you return the loglikelihood with <code>log_lik()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ll &lt;-
<span class="st">  </span>b <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">log_lik</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>()</code></pre></div>
<p>Computing the lppd, the “Bayesian deviance”, takes a bit of leg work.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfmean &lt;-
<span class="st">  </span>ll <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">exp</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_all</span>(mean) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(key, means) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(means) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">log</span>()

(
  lppd &lt;-
<span class="st">  </span>dfmean <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sum</span>()
)</code></pre></div>
<pre><code>## [1] -206.6836</code></pre>
<p>Comupting the effective number of parameters, <span class="math inline">\(p_{\text{WAIC}}\)</span>, isn’t much better.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfvar &lt;-
<span class="st">  </span>ll <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise_all</span>(var) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(key, vars) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(vars) 

pwaic &lt;-
<span class="st">  </span>dfvar <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sum</span>()

pwaic</code></pre></div>
<pre><code>## [1] 3.418859</code></pre>
<p>Finally, here’s what we’ve been working so hard for: our hand calculated WAIC value. Compare it to the value returned by the brms <code>waic()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(lppd <span class="op">-</span><span class="st"> </span>pwaic)</code></pre></div>
<pre><code>## [1] 420.205</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">waic</span>(b)</code></pre></div>
<pre><code>## 
## Computed from 4000 by 50 log-likelihood matrix
## 
##           Estimate   SE
## elpd_waic   -210.1  6.4
## p_waic         3.4  1.2
## waic         420.2 12.7</code></pre>
<p>Before we move on, did you notice the <code>elpd_waic</code> row in the tibble <code>waic()</code> returned? That value is the <code>lppd</code> minus the <code>pwaic</code>, but without multiplying the result by -2. E.g.,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lppd <span class="op">-</span><span class="st"> </span>pwaic</code></pre></div>
<pre><code>## [1] -210.1025</code></pre>
<p>That tidbit will come in handy a little bit later. But for now, here’s how we compute the WAIC standard error.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfmean <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">waic_vec   =</span> <span class="op">-</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(means <span class="op">-</span><span class="st"> </span>dfvar<span class="op">$</span>vars)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">waic_se =</span> (<span class="kw">var</span>(waic_vec) <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(dfmean)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">sqrt</span>())</code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   waic_se
##     &lt;dbl&gt;
## 1    12.7</code></pre>
</div>
</div>
<div id="dic-and-waic-as-estimates-of-deviance." class="section level3">
<h3><span class="header-section-number">6.4.3</span> DIC and WAIC as estimates of deviance.</h3>
<p>Once again, we’ll wrap McElreath’s <code>sim.train.test()</code>-based simulation code within a custom function, <code>make_sim()</code>. This time we’ve adjusted <code>make_sim()</code> to take one argument, <code>b_sigma</code>. We will then feed that value into the same-named argument within <code>sim.train.test()</code>. Also notice that within <code>sim.train.test()</code>, we’ve specified <code>TRUE</code> for the information criteria and deviance arguments. Be warned: it takes extra time to compute the WAIC. Because we do that for every model, this simulation takes longer than the previous ones. To get a taste, try running it with something like <code>n_sim &lt;- 5</code> first.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n_sim &lt;-<span class="st"> </span><span class="fl">1e3</span>

make_sim &lt;-<span class="st"> </span><span class="cf">function</span>(b_sigma){
  <span class="kw">sapply</span>(kseq, <span class="cf">function</span>(k) {
    <span class="kw">print</span>(k);
    r &lt;-<span class="st"> </span><span class="kw">mcreplicate</span>(n_sim, 
                     <span class="kw">sim.train.test</span>(<span class="dt">N         =</span> <span class="dv">20</span>,
                                    <span class="dt">k         =</span> k,
                                    <span class="dt">b_sigma   =</span> b_sigma,
                                    <span class="dt">DIC       =</span> T,
                                    <span class="dt">WAIC      =</span> T, 
                                    <span class="dt">devbar    =</span> T, 
                                    <span class="dt">devbarout =</span> T),
                     <span class="dt">mc.cores =</span> n_cores);
    
    <span class="kw">c</span>(<span class="dt">dev_in    =</span> <span class="kw">mean</span>(r[<span class="dv">1</span>, ]),
      <span class="dt">dev_out   =</span> <span class="kw">mean</span>(r[<span class="dv">2</span>, ]),
      <span class="dt">DIC       =</span> <span class="kw">mean</span>(r[<span class="dv">3</span>, ]), 
      <span class="dt">WAIC      =</span> <span class="kw">mean</span>(r[<span class="dv">4</span>, ]), 
      <span class="dt">devbar    =</span> <span class="kw">mean</span>(r[<span class="dv">5</span>, ]), 
      <span class="dt">devbarout =</span> <span class="kw">mean</span>(r[<span class="dv">6</span>, ])) 
  }
  ) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">rownames_to_column</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">rename</span>(<span class="dt">statistic =</span> rowname)
}

s &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">b_sigma =</span> <span class="kw">c</span>(<span class="dv">100</span>, .<span class="dv">5</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sim =</span> purrr<span class="op">::</span><span class="kw">map</span>(b_sigma, make_sim)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>()</code></pre></div>
<p>Here we wrangle and plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">s <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(n_par, value, <span class="op">-</span>b_sigma, <span class="op">-</span>statistic) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">n_par =</span> <span class="kw">str_remove</span>(n_par, <span class="st">&quot;X&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.double</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(statistic <span class="op">!=</span><span class="st"> &quot;devbar&quot;</span> <span class="op">&amp;</span><span class="st"> </span>statistic <span class="op">!=</span><span class="st"> &quot;devbarout&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> statistic, <span class="dt">value =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(ic, value, <span class="op">-</span>b_sigma, <span class="op">-</span>n_par, <span class="op">-</span>dev_in, <span class="op">-</span>dev_out) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(sample, deviance, <span class="op">-</span>b_sigma, <span class="op">-</span>n_par, <span class="op">-</span>ic, <span class="op">-</span>value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(sample <span class="op">==</span><span class="st"> &quot;dev_out&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">b_sigma =</span> b_sigma <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.character</span>()) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n_par)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> deviance, <span class="dt">color =</span> b_sigma),
             <span class="dt">size =</span> <span class="fl">2.5</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> value, <span class="dt">group =</span> b_sigma, <span class="dt">color =</span> b_sigma)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>])) <span class="op">+</span>
<span class="st">  </span><span class="co"># scale_color_manual(values = c(&quot;steelblue&quot;, &quot;black&quot;)) +</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;n = 20&quot;</span>,
       <span class="dt">x =</span> <span class="st">&quot;number of parameters&quot;</span>,
       <span class="dt">y =</span> <span class="st">&quot;deviance&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text             =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">1</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>), <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)),
        <span class="dt">legend.position  =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>ic, <span class="dt">ncol =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-57-1.png" width="312" /></p>
<p>And again, our results don’t perfectly match those in the text because a) we’re simulating and b) we used fewer iterations than McElreath did. But the overall pattern remains.</p>
</div>
</div>
<div id="using-information-criteria" class="section level2">
<h2><span class="header-section-number">6.5</span> Using information criteria</h2>
<p>In contrast to model selection, “this section provides a brief example of model <em>comparison</em> and <em>averaging</em>” (p. 195, <em>emphasis</em> in the original).</p>
<div id="model-comparison." class="section level3">
<h3><span class="header-section-number">6.5.1</span> Model comparison.</h3>
<p>Load the <code>milk</code> data from earlier in the text.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">data</span>(milk)

d &lt;-<span class="st"> </span>
<span class="st">  </span>milk <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">drop_na</span>(<span class="kw">ends_with</span>(<span class="st">&quot;_s&quot;</span>))
<span class="kw">rm</span>(milk)

d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">neocortex =</span> neocortex.perc <span class="op">/</span><span class="st"> </span><span class="dv">100</span>)</code></pre></div>
<p>The dimensions of <code>d</code> are:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(d)</code></pre></div>
<pre><code>## [1] 17  9</code></pre>
<p>Load brms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)</code></pre></div>
<p>We’re ready to fit the competing <code>kcal.per.g</code> models. Note our use of <code>update()</code> in the last two models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Intercept =</span> <span class="kw">mean</span>(d<span class="op">$</span>kcal.per.g),
              <span class="dt">sigma     =</span> <span class="kw">sd</span>(d<span class="op">$</span>kcal.per.g))

inits_list &lt;-<span class="kw">list</span>(inits, inits, inits, inits)

b6.<span class="dv">11</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> gaussian,
      kcal.per.g <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="op">-</span><span class="dv">1000</span>, <span class="dv">1000</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">inits =</span> inits_list,
      <span class="dt">seed =</span> <span class="dv">6</span>)

inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Intercept =</span> <span class="kw">mean</span>(d<span class="op">$</span>kcal.per.g),
              <span class="dt">neocortex =</span> <span class="dv">0</span>,
              <span class="dt">sigma     =</span> <span class="kw">sd</span>(d<span class="op">$</span>kcal.per.g))
inits_list &lt;-<span class="kw">list</span>(inits, inits, inits, inits)

b6.<span class="dv">12</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> gaussian,
      kcal.per.g <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>neocortex,
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="op">-</span><span class="dv">1000</span>, <span class="dv">1000</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="op">-</span><span class="dv">1000</span>, <span class="dv">1000</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">100</span>), <span class="dt">class =</span> sigma)),
      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,
      <span class="dt">inits =</span> inits_list,
      <span class="dt">seed =</span> <span class="dv">6</span>)

inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Intercept   =</span> <span class="kw">mean</span>(d<span class="op">$</span>kcal.per.g),
              <span class="st">`</span><span class="dt">log(mass)</span><span class="st">`</span> =<span class="st"> </span><span class="dv">0</span>,
              <span class="dt">sigma       =</span> <span class="kw">sd</span>(d<span class="op">$</span>kcal.per.g))
inits_list &lt;-<span class="kw">list</span>(inits, inits, inits, inits)

b6.<span class="dv">13</span> &lt;-
<span class="st">  </span><span class="kw">update</span>(b6.<span class="dv">12</span>, 
         <span class="dt">newdata =</span> d,
         <span class="dt">formula =</span> kcal.per.g <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(mass),
         <span class="dt">inits   =</span> inits_list)

inits &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Intercept   =</span> <span class="kw">mean</span>(d<span class="op">$</span>kcal.per.g),
              <span class="dt">neocortex   =</span> <span class="dv">0</span>,
              <span class="st">`</span><span class="dt">log(mass)</span><span class="st">`</span> =<span class="st"> </span><span class="dv">0</span>,
              <span class="dt">sigma       =</span> <span class="kw">sd</span>(d<span class="op">$</span>kcal.per.g))
inits_list &lt;-<span class="kw">list</span>(inits, inits, inits, inits)

b6.<span class="dv">14</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">update</span>(b6.<span class="dv">13</span>, 
         <span class="dt">newdata =</span> d,
         <span class="dt">formula =</span> kcal.per.g <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>neocortex <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(mass),
         <span class="dt">inits   =</span> inits_list)</code></pre></div>
<div id="comparing-waic-values." class="section level4">
<h4><span class="header-section-number">6.5.1.1</span> Comparing WAIC values.</h4>
<p>In brms, you can get a model’s WAIC value with the <code>waic()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">waic</span>(b6.<span class="dv">14</span>)</code></pre></div>
<pre><code>## 
## Computed from 4000 by 17 log-likelihood matrix
## 
##           Estimate  SE
## elpd_waic      8.2 2.6
## p_waic         3.3 0.9
## waic         -16.4 5.2</code></pre>
<pre><code>## Warning: 2 (11.8%) p_waic estimates greater than 0.4. We recommend trying loo instead.</code></pre>
<p>Note the warning messages. Statisticians have made notable advances in Bayesian information criteria since McElreath published <em>Statistical Rethinking</em>. I won’t go into detail here, but the “We recommend trying loo instead” part of the message is designed to prompt us to use a different information criteria, the Pareto smoothed importance-sampling leave-one-out cross-validation (PSIS-LOO; aka, the LOO). In brms this is available with the <code>loo()</code> function, which you can learn more about in <a href="https://cran.r-project.org/web/packages/loo/vignettes/loo2-example.html">this vignette</a> from the makers of the <a href="https://cran.r-project.org/web/packages/loo/index.html">loo package</a>. For now, back to the WAIC.</p>
<p>There are a few ways to approach information criteria within the brms framework. If all you want are the quick results for a model, just plug the name of your <code>brm()</code> fit object into the <code>waic()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">waic</span>(b6.<span class="dv">11</span>)</code></pre></div>
<pre><code>## 
## Computed from 4000 by 17 log-likelihood matrix
## 
##           Estimate  SE
## elpd_waic      4.4 1.9
## p_waic         1.3 0.3
## waic          -8.9 3.8</code></pre>
<p>The WAIC and its standard error are on the bottom row. The <span class="math inline">\(p_\text{WAIC}\)</span> and its SE are stacked atop that. And look there on the top row. Remember how we pointed out, above, that we get the WAIC by multiplying <code>(lppd - pwaic)</code> by -2? Well, if you just do the subtraction without multiplying the result by -2, you get the <code>elpd_waic</code>. File that away. It’ll become important in a bit.</p>
<p>Following the version 2.8.0 update, part of the suggested workflow for using information criteria with brms (i.e., execute <code>?loo.brmsfit</code>) is to add the estimates to the <code>brm()</code> fit object itself. You do that with the <code>add_criterion()</code> function. Here’s how we’d do so with <code>b6.11</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b6.<span class="dv">11</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b6.<span class="dv">11</span>, <span class="st">&quot;waic&quot;</span>)</code></pre></div>
<p>With that in place, here’s how you’d extract the WAIC information from the fit object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b6.<span class="dv">11</span><span class="op">$</span>waic</code></pre></div>
<pre><code>## 
## Computed from 4000 by 17 log-likelihood matrix
## 
##           Estimate  SE
## elpd_waic      4.4 1.9
## p_waic         1.3 0.3
## waic          -8.9 3.8</code></pre>
<p><em>Why would I go through all that trouble?</em>, you might ask. Well, two reasons. First, now your WAIC information is saved with all the rest of your fit output, which can be convenient. But second, it sets you up to use the <code>loo_compare()</code> function to compare models by their information criteria. To get a sense of that workflow, here we use <code>add_criterion()</code> for the next three models. Then we’ll use <code>loo_compare()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute and save the WAIC information for the next three models</span>
b6.<span class="dv">12</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b6.<span class="dv">12</span>, <span class="st">&quot;waic&quot;</span>)
b6.<span class="dv">13</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b6.<span class="dv">13</span>, <span class="st">&quot;waic&quot;</span>)
b6.<span class="dv">14</span> &lt;-<span class="st"> </span><span class="kw">add_criterion</span>(b6.<span class="dv">14</span>, <span class="st">&quot;waic&quot;</span>)

<span class="co"># compare the WAIC estimates</span>
w &lt;-<span class="st"> </span><span class="kw">loo_compare</span>(b6.<span class="dv">11</span>, b6.<span class="dv">12</span>, b6.<span class="dv">13</span>, b6.<span class="dv">14</span>,
                 <span class="dt">criterion =</span> <span class="st">&quot;waic&quot;</span>)

<span class="kw">print</span>(w)</code></pre></div>
<pre><code>##       elpd_diff se_diff
## b6.14  0.0       0.0   
## b6.11 -3.8       2.5   
## b6.13 -3.8       1.8   
## b6.12 -4.7       2.5</code></pre>
<p>You don’t have to save those results as an object like we just did with <code>w</code>. But that’ll serve some pedagogical purposes in just a bit. So go with it. With respect to the output, notice the <code>elpd_diff</code> column and the adjacent <code>se_diff</code> column. Those are our WAIC differences. The models have been rank ordered from the lowest (i.e., <code>b6.14</code>) to the highest (i.e., <code>b6.12</code>). The scores listed are the differences of <code>b6.14</code> minus the comparison model. Since <code>b6.14</code> is the comparison model in the top row, the values are naturally 0 (i.e., <span class="math inline">\(x – x = 0\)</span>). But now here’s another critical thing to understand: Since the brms version 2.8.0 update, WAIC and LOO differences are no longer reported in the <span class="math inline">\(-2 * x\)</span> metric. Remember how we keep rehearsing that multiplying <code>(lppd - pwaic)</code> by -2 is a historic artifact associated with the frequentist chi-square test? We’ll, the makers of the loo package aren’t fans and they no longer support the conversion.</p>
<p>So here’s the deal. The substantive interpretations of the differences presented in an <code>elpd_diff</code> metric will be the same as if presented in a WAIC metric. But if we want to compare our <code>elpd_diff</code> results to those in the text, we will have to multiply them by -2. And also, if we want the associated standard error in the proper metric, we’ll need to multiply the <code>se_diff</code> column by 2. You wouldn’t multiply by -2 because that would return a negative standard error, which would be silly. Here’s a quick way to do so.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cbind</span>(<span class="dt">waic_diff =</span> w[, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="op">-</span><span class="dv">2</span>,
      <span class="dt">se        =</span> w[, <span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)</code></pre></div>
<pre><code>##       waic_diff       se
## b6.14  0.000000 0.000000
## b6.11  7.528218 5.026986
## b6.13  7.617990 3.569936
## b6.12  9.339240 5.082137</code></pre>
<p>One more thing. On page 198, and on many other pages to follow in the text, McElreath used the <code>rethinking::compare()</code> function to return a rich table of information about the WAIC information for several models. If we’re tricky, we can do something similar with <code>loo_compare</code>. To learn how, let’s peer further into the structure of our <code>w</code> object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(w)</code></pre></div>
<pre><code>##  &#39;compare.loo&#39; num [1:4, 1:8] 0 -3.76 -3.81 -4.67 0 ...
##  - attr(*, &quot;dimnames&quot;)=List of 2
##   ..$ : chr [1:4] &quot;b6.14&quot; &quot;b6.11&quot; &quot;b6.13&quot; &quot;b6.12&quot;
##   ..$ : chr [1:8] &quot;elpd_diff&quot; &quot;se_diff&quot; &quot;elpd_waic&quot; &quot;se_elpd_waic&quot; ...</code></pre>
<p>When we used <code>print(w)</code>, a few code blocks earlier, it only returned two columns. It appears we actually have eight. We can see the full output with the <code>simplify = F</code> argument.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(w, <span class="dt">simplify =</span> F)</code></pre></div>
<pre><code>##       elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic  se_waic
## b6.14   0.0       0.0     8.2       2.6          3.3    0.9     -16.4   5.2  
## b6.11  -3.8       2.5     4.4       1.9          1.3    0.3      -8.9   3.8  
## b6.13  -3.8       1.8     4.4       2.1          2.1    0.5      -8.8   4.2  
## b6.12  -4.7       2.5     3.5       1.6          2.0    0.3      -7.1   3.2</code></pre>
<p>The results are quite analogous to those from <code>rethinking::compare()</code>. Again, the difference estimates are in the metric of the <span class="math inline">\(\text{elpd}\)</span>. But the interpretation is the same and we can convert them to the traditional information criteria metric with simple multiplication. As we’ll see later, this basic workflow applies to the LOO, too.</p>
<p>If you want to get those WAIC weights, you can use the <code>brms::model_weights()</code> function like so:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">model_weights</span>(b6.<span class="dv">11</span>, b6.<span class="dv">12</span>, b6.<span class="dv">13</span>, b6.<span class="dv">14</span>, 
              <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>## b6.11 b6.12 b6.13 b6.14 
##  0.02  0.01  0.02  0.95</code></pre>
<p>That last <code>round()</code> line was just to limit the decimal-place precision. If you really wanted to go through the trouble, you could make yourself a little table like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">model_weights</span>(b6.<span class="dv">11</span>, b6.<span class="dv">12</span>, b6.<span class="dv">13</span>, b6.<span class="dv">14</span>, 
              <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">weight =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model  =</span> <span class="kw">c</span>(<span class="st">&quot;b6.11&quot;</span>, <span class="st">&quot;b6.12&quot;</span>, <span class="st">&quot;b6.13&quot;</span>, <span class="st">&quot;b6.14&quot;</span>),
         <span class="dt">weight =</span> weight <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(model, weight) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(weight)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">model</th>
<th align="right">weight</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b6.14</td>
<td align="right">0.95</td>
</tr>
<tr class="even">
<td align="left">b6.11</td>
<td align="right">0.02</td>
</tr>
<tr class="odd">
<td align="left">b6.13</td>
<td align="right">0.02</td>
</tr>
<tr class="even">
<td align="left">b6.12</td>
<td align="right">0.01</td>
</tr>
</tbody>
</table>
<p>With a little <code>[]</code> subsetting and light wrangling, we can convert the contents of our <code>w</code> object to a format suitable for plotting the WAIC estimates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">w[, <span class="dv">7</span><span class="op">:</span><span class="dv">8</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="dt">var =</span> <span class="st">&quot;model_name&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x    =</span> model_name, 
             <span class="dt">y    =</span> waic, 
             <span class="dt">ymin =</span> waic <span class="op">-</span><span class="st"> </span>se_waic, 
             <span class="dt">ymax =</span> waic <span class="op">+</span><span class="st"> </span>se_waic)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>, <span class="dt">y =</span> <span class="ot">NULL</span>,
       <span class="dt">title =</span> <span class="st">&quot;My custom WAIC plot&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text             =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">axis.ticks.y     =</span> <span class="kw">element_blank</span>(),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/w_plot-1.png" width="432" /></p>
<p>We briefly discussed the alternative information criteria, the LOO, above. Here’s how to use it in brms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">loo</span>(b6.<span class="dv">11</span>)</code></pre></div>
<pre><code>## 
## Computed from 4000 by 17 log-likelihood matrix
## 
##          Estimate  SE
## elpd_loo      4.4 1.9
## p_loo         1.3 0.3
## looic        -8.8 3.8
## ------
## Monte Carlo SE of elpd_loo is 0.0.
## 
## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     16    94.1%   3013      
##  (0.5, 0.7]   (ok)        1     5.9%   2041      
##    (0.7, 1]   (bad)       0     0.0%   &lt;NA&gt;      
##    (1, Inf)   (very bad)  0     0.0%   &lt;NA&gt;      
## 
## All Pareto k estimates are ok (k &lt; 0.7).
## See help(&#39;pareto-k-diagnostic&#39;) for details.</code></pre>
<p>The Pareto <span class="math inline">\(k\)</span> values are a useful model fit diagnostic tool, which we’ll discuss later. But for now, realize that brms uses functions from the <a href="https://cran.r-project.org/web/packages/loo/index.html">loo package</a> to compute its WAIC and LOO values. In addition to the vignette, above, <a href="https://cran.r-project.org/web/packages/loo/vignettes/loo2-weights.html">this vignette</a> demonstrates the LOO with these very same examples from McElreath’s text. And if you’d like to dive a little deeper, check out <a href="https://www.youtube.com/watch?v=8_Su5Qo49Dg&amp;t">Aki Vehtari’s GPSS2017 workshop</a> or his talk from November 2018, <a href="https://www.youtube.com/watch?v=Re-2yVd0Mqk"><em>Model assessment, selection and averaging</em></a>.</p>
<p>Let’s get back on track with the text. To put all this model comparison in perspective,</p>
<blockquote>
<p>in this analysis, the best model has more than 90% of the model weight. That’s pretty good. But with only 12 cases, the error on the WAIC estimate is substantial, and of course that uncertainty should propagate to the Akaike weights. So don’t get too excited. If we take the standard error of the difference from the [<code>loo_compare()</code>] table literally, you can think of the difference as a Gaussian distribution centered (for the difference between models [<code>b6.14</code> and <code>b6.11</code>]) on [9.34] with a standard deviation of [5.08]. (p. 200)</p>
</blockquote>
<p>Here are those two values in the <span class="math inline">\(\text{elpd}\)</span> metric.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">w[<span class="dv">4</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]</code></pre></div>
<pre><code>## elpd_diff   se_diff 
## -4.669620  2.541069</code></pre>
<p>And here we convert them to the WAIC metric.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(w[<span class="dv">4</span>, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 9.34</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(w[<span class="dv">4</span>, <span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="dv">2</span>, <span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 5.08</code></pre>
<p>If it’s easier to see, here’s the same information in a tibble.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">value             =</span> <span class="kw">c</span>(<span class="st">&quot;difference&quot;</span>, <span class="st">&quot;se&quot;</span>),
       <span class="dt">elpd              =</span> w[<span class="dv">4</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>],
       <span class="dt">conversion_factor =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">waic            =</span> elpd <span class="op">*</span><span class="st"> </span>conversion_factor)</code></pre></div>
<pre><code>## # A tibble: 2 x 4
##   value       elpd conversion_factor  waic
##   &lt;chr&gt;      &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt;
## 1 difference -4.67                -2  9.34
## 2 se          2.54                 2  5.08</code></pre>
<p>Before we forget, McElreath gave some perspective difference between the models with the highest and lowest WAIC values (p. 200).</p>
<p>But to the point, we can extract the two numerals and plug them into <code>rnorm()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># how many draws would you like?</span>
n &lt;-<span class="st"> </span><span class="fl">1e5</span>

<span class="kw">set.seed</span>(<span class="dv">6</span>)

<span class="co"># simulate</span>
diff &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">diff =</span> <span class="kw">rnorm</span>(n, 
                      <span class="dt">mean =</span> w[<span class="dv">4</span>, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="op">-</span><span class="dv">2</span>, 
                      <span class="dt">sd   =</span> w[<span class="dv">4</span>, <span class="dv">2</span>] <span class="op">*</span><span class="st">  </span><span class="dv">2</span>))

diff <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">the_probability_a_difference_is_negative =</span> <span class="kw">sum</span>(diff <span class="op">&lt;</span><span class="st"> </span><span class="dv">0</span>) <span class="op">/</span><span class="st"> </span>n)</code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   the_probability_a_difference_is_negative
##                                      &lt;dbl&gt;
## 1                                   0.0331</code></pre>
<p>In case you’re curious, this is a graphic version of what we just did.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">diff =</span> <span class="op">-</span><span class="dv">20</span><span class="op">:</span><span class="dv">30</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> diff, <span class="dt">ymin =</span> <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymax =</span> <span class="kw">dnorm</span>(diff, w[<span class="dv">4</span>, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="op">-</span><span class="dv">2</span>, w[<span class="dv">4</span>, <span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)),
              <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> <span class="kw">tibble</span>(<span class="dt">diff =</span> <span class="op">-</span><span class="dv">20</span><span class="op">:</span><span class="dv">0</span>),
              <span class="kw">aes</span>(<span class="dt">ymax =</span> <span class="kw">dnorm</span>(diff, w[<span class="dv">4</span>, <span class="dv">1</span>] <span class="op">*</span><span class="st"> </span><span class="op">-</span><span class="dv">2</span>, w[<span class="dv">4</span>, <span class="dv">2</span>] <span class="op">*</span><span class="st"> </span><span class="dv">2</span>)),
              <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="dv">3</span>,
             <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text             =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/plot_WAIC_diff-1.png" width="288" /></p>
</div>
<div id="comparing-estimates." class="section level4">
<h4><span class="header-section-number">6.5.1.2</span> Comparing estimates.</h4>
<p>The brms package doesn’t have anything like rethinking’s <code>coeftab()</code> function. However, one can get that information with a little ingenuity. Here we’ll employ the <code>broom::tidy()</code> function, which will save the summary statistics for our model parameters. For example, this is what it will produce for the full model, <code>b6.14</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tidy</span>(b6.<span class="dv">14</span>)</code></pre></div>
<pre><code>##          term     estimate  std.error        lower        upper
## 1 b_Intercept  -1.10778838 0.59753389  -2.07797336  -0.11671016
## 2 b_neocortex   2.82815806 0.92990864   1.27706360   4.31866798
## 3   b_logmass  -0.09724996 0.02888818  -0.14293482  -0.04860256
## 4       sigma   0.13995088 0.03072319   0.09899014   0.19629633
## 5        lp__ -19.26708438 1.64611968 -22.48058767 -17.30314877</code></pre>
<p>Note, <code>tidy()</code> also grabs the log posterior (i.e., <code>lp__</code>), which we’ll exclude for our purposes. With a little <code>purrr::map()</code> code, you can save the <code>brm()</code> fits and their <code>tidy()</code> summaries into a nested tibble, and then <code>unnest()</code> the tibble for <code>coeftab()</code>-like use.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_coef_tab &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">model =</span> <span class="kw">c</span>(<span class="st">&quot;b6.11&quot;</span>, <span class="st">&quot;b6.12&quot;</span>, <span class="st">&quot;b6.13&quot;</span>, <span class="st">&quot;b6.14&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">fit   =</span> purrr<span class="op">::</span><span class="kw">map</span>(model, get)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">tidy  =</span> purrr<span class="op">::</span><span class="kw">map</span>(fit, tidy)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>(tidy) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;lp__&quot;</span>)

<span class="kw">head</span>(my_coef_tab)</code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   model term        estimate std.error  lower upper
##   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 b6.11 b_Intercept    0.656    0.0449  0.582 0.731
## 2 b6.11 sigma          0.187    0.0369  0.138 0.254
## 3 b6.12 b_Intercept    0.348    0.567  -0.579 1.27 
## 4 b6.12 b_neocortex    0.460    0.834  -0.883 1.82 
## 5 b6.12 sigma          0.194    0.0403  0.142 0.268
## 6 b6.13 b_Intercept    0.705    0.0583  0.609 0.802</code></pre>
<p>Just a little more work and we’ll have a table analogous to the one McElreath produced with his <code>coef_tab()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_coef_tab <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># learn more about dplyr::complete() here: https://rdrr.io/cran/tidyr/man/expand.html</span>
<span class="st">  </span><span class="kw">complete</span>(<span class="dt">term =</span> <span class="kw">distinct</span>(., term), model) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(model, term, estimate) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">estimate =</span> <span class="kw">round</span>(estimate, <span class="dt">digits =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">spread</span>(<span class="dt">key =</span> model, <span class="dt">value =</span> estimate)</code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term        b6.11 b6.12  b6.13 b6.14
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 b_Intercept  0.66  0.35   0.7  -1.11
## 2 b_logmass   NA    NA     -0.03 -0.1 
## 3 b_neocortex NA     0.46  NA     2.83
## 4 sigma        0.19  0.19   0.18  0.14</code></pre>
<p>I’m also not aware of an efficient way in brms to reproduce Figure 6.12 for which McElreath nested his <code>coeftab()</code> argument in a <code>plot()</code> argument. However, one can build something similar by hand with a little data wrangling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># data wrangling</span>
wrangled_my_coef_tab &lt;-
<span class="st">  </span>my_coef_tab <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">complete</span>(<span class="dt">term =</span> <span class="kw">distinct</span>(., term), model) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rbind</span>(
     <span class="kw">tibble</span>(
       <span class="dt">model     =</span> <span class="ot">NA</span>,
       <span class="dt">term      =</span> <span class="kw">c</span>(<span class="st">&quot;b_logmass&quot;</span>, <span class="st">&quot;b_neocortex&quot;</span>, <span class="st">&quot;sigma&quot;</span>, <span class="st">&quot;b_Intercept&quot;</span>),
       <span class="dt">estimate  =</span> <span class="ot">NA</span>,
       <span class="dt">std.error =</span> <span class="ot">NA</span>,
       <span class="dt">lower     =</span> <span class="ot">NA</span>,
       <span class="dt">upper     =</span> <span class="ot">NA</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">axis  =</span> <span class="kw">ifelse</span>(<span class="kw">is.na</span>(model), term, model),
         <span class="dt">model =</span> <span class="kw">factor</span>(model, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;b6.11&quot;</span>, <span class="st">&quot;b6.12&quot;</span>, <span class="st">&quot;b6.13&quot;</span>, <span class="st">&quot;b6.14&quot;</span>)),
         <span class="dt">term  =</span> <span class="kw">factor</span>(term, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;b_logmass&quot;</span>, <span class="st">&quot;b_neocortex&quot;</span>, <span class="st">&quot;sigma&quot;</span>, <span class="st">&quot;b_Intercept&quot;</span>, <span class="ot">NA</span>))) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(term, model) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">axis_order =</span> letters[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>],
         <span class="dt">axis =</span> <span class="kw">ifelse</span>(<span class="kw">str_detect</span>(axis, <span class="st">&quot;b6.&quot;</span>), <span class="kw">str_c</span>(<span class="st">&quot;      &quot;</span>, axis), axis))
  
<span class="co"># plot</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> wrangled_my_coef_tab,
       <span class="kw">aes</span>(<span class="dt">x =</span> axis_order,
           <span class="dt">y =</span> estimate,
           <span class="dt">ymin =</span> lower,
           <span class="dt">ymax =</span> upper)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>,  <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_discrete</span>(<span class="ot">NULL</span>, <span class="dt">labels =</span> wrangled_my_coef_tab<span class="op">$</span>axis) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;My other coeftab() plot&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text         =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.grid   =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-68-1.png" width="384" /></p>
<p>However, if you’re willing to deviate just a bit from the format of McElreath’s <code>coeftab()</code> plot, here’s a more elegant way to work with our <code>my_coef_tab</code> tibble.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_coef_tab <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> model, <span class="dt">y =</span> estimate, <span class="dt">ymin =</span> lower, <span class="dt">ymax =</span> upper)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>,  <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">2</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_pointrange</span>(<span class="dt">shape =</span> <span class="dv">21</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>], <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="ot">NULL</span>,
       <span class="dt">y =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text         =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.grid   =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.ticks.y =</span> <span class="kw">element_blank</span>(),
        <span class="dt">axis.text.y  =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)),
        <span class="dt">strip.background =</span> <span class="kw">element_rect</span>(<span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>term, <span class="dt">ncol =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-69-1.png" width="384" /></p>
</div>
<div id="rethinking-barplots-suck." class="section level4">
<h4><span class="header-section-number">6.5.1.3</span> Rethinking: Barplots suck.</h4>
<p>Man, I agree. “The only problem with barplots is that they have bars” (p. 203). You can find alternatives <a href="http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/80-bar-plots-and-modern-alternatives/">here</a>, <a href="https://janhove.github.io/reporting/2015/01/07/some-alternatives-to-barplots">here</a>, <a href="http://www.rebeccabarter.com/blog/2018-05-29_alternatives_dodged_bars/">here</a>, <a href="http://www.audhalbritter.com/alternatives-to-barplots/">here</a>, and a whole bunch <a href="http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html#2.%20Deviation">here</a>.</p>
</div>
</div>
<div id="model-averaging." class="section level3">
<h3><span class="header-section-number">6.5.2</span> Model averaging.</h3>
<p>Within the current brms framework, you can do model-averaged predictions with the <code>pp_average()</code> function. The default weighting scheme is with the LOO. Here we’ll use the <code>weights = &quot;waic&quot;</code> argument to match McElreath’s method in the text. Because <code>pp_average()</code> yields a matrix, we’ll want to convert it to a tibble before feeding it into ggplot2.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># we need new data for both the `fitted()` and `pp_average()` functions</span>
nd &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">neocortex =</span> <span class="kw">seq</span>(<span class="dt">from =</span> .<span class="dv">5</span>, <span class="dt">to =</span> .<span class="dv">8</span>, <span class="dt">length.out =</span> <span class="dv">30</span>),
         <span class="dt">mass      =</span> <span class="fl">4.5</span>)

<span class="co"># we&#39;ll get the `b6.14`-implied trajectory with `fitted()`</span>
f &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b6.<span class="dv">14</span>, <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd)

<span class="co"># the model-average trajectory comes from `pp_average()`</span>
<span class="kw">pp_average</span>(b6.<span class="dv">11</span>, b6.<span class="dv">12</span>, b6.<span class="dv">13</span>, b6.<span class="dv">14</span>,
           <span class="dt">weights =</span> <span class="st">&quot;waic&quot;</span>,
           <span class="dt">method  =</span> <span class="st">&quot;fitted&quot;</span>,  <span class="co"># for new data predictions, use `method = &quot;predict&quot;`</span>
           <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="co"># plot Figure 6.13</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> neocortex, <span class="dt">y =</span> Estimate)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q2.<span class="dv">5</span>, <span class="dt">ymax =</span> Q97.<span class="dv">5</span>), 
              <span class="dt">fill  =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color   =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data  =</span> f, <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2.<span class="dv">5</span>, <span class="dt">ymax =</span> Q97.<span class="dv">5</span>),
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="dt">fill =</span> <span class="st">&quot;transparent&quot;</span>, <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> f,
              <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> d, <span class="kw">aes</span>(<span class="dt">y =</span> kcal.per.g), 
             <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>]) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;kcal.per.g&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d<span class="op">$</span>neocortex), 
                  <span class="dt">ylim =</span> <span class="kw">range</span>(d<span class="op">$</span>kcal.per.g)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text             =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-70-1.png" width="336" /></p>
</div>
</div>
<div id="summary-bonus-r2-talk" class="section level2">
<h2><span class="header-section-number">6.6</span> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</h2>
<p>At the beginning of the chapter (pp. 167–168), McElreath briefly introduced <span class="math inline">\(R^2\)</span> as a popular way to assess the variance explained in a model. He pooh-poohed it because of its tendency to overfit. It’s also limited in that it doesn’t generalize well outside of the single-level Gaussian framework. However, if you should find yourself in a situation where <span class="math inline">\(R^2\)</span> suits your purposes, the brms <code>bayes_R2()</code> function might be of use. Simply feeding a model brm fit object into <code>bayes_R2()</code> will return the posterior mean, <span class="math inline">\(SD\)</span>, and 95% intervals. For example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bayes_R2</span>(b6.<span class="dv">14</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">3</span>)</code></pre></div>
<pre><code>##    Estimate Est.Error  Q2.5 Q97.5
## R2    0.502     0.133 0.163 0.669</code></pre>
<p>With just a little data processing, you can get a tibble table of each of models’ <span class="math inline">\(R^2\)</span> ‘Estimate’.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rbind</span>(<span class="kw">bayes_R2</span>(b6.<span class="dv">11</span>), 
      <span class="kw">bayes_R2</span>(b6.<span class="dv">12</span>), 
      <span class="kw">bayes_R2</span>(b6.<span class="dv">13</span>), 
      <span class="kw">bayes_R2</span>(b6.<span class="dv">14</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">c</span>(<span class="st">&quot;b6.11&quot;</span>, <span class="st">&quot;b6.12&quot;</span>, <span class="st">&quot;b6.13&quot;</span>, <span class="st">&quot;b6.14&quot;</span>),
         <span class="dt">r_square_posterior_mean =</span> <span class="kw">round</span>(Estimate, <span class="dt">digits =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(model, r_square_posterior_mean)</code></pre></div>
<pre><code>## # A tibble: 4 x 2
##   model r_square_posterior_mean
##   &lt;chr&gt;                   &lt;dbl&gt;
## 1 b6.11                    0   
## 2 b6.12                    0.08
## 3 b6.13                    0.15
## 4 b6.14                    0.5</code></pre>
<p>If you want the full distribution of the <span class="math inline">\(R^2\)</span>, you’ll need to add a <code>summary = F</code> argument. Note how this returns a numeric vector.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r2_b6.<span class="dv">13</span> &lt;-<span class="st"> </span><span class="kw">bayes_R2</span>(b6.<span class="dv">13</span>, <span class="dt">summary =</span> F)

r2_b6.<span class="dv">13</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>##  num [1:4000, 1] 0.215 0.227 0.31 0.319 0.377 ...
##  - attr(*, &quot;dimnames&quot;)=List of 2
##   ..$ : NULL
##   ..$ : chr &quot;R2&quot;</code></pre>
<p>If you want to use these in ggplot2, you’ll need to put them in tibbles or data frames. Here we do so for two of our model fits.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># model b6.13</span>
r2_b6.<span class="dv">13</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">bayes_R2</span>(b6.<span class="dv">13</span>, <span class="dt">summary =</span> F) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">r2_13 =</span> R2)

<span class="co"># model b6.14</span>
r2_b6.<span class="dv">14</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">bayes_R2</span>(b6.<span class="dv">14</span>, <span class="dt">summary =</span> F) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">r2_14 =</span> R2)

<span class="co"># Let&#39;s put them in the same data object</span>
r2_combined &lt;-
<span class="st">  </span><span class="kw">bind_cols</span>(r2_b6.<span class="dv">13</span>, r2_b6.<span class="dv">14</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dif =</span> r2_<span class="dv">14</span> <span class="op">-</span><span class="st"> </span>r2_<span class="dv">13</span>)

<span class="co"># Plot their densities</span>
r2_combined <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> r2_<span class="dv">13</span>),
               <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">4</span>], <span class="dt">alpha =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">0</span>, ) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> r2_<span class="dv">14</span>),
               <span class="dt">fill =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">6</span>], <span class="dt">alpha =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">0</span>, ) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x        =</span> <span class="ot">NULL</span>,
       <span class="dt">title    =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">italic</span>(<span class="st">&quot;R&quot;</span>)<span class="op">^</span>{<span class="dv">2</span>}, <span class="st">&quot; distributions&quot;</span>)),
       <span class="dt">subtitle =</span> <span class="st">&quot;Going from left to right, these are</span><span class="ch">\n</span><span class="st">for models b6.13 and b6.14.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-74-1.png" width="336" /></p>
<p>If you do your work in a field where folks use <span class="math inline">\(R^2\)</span> change, you might do that with a simple difference score, which we computed above with <code>mutate(dif = R2.14 - R2.13)</code>. Here’s the <span class="math inline">\(\Delta R^2\)</span> (i.e., <code>dif</code>) plot:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">r2_combined <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> dif, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_halfeyeh</span>(<span class="dt">fill  =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">5</span>], 
                <span class="dt">color =</span> <span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">7</span>],
                <span class="dt">point_interval =</span> median_qi, <span class="dt">.width =</span> .<span class="dv">95</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">x        =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(Delta, <span class="kw">italic</span>(<span class="st">&quot;R&quot;</span>)<span class="op">^</span>{<span class="dv">2</span>})),
       <span class="dt">subtitle =</span> <span class="st">&quot;This is how much more variance, in</span><span class="ch">\n</span><span class="st">terms of %, model b6.14 explained</span><span class="ch">\n</span><span class="st">compared to model b6.13.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_classic</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Courier&quot;</span>),
        <span class="dt">panel.background =</span> <span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="kw">alpha</span>(<span class="kw">carto_pal</span>(<span class="dv">7</span>, <span class="st">&quot;BurgYl&quot;</span>)[<span class="dv">3</span>], <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>)))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-75-1.png" width="336" /></p>
<p>The brms package did not get these <span class="math inline">\(R^2\)</span> values by traditional method used in, say, ordinary least squares estimation. To learn more about how the Bayesian <span class="math inline">\(R^2\)</span> sausage is made, check out the paper by <a href="https://github.com/jgabry/bayes_R2/blob/master/bayes_R2.pdf">Gelman, Goodrich, Gabry, and Ali</a>.</p>
</div>
<div id="reference-5" class="section level2 unnumbered">
<h2>Reference</h2>
<p><a href="https://xcelab.net/rm/statistical-rethinking/">McElreath, R. (2016). <em>Statistical rethinking: A Bayesian course with examples in R and Stan.</em> Chapman &amp; Hall/CRC Press.</a></p>
</div>
<div id="session-info-5" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] rethinking_1.80        viridis_0.5.1          viridisLite_0.3.0      ggbeeswarm_0.6.0      
##  [5] dutchmasters_0.1.0     ghibli_0.2.0           hrbrthemes_0.6.0       loo_2.1.0             
##  [9] ggthemes_4.0.1         wesanderson_0.3.6.9000 GGally_1.4.0           tidybayes_1.0.4       
## [13] bayesplot_1.6.0        fiftystater_1.0.1      bindrcpp_0.2.2         rstan_2.18.2          
## [17] StanHeaders_2.18.0-1   brms_2.8.0             Rcpp_1.0.0             gridExtra_2.3         
## [21] broom_0.5.1            ggrepel_0.8.0          rcartocolor_1.0.0      forcats_0.3.0         
## [25] stringr_1.3.1          dplyr_0.8.0.1          purrr_0.2.5            readr_1.1.1           
## [29] tidyr_0.8.1            tibble_2.1.1           ggplot2_3.1.0          tidyverse_1.2.1       
## 
## loaded via a namespace (and not attached):
##   [1] colorspace_1.3-2          ggridges_0.5.0            rsconnect_0.8.8          
##   [4] rprojroot_1.3-2           ggstance_0.3              markdown_0.8             
##   [7] base64enc_0.1-3           rstudioapi_0.7            svUnit_0.7-12            
##  [10] DT_0.4                    fansi_0.4.0               mvtnorm_1.0-8            
##  [13] lubridate_1.7.4           xml2_1.2.0                codetools_0.2-15         
##  [16] bridgesampling_0.4-0      extrafont_0.17            knitr_1.20               
##  [19] shinythemes_1.1.1         jsonlite_1.5              Rttf2pt1_1.3.7           
##  [22] shiny_1.1.0               compiler_3.5.1            httr_1.3.1               
##  [25] backports_1.1.2           assertthat_0.2.0          Matrix_1.2-14            
##  [28] lazyeval_0.2.1            cli_1.0.1                 later_0.7.3              
##  [31] htmltools_0.3.6           prettyunits_1.0.2         tools_3.5.1              
##  [34] igraph_1.2.1              coda_0.19-2               gtable_0.2.0             
##  [37] glue_1.3.0                reshape2_1.4.3            cellranger_1.1.0         
##  [40] nlme_3.1-137              extrafontdb_1.0           crosstalk_1.0.0          
##  [43] xfun_0.3                  ps_1.2.1                  rvest_0.3.2              
##  [46] mime_0.5                  miniUI_0.1.1.1            gtools_3.8.1             
##  [49] MASS_7.3-50               zoo_1.8-2                 scales_1.0.0             
##  [52] colourpicker_1.0          hms_0.4.2                 promises_1.0.1           
##  [55] Brobdingnag_1.2-5         inline_0.3.15             RColorBrewer_1.1-2       
##  [58] shinystan_2.5.0           yaml_2.1.19               gdtools_0.1.7            
##  [61] reshape_0.8.7             stringi_1.2.3             highr_0.7                
##  [64] dygraphs_1.1.1.5          pkgbuild_1.0.2            rlang_0.3.1              
##  [67] pkgconfig_2.0.2           matrixStats_0.54.0        evaluate_0.10.1          
##  [70] lattice_0.20-35           bindr_0.1.1               rstantools_1.5.0         
##  [73] htmlwidgets_1.2           labeling_0.3              tidyselect_0.2.5         
##  [76] processx_3.2.1            plyr_1.8.4                magrittr_1.5             
##  [79] bookdown_0.9              R6_2.3.0                  generics_0.0.2           
##  [82] pillar_1.3.1              haven_1.1.2               withr_2.1.2              
##  [85] xts_0.10-2                abind_1.4-5               modelr_0.1.2             
##  [88] crayon_1.3.4              arrayhelpers_1.0-20160527 utf8_1.1.4               
##  [91] rmarkdown_1.10            grid_3.5.1                readxl_1.1.0             
##  [94] callr_3.1.0               threejs_0.3.1             digest_0.6.18            
##  [97] xtable_1.8-2              httpuv_1.4.4.2            stats4_3.5.1             
## [100] munsell_0.5.0             beeswarm_0.2.3            vipor_0.4.5              
## [103] shinyjs_1.0</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multivariate-linear-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interactions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
