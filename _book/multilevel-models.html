<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Statistical Rethinking with brms, ggplot2, and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKURZ/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Statistical Rethinking with brms, ggplot2, and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz">


<meta name="date" content="2018-09-26">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="monsters-and-mixtures.html">
<link rel="next" href="adventures-in-covariance.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>This is a love letter</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this"><i class="fa fa-check"></i>Why this?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#my-assumptions-about-you"><i class="fa fa-check"></i>My assumptions about you</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-and-understand-this-project"><i class="fa fa-check"></i>How to use and understand this project</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#you-can-do-this-too"><i class="fa fa-check"></i>You can do this, too</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html"><i class="fa fa-check"></i><b>1</b> The Golem of Prague</a><ul>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#reference"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html"><i class="fa fa-check"></i><b>2</b> Small Worlds and Large Worlds</a><ul>
<li class="chapter" data-level="2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#the-garden-of-forking-data"><i class="fa fa-check"></i><b>2.1</b> The garden of forking data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#counting-possibilities."><i class="fa fa-check"></i><b>2.1.1</b> Counting possibilities.</a></li>
<li class="chapter" data-level="2.1.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#using-prior-information."><i class="fa fa-check"></i><b>2.1.2</b> Using prior information.</a></li>
<li class="chapter" data-level="2.1.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#from-counts-to-probability."><i class="fa fa-check"></i><b>2.1.3</b> From counts to probability.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#building-a-model"><i class="fa fa-check"></i><b>2.2</b> Building a model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-data-story."><i class="fa fa-check"></i><b>2.2.1</b> A data story.</a></li>
<li class="chapter" data-level="2.2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayesian-updating."><i class="fa fa-check"></i><b>2.2.2</b> Bayesian updating.</a></li>
<li class="chapter" data-level="2.2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#evaluate."><i class="fa fa-check"></i><b>2.2.3</b> Evaluate.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#components-of-the-model"><i class="fa fa-check"></i><b>2.3</b> Components of the model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#likelihood."><i class="fa fa-check"></i><b>2.3.1</b> Likelihood.</a></li>
<li class="chapter" data-level="2.3.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#parameters."><i class="fa fa-check"></i><b>2.3.2</b> Parameters.</a></li>
<li class="chapter" data-level="2.3.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#prior."><i class="fa fa-check"></i><b>2.3.3</b> Prior.</a></li>
<li class="chapter" data-level="2.3.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#posterior."><i class="fa fa-check"></i><b>2.3.4</b> Posterior.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#making-the-model-go"><i class="fa fa-check"></i><b>2.4</b> Making the model go</a><ul>
<li class="chapter" data-level="2.4.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#grid-approximation."><i class="fa fa-check"></i><b>2.4.1</b> Grid approximation.</a></li>
<li class="chapter" data-level="2.4.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#quadratic-approximation."><i class="fa fa-check"></i><b>2.4.2</b> Quadratic approximation.</a></li>
<li class="chapter" data-level="2.4.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#markov-chain-monte-carlo."><i class="fa fa-check"></i><b>2.4.3</b> Markov chain Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#reference-1"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html"><i class="fa fa-check"></i><b>3</b> Sampling the Imaginary</a><ul>
<li class="chapter" data-level="3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-from-a-grid-like-approximate-posterior"><i class="fa fa-check"></i><b>3.1</b> Sampling from a grid-like approximate posterior</a></li>
<li class="chapter" data-level="3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-summarize"><i class="fa fa-check"></i><b>3.2</b> Sampling to summarize</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-boundaries."><i class="fa fa-check"></i><b>3.2.1</b> Intervals of defined boundaries.</a></li>
<li class="chapter" data-level="3.2.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-mass."><i class="fa fa-check"></i><b>3.2.2</b> Intervals of defined mass.</a></li>
<li class="chapter" data-level="3.2.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#point-estimates."><i class="fa fa-check"></i><b>3.2.3</b> Point estimates.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-simulate-prediction"><i class="fa fa-check"></i><b>3.3</b> Sampling to simulate prediction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#dummy-data."><i class="fa fa-check"></i><b>3.3.1</b> Dummy data.</a></li>
<li class="chapter" data-level="3.3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#model-checking."><i class="fa fa-check"></i><b>3.3.2</b> Model checking.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#summary-lets-practice-in-brms"><i class="fa fa-check"></i><b>3.4</b> <del>Summary</del> Let’s practice in brms</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#reference-2"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>4</b> Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-models.html"><a href="linear-models.html#why-normal-distributions-are-normal"><i class="fa fa-check"></i><b>4.1</b> Why normal distributions are normal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linear-models.html"><a href="linear-models.html#normal-by-addition."><i class="fa fa-check"></i><b>4.1.1</b> Normal by addition.</a></li>
<li class="chapter" data-level="4.1.2" data-path="linear-models.html"><a href="linear-models.html#normal-by-multiplication."><i class="fa fa-check"></i><b>4.1.2</b> Normal by multiplication.</a></li>
<li class="chapter" data-level="4.1.3" data-path="linear-models.html"><a href="linear-models.html#normal-by-log-multiplication."><i class="fa fa-check"></i><b>4.1.3</b> Normal by log-multiplication.</a></li>
<li class="chapter" data-level="4.1.4" data-path="linear-models.html"><a href="linear-models.html#using-gaussian-distributions."><i class="fa fa-check"></i><b>4.1.4</b> Using Gaussian distributions.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-models.html"><a href="linear-models.html#a-language-for-describing-models"><i class="fa fa-check"></i><b>4.2</b> A language for describing models</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-models.html"><a href="linear-models.html#re-describing-the-globe-tossing-model."><i class="fa fa-check"></i><b>4.2.1</b> Re-describing the globe tossing model.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-models.html"><a href="linear-models.html#a-gaussian-model-of-height"><i class="fa fa-check"></i><b>4.3</b> A Gaussian model of height</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linear-models.html"><a href="linear-models.html#the-data."><i class="fa fa-check"></i><b>4.3.1</b> The data.</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-models.html"><a href="linear-models.html#the-model."><i class="fa fa-check"></i><b>4.3.2</b> The model.</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-models.html"><a href="linear-models.html#grid-approximation-of-the-posterior-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Grid approximation of the posterior distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="linear-models.html"><a href="linear-models.html#sampling-from-the-posterior."><i class="fa fa-check"></i><b>4.3.4</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="4.3.5" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model-with-map-brm."><i class="fa fa-check"></i><b>4.3.5</b> Fitting the model with <del><code>map()</code></del> <code>brm()</code>.</a></li>
<li class="chapter" data-level="4.3.6" data-path="linear-models.html"><a href="linear-models.html#sampling-from-a-map-brm-fit."><i class="fa fa-check"></i><b>4.3.6</b> Sampling from a <del><code>map()</code></del> <code>brm()</code> fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-models.html"><a href="linear-models.html#adding-a-predictor"><i class="fa fa-check"></i><b>4.4</b> Adding a predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="linear-models.html"><a href="linear-models.html#the-linear-model-strategy"><i class="fa fa-check"></i><b>4.4.1</b> The linear model strategy</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model."><i class="fa fa-check"></i><b>4.4.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="4.4.3" data-path="linear-models.html"><a href="linear-models.html#interpreting-the-model-fit."><i class="fa fa-check"></i><b>4.4.3</b> Interpreting the model fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-models.html"><a href="linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>4.5</b> Polynomial regression</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#reference-3"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html"><i class="fa fa-check"></i><b>5</b> Multivariate Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#spurious-associations"><i class="fa fa-check"></i><b>5.1</b> Spurious associations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multivariate-notation."><i class="fa fa-check"></i><b>5.1.1</b> Multivariate notation.</a></li>
<li class="chapter" data-level="5.1.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#fitting-the-model.-1"><i class="fa fa-check"></i><b>5.1.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="5.1.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#plotting-multivariate-posteriors."><i class="fa fa-check"></i><b>5.1.3</b> Plotting multivariate posteriors.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#masked-relationship"><i class="fa fa-check"></i><b>5.2</b> Masked relationship</a></li>
<li class="chapter" data-level="5.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#when-adding-variables-hurts"><i class="fa fa-check"></i><b>5.3</b> When adding variables hurts</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-legs."><i class="fa fa-check"></i><b>5.3.1</b> Multicollinear legs.</a></li>
<li class="chapter" data-level="5.3.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-milk."><i class="fa fa-check"></i><b>5.3.2</b> Multicollinear <code>milk</code>.</a></li>
<li class="chapter" data-level="5.3.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#post-treatment-bias."><i class="fa fa-check"></i><b>5.3.3</b> Post-treatment bias.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#categorical-varaibles"><i class="fa fa-check"></i><b>5.4</b> Categorical varaibles</a><ul>
<li class="chapter" data-level="5.4.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#binary-categories."><i class="fa fa-check"></i><b>5.4.1</b> Binary categories.</a></li>
<li class="chapter" data-level="5.4.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#many-categories."><i class="fa fa-check"></i><b>5.4.2</b> Many categories.</a></li>
<li class="chapter" data-level="5.4.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#adding-regular-predictor-variables."><i class="fa fa-check"></i><b>5.4.3</b> Adding regular predictor variables.</a></li>
<li class="chapter" data-level="5.4.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#another-approach-unique-intercepts."><i class="fa fa-check"></i><b>5.4.4</b> Another approach: Unique intercepts.</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#ordinary-least-squares-and-lm"><i class="fa fa-check"></i><b>5.5</b> <del>Ordinary least squares and <code>lm()</code></del></a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#reference-4"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html"><i class="fa fa-check"></i><b>6</b> Overfitting, Regularization, and Information Criteria</a><ul>
<li class="chapter" data-level="6.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#the-problem-with-parameters"><i class="fa fa-check"></i><b>6.1</b> The problem with parameters</a><ul>
<li class="chapter" data-level="6.1.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#more-parameters-always-improve-fit."><i class="fa fa-check"></i><b>6.1.1</b> More parameters always improve fit.</a></li>
<li class="chapter" data-level="6.1.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#too-few-parameters-hurts-too."><i class="fa fa-check"></i><b>6.1.2</b> Too few parameters hurts, too.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-theory-and-model-performance"><i class="fa fa-check"></i><b>6.2</b> Information theory and model performance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#firing-the-weatherperson."><i class="fa fa-check"></i><b>6.2.1</b> Firing the weatherperson.</a></li>
<li class="chapter" data-level="6.2.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-and-uncertainty."><i class="fa fa-check"></i><b>6.2.2</b> Information and uncertainty.</a></li>
<li class="chapter" data-level="6.2.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-entropy-to-accuracy."><i class="fa fa-check"></i><b>6.2.3</b> From entropy to accuracy.</a></li>
<li class="chapter" data-level="6.2.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-divergence-to-deviance."><i class="fa fa-check"></i><b>6.2.4</b> From divergence to deviance.</a></li>
<li class="chapter" data-level="6.2.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-deviance-to-out-of-sample."><i class="fa fa-check"></i><b>6.2.5</b> From deviance to out-of-sample.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#regularization"><i class="fa fa-check"></i><b>6.3</b> Regularization</a></li>
<li class="chapter" data-level="6.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-criteria"><i class="fa fa-check"></i><b>6.4</b> Information criteria</a><ul>
<li class="chapter" data-level="6.4.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic."><i class="fa fa-check"></i><b>6.4.1</b> DIC.</a></li>
<li class="chapter" data-level="6.4.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#waic."><i class="fa fa-check"></i><b>6.4.2</b> WAIC.</a></li>
<li class="chapter" data-level="6.4.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic-and-waic-as-estimates-of-deviance."><i class="fa fa-check"></i><b>6.4.3</b> DIC and WAIC as estimates of deviance.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#using-information-criteria"><i class="fa fa-check"></i><b>6.5</b> Using information criteria</a><ul>
<li class="chapter" data-level="6.5.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-comparison."><i class="fa fa-check"></i><b>6.5.1</b> Model comparison.</a></li>
<li class="chapter" data-level="6.5.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-averaging."><i class="fa fa-check"></i><b>6.5.2</b> Model averaging.</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#summary-bonus-r2-talk"><i class="fa fa-check"></i><b>6.6</b> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#reference-5"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>7</b> Interactions</a><ul>
<li class="chapter" data-level="7.1" data-path="interactions.html"><a href="interactions.html#building-an-interaction."><i class="fa fa-check"></i><b>7.1</b> Building an interaction.</a><ul>
<li class="chapter" data-level="7.1.1" data-path="interactions.html"><a href="interactions.html#adding-a-dummy-variable-doesnt-work."><i class="fa fa-check"></i><b>7.1.1</b> Adding a dummy variable doesn’t work.</a></li>
<li class="chapter" data-level="7.1.2" data-path="interactions.html"><a href="interactions.html#adding-a-linear-interaction-does-work."><i class="fa fa-check"></i><b>7.1.2</b> Adding a linear interaction does work.</a></li>
<li class="chapter" data-level="7.1.3" data-path="interactions.html"><a href="interactions.html#plotting-the-interaction."><i class="fa fa-check"></i><b>7.1.3</b> Plotting the interaction.</a></li>
<li class="chapter" data-level="7.1.4" data-path="interactions.html"><a href="interactions.html#interpreting-an-interaction-estimate."><i class="fa fa-check"></i><b>7.1.4</b> Interpreting an interaction estimate.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="interactions.html"><a href="interactions.html#symmetry-of-the-linear-interaction."><i class="fa fa-check"></i><b>7.2</b> Symmetry of the linear interaction.</a><ul>
<li class="chapter" data-level="7.2.1" data-path="interactions.html"><a href="interactions.html#buridans-interaction."><i class="fa fa-check"></i><b>7.2.1</b> Buridan’s interaction.</a></li>
<li class="chapter" data-level="7.2.2" data-path="interactions.html"><a href="interactions.html#africa-depends-upon-ruggedness."><i class="fa fa-check"></i><b>7.2.2</b> Africa depends upon ruggedness.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="interactions.html"><a href="interactions.html#continuous-interactions"><i class="fa fa-check"></i><b>7.3</b> Continuous interactions</a><ul>
<li class="chapter" data-level="7.3.1" data-path="interactions.html"><a href="interactions.html#the-data.-1"><i class="fa fa-check"></i><b>7.3.1</b> The data.</a></li>
<li class="chapter" data-level="7.3.2" data-path="interactions.html"><a href="interactions.html#the-un-centered-models."><i class="fa fa-check"></i><b>7.3.2</b> The un-centered models.</a></li>
<li class="chapter" data-level="7.3.3" data-path="interactions.html"><a href="interactions.html#center-and-re-estimate."><i class="fa fa-check"></i><b>7.3.3</b> Center and re-estimate.</a></li>
<li class="chapter" data-level="7.3.4" data-path="interactions.html"><a href="interactions.html#plotting-implied-predictions."><i class="fa fa-check"></i><b>7.3.4</b> Plotting implied predictions.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="interactions.html"><a href="interactions.html#interactions-in-design-formulas"><i class="fa fa-check"></i><b>7.4</b> Interactions in design formulas</a></li>
<li class="chapter" data-level="7.5" data-path="interactions.html"><a href="interactions.html#summary-bonus-marginal_effects"><i class="fa fa-check"></i><b>7.5</b> <del>Summary</del> Bonus: <code>marginal_effects()</code></a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#reference-6"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>8</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#good-king-markov-and-his-island-kingdom"><i class="fa fa-check"></i><b>8.1</b> Good King Markov and His island kingdom</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-1"><i class="fa fa-check"></i><b>8.2</b> Markov chain Monte Carlo</a></li>
<li class="chapter" data-level="8.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#easy-hmc-map2stan-brm"><i class="fa fa-check"></i><b>8.3</b> Easy HMC: <del>map2stan</del> <code>brm()</code></a><ul>
<li class="chapter" data-level="8.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#preparation."><i class="fa fa-check"></i><b>8.3.1</b> Preparation.</a></li>
<li class="chapter" data-level="8.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#estimation."><i class="fa fa-check"></i><b>8.3.2</b> Estimation.</a></li>
<li class="chapter" data-level="8.3.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-again-in-parallel."><i class="fa fa-check"></i><b>8.3.3</b> Sampling again, in parallel.</a></li>
<li class="chapter" data-level="8.3.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#visualization."><i class="fa fa-check"></i><b>8.3.4</b> Visualization.</a></li>
<li class="chapter" data-level="8.3.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#using-the-samples."><i class="fa fa-check"></i><b>8.3.5</b> Using the samples.</a></li>
<li class="chapter" data-level="8.3.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#checking-the-chain."><i class="fa fa-check"></i><b>8.3.6</b> Checking the chain.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#care-and-feeding-of-your-markov-chain."><i class="fa fa-check"></i><b>8.4</b> Care and feeding of your Markov chain.</a><ul>
<li class="chapter" data-level="8.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-samples-do-you-need"><i class="fa fa-check"></i><b>8.4.1</b> How many samples do you need?</a></li>
<li class="chapter" data-level="8.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-chains-do-you-need"><i class="fa fa-check"></i><b>8.4.2</b> How many chains do you need?</a></li>
<li class="chapter" data-level="8.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#taming-a-wild-chain."><i class="fa fa-check"></i><b>8.4.3</b> Taming a wild chain.</a></li>
<li class="chapter" data-level="8.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#non-identifiable-parameters."><i class="fa fa-check"></i><b>8.4.4</b> Non-identifiable parameters.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#reference-7"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>9</b> Big Entropy and the Generalized Linear Model</a><ul>
<li class="chapter" data-level="9.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#maximum-entropy"><i class="fa fa-check"></i><b>9.1</b> Maximum entropy</a><ul>
<li class="chapter" data-level="9.1.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#gaussian."><i class="fa fa-check"></i><b>9.1.1</b> Gaussian.</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#binomial."><i class="fa fa-check"></i><b>9.1.2</b> Binomial.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#generalized-linear-models"><i class="fa fa-check"></i><b>9.2</b> Generalized linear models</a><ul>
<li class="chapter" data-level="9.2.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#meet-the-family."><i class="fa fa-check"></i><b>9.2.1</b> Meet the family.</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions."><i class="fa fa-check"></i><b>9.2.2</b> Linking linear models to distributions.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#reference-8"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="counting-and-classification.html"><a href="counting-and-classification.html"><i class="fa fa-check"></i><b>10</b> Counting and Classification</a><ul>
<li class="chapter" data-level="10.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#binomial-regression"><i class="fa fa-check"></i><b>10.1</b> Binomial regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#logistic-regression-prosocial-chimpanzees."><i class="fa fa-check"></i><b>10.1.1</b> Logistic regression: Prosocial chimpanzees.</a></li>
<li class="chapter" data-level="10.1.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-chimpanzees-again-condensed."><i class="fa fa-check"></i><b>10.1.2</b> Aggregated binomial: Chimpanzees again, condensed.</a></li>
<li class="chapter" data-level="10.1.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-graduate-school-admissions."><i class="fa fa-check"></i><b>10.1.3</b> Aggregated binomial: Graduate school admissions.</a></li>
<li class="chapter" data-level="10.1.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#fitting-binomial-regressions-with-glm."><i class="fa fa-check"></i><b>10.1.4</b> Fitting binomial regressions with <code>glm()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#poisson-regression"><i class="fa fa-check"></i><b>10.2</b> Poisson regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-oceanic-tool-complexity."><i class="fa fa-check"></i><b>10.2.1</b> Example: Oceanic tool complexity.</a></li>
<li class="chapter" data-level="10.2.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#mcmc-islands."><i class="fa fa-check"></i><b>10.2.2</b> MCMC islands.</a></li>
<li class="chapter" data-level="10.2.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-exposure-and-the-offset."><i class="fa fa-check"></i><b>10.2.3</b> Example: Exposure and the offset.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#other-count-regressions"><i class="fa fa-check"></i><b>10.3</b> Other count regressions</a><ul>
<li class="chapter" data-level="10.3.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#multinomial."><i class="fa fa-check"></i><b>10.3.1</b> Multinomial.</a></li>
<li class="chapter" data-level="10.3.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#geometric."><i class="fa fa-check"></i><b>10.3.2</b> Geometric.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#reference-9"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html"><i class="fa fa-check"></i><b>11</b> Monsters and Mixtures</a><ul>
<li class="chapter" data-level="11.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-outcomes"><i class="fa fa-check"></i><b>11.1</b> Ordered categorical outcomes</a><ul>
<li class="chapter" data-level="11.1.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-moral-intuition."><i class="fa fa-check"></i><b>11.1.1</b> Example: Moral intuition.</a></li>
<li class="chapter" data-level="11.1.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#describing-an-ordered-distribution-with-intercepts."><i class="fa fa-check"></i><b>11.1.2</b> Describing an ordered distribution with intercepts.</a></li>
<li class="chapter" data-level="11.1.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#adding-predictor-variables."><i class="fa fa-check"></i><b>11.1.3</b> Adding predictor variables.</a></li>
<li class="chapter" data-level="11.1.4" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#bonus-figure-11.3-alternative."><i class="fa fa-check"></i><b>11.1.4</b> Bonus: Figure 11.3 alternative.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#zero-inflated-outcomes"><i class="fa fa-check"></i><b>11.2</b> Zero-inflated outcomes</a><ul>
<li class="chapter" data-level="11.2.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-zero-inflated-poisson."><i class="fa fa-check"></i><b>11.2.1</b> Example: Zero-inflated Poisson.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersed-outcomes"><i class="fa fa-check"></i><b>11.3</b> Over-dispersed outcomes</a><ul>
<li class="chapter" data-level="11.3.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#beta-binomial."><i class="fa fa-check"></i><b>11.3.1</b> Beta-binomial.</a></li>
<li class="chapter" data-level="11.3.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#negative-binomial-or-gamma-poisson."><i class="fa fa-check"></i><b>11.3.2</b> Negative-binomial or gamma-Poisson.</a></li>
<li class="chapter" data-level="11.3.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersion-entropy-and-information-criteria."><i class="fa fa-check"></i><b>11.3.3</b> Over-dispersion, entropy, and information criteria.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#reference-10"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>12</b> Multilevel Models</a><ul>
<li class="chapter" data-level="12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-multilevel-tadpoles"><i class="fa fa-check"></i><b>12.1</b> Example: Multilevel tadpoles</a></li>
<li class="chapter" data-level="12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>12.2</b> Varying effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multilevel-models.html"><a href="multilevel-models.html#the-model.-1"><i class="fa fa-check"></i><b>12.2.1</b> The model.</a></li>
<li class="chapter" data-level="12.2.2" data-path="multilevel-models.html"><a href="multilevel-models.html#assign-values-to-the-parameters."><i class="fa fa-check"></i><b>12.2.2</b> Assign values to the parameters.</a></li>
<li class="chapter" data-level="12.2.3" data-path="multilevel-models.html"><a href="multilevel-models.html#sumulate-survivors."><i class="fa fa-check"></i><b>12.2.3</b> Sumulate survivors.</a></li>
<li class="chapter" data-level="12.2.4" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-no-pooling-estimates."><i class="fa fa-check"></i><b>12.2.4</b> Compute the no-pooling estimates.</a></li>
<li class="chapter" data-level="12.2.5" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-partial-pooling-estimates."><i class="fa fa-check"></i><b>12.2.5</b> Compute the partial-pooling estimates.</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multilevel-models.html"><a href="multilevel-models.html#more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>12.3</b> More than one type of cluster</a><ul>
<li class="chapter" data-level="12.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-chimpanzees."><i class="fa fa-check"></i><b>12.3.1</b> Multilevel chimpanzees.</a></li>
<li class="chapter" data-level="12.3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#two-types-of-cluster."><i class="fa fa-check"></i><b>12.3.2</b> Two types of cluster.</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-posterior-predictions"><i class="fa fa-check"></i><b>12.4</b> Multilevel posterior predictions</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-same-clusters."><i class="fa fa-check"></i><b>12.4.1</b> Posterior prediction for same clusters.</a></li>
<li class="chapter" data-level="12.4.2" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-new-clusters."><i class="fa fa-check"></i><b>12.4.2</b> Posterior prediction for new clusters.</a></li>
<li class="chapter" data-level="12.4.3" data-path="multilevel-models.html"><a href="multilevel-models.html#focus-and-multilevel-prediction."><i class="fa fa-check"></i><b>12.4.3</b> Focus and multilevel prediction.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#reference-11"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html"><i class="fa fa-check"></i><b>13</b> Adventures in Covariance</a><ul>
<li class="chapter" data-level="13.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-slopes-by-construction"><i class="fa fa-check"></i><b>13.1</b> Varying slopes by construction</a><ul>
<li class="chapter" data-level="13.1.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-the-population."><i class="fa fa-check"></i><b>13.1.1</b> Simulate the population.</a></li>
<li class="chapter" data-level="13.1.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-observations."><i class="fa fa-check"></i><b>13.1.2</b> Simulate observations.</a></li>
<li class="chapter" data-level="13.1.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#the-varying-slopes-model."><i class="fa fa-check"></i><b>13.1.3</b> The varying slopes model.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-admission-decisions-and-gender"><i class="fa fa-check"></i><b>13.2</b> Example: Admission decisions and gender</a><ul>
<li class="chapter" data-level="13.2.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-intercepts."><i class="fa fa-check"></i><b>13.2.1</b> Varying intercepts.</a></li>
<li class="chapter" data-level="13.2.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-effects-of-being-male."><i class="fa fa-check"></i><b>13.2.2</b> Varying effects of being <code>male</code>.</a></li>
<li class="chapter" data-level="13.2.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#shrinkage."><i class="fa fa-check"></i><b>13.2.3</b> Shrinkage.</a></li>
<li class="chapter" data-level="13.2.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#model-comparison.-1"><i class="fa fa-check"></i><b>13.2.4</b> Model comparison.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-cross-classified-chimpanzees-with-varying-slopes"><i class="fa fa-check"></i><b>13.3</b> Example: Cross-classified <code>chimpanzees</code> with varying slopes</a></li>
<li class="chapter" data-level="13.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#continuous-categories-and-the-gaussian-process"><i class="fa fa-check"></i><b>13.4</b> Continuous categories and the Gaussian process</a><ul>
<li class="chapter" data-level="13.4.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-spatial-autocorrelation-in-oceanic-tools."><i class="fa fa-check"></i><b>13.4.1</b> Example: Spatial autocorrelation in Oceanic tools.</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#summary-bonus-another-berkley-admissions-data-like-example."><i class="fa fa-check"></i><b>13.5</b> <del>Summary</del> Bonus: Another Berkley-admissions-data-like example.</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#reference-12"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html"><i class="fa fa-check"></i><b>14</b> Missing Data and Other Opportunities</a><ul>
<li class="chapter" data-level="14.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-error"><i class="fa fa-check"></i><b>14.1</b> Measurement error</a><ul>
<li class="chapter" data-level="14.1.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-the-outcome."><i class="fa fa-check"></i><b>14.1.1</b> Error on the outcome.</a></li>
<li class="chapter" data-level="14.1.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-both-outcome-and-predictor."><i class="fa fa-check"></i><b>14.1.2</b> Error on both outcome and predictor.</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#missing-data"><i class="fa fa-check"></i><b>14.2</b> Missing data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#imputing-neocortex"><i class="fa fa-check"></i><b>14.2.1</b> Imputing <code>neocortex</code></a></li>
<li class="chapter" data-level="14.2.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#improving-the-imputation-model"><i class="fa fa-check"></i><b>14.2.2</b> Improving the imputation model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#reference-13"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html"><i class="fa fa-check"></i><b>15</b> <del>Horoscopes</del> Insights</a><ul>
<li class="chapter" data-level="15.1" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-r-notebooks"><i class="fa fa-check"></i><b>15.1</b> Use R Notebooks</a></li>
<li class="chapter" data-level="15.2" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#save-your-model-fits"><i class="fa fa-check"></i><b>15.2</b> Save your model fits</a></li>
<li class="chapter" data-level="15.3" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#build-your-models-slowly"><i class="fa fa-check"></i><b>15.3</b> Build your models slowly</a></li>
<li class="chapter" data-level="15.4" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#look-at-your-data"><i class="fa fa-check"></i><b>15.4</b> Look at your data</a></li>
<li class="chapter" data-level="15.5" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-the-0-intercept-syntax"><i class="fa fa-check"></i><b>15.5</b> Use the <code>0 + intercept</code> syntax</a></li>
<li class="chapter" data-level="15.6" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-workflow"><i class="fa fa-check"></i><b>15.6</b> Annotate your workflow</a></li>
<li class="chapter" data-level="15.7" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-code"><i class="fa fa-check"></i><b>15.7</b> Annotate your code</a></li>
<li class="chapter" data-level="15.8" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#break-up-your-workflow"><i class="fa fa-check"></i><b>15.8</b> Break up your workflow</a></li>
<li class="chapter" data-level="15.9" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#read-gelmans-blog"><i class="fa fa-check"></i><b>15.9</b> Read Gelman’s blog</a></li>
<li class="chapter" data-level="15.10" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#check-out-other-social-media-too"><i class="fa fa-check"></i><b>15.10</b> Check out other social media, too</a></li>
<li class="chapter" data-level="15.11" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#parting-wisdom"><i class="fa fa-check"></i><b>15.11</b> Parting wisdom</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#reference-14"><i class="fa fa-check"></i>Reference</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical Rethinking</em> with brms, ggplot2, and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multilevel-models" class="section level1">
<h1><span class="header-section-number">12</span> Multilevel Models</h1>
<blockquote>
<p>Multilevel models… remember features of each cluster in the data as they learn about all of the clusters. Depending upon the variation among clusters, which is learned from the data as well, the model pools information across clusters. This pooling tends to improve estimates about each cluster. This improved estimation leads to several, more pragmatic sounding, benefits of the multilevel approach. (p. 356)</p>
</blockquote>
<p>These benefits include:</p>
<ul>
<li>improved estimates for repeated sampling (i.e., in longitudinal data)</li>
<li>improved estimates when there are imbalances among subsamples</li>
<li>estimates of the variation across subsamples</li>
<li>avoiding simplistic averaging by retaining variation across subsamples</li>
</ul>
<blockquote>
<p>All of these benefits flow out of the same strategy and model structure. You learn one basic design and you get all of this for free.</p>
<p>When it comes to regression, multilevel regression deserves to be the default approach. There are certainly contexts in which it would be better to use an old-fashioned single-level model. But the contexts in which multilevel models are superior are much more numerous. It is better to begin to build a multilevel analysis, and then realize it’s unnecessary, than to overlook it. And once you grasp the basic multilevel stragety, it becomes much easier to incorporate related tricks such as allowing for measurement error in the data and even model missing data itself (Chapter 14). (p. 356)</p>
</blockquote>
<p>I’m totally on board with this. After learning about the multilevel model, I see it everywhere. For more on the sentiment it should be the default, check out McElreath’s blog post, <a href="http://elevanth.org/blog/2017/08/24/multilevel-regression-as-default/"><em>Multilevel Regression as Default</em></a>.</p>
<div id="example-multilevel-tadpoles" class="section level2">
<h2><span class="header-section-number">12.1</span> Example: Multilevel tadpoles</h2>
<p>Let’s get the <code>reedfrogs</code> data from rethinking.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">data</span>(reedfrogs)
d &lt;-<span class="st"> </span>reedfrogs</code></pre></div>
<p>Detach rethinking and load brms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rm</span>(reedfrogs)
<span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)</code></pre></div>
<p>Go ahead and acquaint yourself with the <code>reedfrogs</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse)

d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 48
## Variables: 5
## $ density  &lt;int&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 25, 25, 25, 25, 25, 25, ...
## $ pred     &lt;fct&gt; no, no, no, no, no, no, no, no, pred, pred, pred, pred, pred, pred, pred, pred, no, no, ...
## $ size     &lt;fct&gt; big, big, big, big, small, small, small, small, big, big, big, big, small, small, small,...
## $ surv     &lt;int&gt; 9, 10, 7, 10, 9, 9, 10, 9, 4, 9, 7, 6, 7, 5, 9, 9, 24, 23, 22, 25, 23, 23, 23, 21, 6, 13...
## $ propsurv &lt;dbl&gt; 0.9000000, 1.0000000, 0.7000000, 1.0000000, 0.9000000, 0.9000000, 1.0000000, 0.9000000, ...</code></pre>
<p>Making the <code>tank</code> cluster variable is easy.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d &lt;-<span class="st"> </span>
<span class="st">  </span>d <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">tank =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(d))</code></pre></div>
<p>Here’s the formula for the un-pooled model in which each <code>tank</code> gets its own intercept.</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{surv}_i &amp; \sim &amp; \text{Binomial} (n_i, p_i) \\
\text{logit} (p_i) &amp; = &amp; \alpha_{\text{tank}_i} \\
\alpha_{\text{tank}} &amp; \sim &amp; \text{Normal} (0, 5)
\end{eqnarray}
\]</span></p>
<p>And <span class="math inline">\(n_i = \text{density}_i\)</span>. Now we’ll fit this simple aggregated binomial model much like we practiced in Chapter 10.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">1</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      surv <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(density) <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(tank),
      <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">class =</span> b),
      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">500</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>)</code></pre></div>
<p>The formula for the multilevel alternative is</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{surv}_i &amp; \sim &amp; \text{Binomial} (n_i, p_i) \\
\text{logit} (p_i) &amp; = &amp; \alpha_{\text{tank}_i} \\
\alpha_{\text{tank}} &amp; \sim &amp; \text{Normal} (\alpha, \sigma) \\
\alpha &amp; \sim &amp; \text{Normal} (0, 1) \\
\sigma &amp; \sim &amp; \text{HalfCauchy} (0, 1)
\end{eqnarray}
\]</span></p>
<p>You specify the corresponding multilevel model like this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">2</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      surv <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(density) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>tank),
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd)),
      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>)</code></pre></div>
<p>The syntax for the varying effects follows the <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_overview.pdf">lme4 style</a>, <code>( &lt;varying predictor(s)&gt; | &lt;grouping variable(s)&gt; )</code>. In this case <code>(1 | tank)</code> indicates only the intercept, <code>1</code>, varies by <code>tank</code>. The extent to which parameters vary is controlled by the prior, <code>prior(cauchy(0, 1), class = sd)</code>, which is <u>parameterized in the standard deviation metric</u>. Do note that last part. It’s common in multilevel software to model in the variance metric, instead.</p>
<p>Instead of computing the information criteria for each model, saving the results as objects and then placing those objects in <code>compare_ic()</code>, we can also just put both fit objects in <code>waic()</code> or <code>loo()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">waic</span>(b12.<span class="dv">1</span>, b12.<span class="dv">2</span>)</code></pre></div>
<pre><code>##                 WAIC   SE
## b12.1         201.24 9.47
## b12.2         200.86 7.25
## b12.1 - b12.2   0.38 4.56</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">loo</span>(b12.<span class="dv">1</span>, b12.<span class="dv">2</span>)</code></pre></div>
<pre><code>## Warning: Found 40 observations with a pareto_k &gt; 0.7 in model &#39;b12.1&#39;. With this many problematic
## observations, it may be more appropriate to use &#39;kfold&#39; with argument &#39;K = 10&#39; to perform 10-fold cross-
## validation rather than LOO.</code></pre>
<pre><code>## Warning: Found 41 observations with a pareto_k &gt; 0.7 in model &#39;b12.2&#39;. With this many problematic
## observations, it may be more appropriate to use &#39;kfold&#39; with argument &#39;K = 10&#39; to perform 10-fold cross-
## validation rather than LOO.</code></pre>
<pre><code>##                LOOIC    SE
## b12.1         229.25 10.60
## b12.2         229.97  8.87
## b12.1 - b12.2  -0.72  6.42</code></pre>
<p>Note those “pareto_k &gt; 0.7” warnings. We can follow the advice and use the <code>kfold()</code> function, instead. We’ll also go ahead and specify <code>K = 10</code>, as recommended. But beware, this takes a few minutes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kf &lt;-<span class="st"> </span><span class="kw">kfold</span>(b12.<span class="dv">1</span>, b12.<span class="dv">2</span>, 
            <span class="dt">K =</span> <span class="dv">10</span>, <span class="dt">cores =</span> <span class="dv">4</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kf</code></pre></div>
<pre><code>##               KFOLDIC    SE
## b12.1          323.89 13.19
## b12.2          264.51 13.12
## b12.1 - b12.2   59.39  8.35</code></pre>
<p>The <span class="math inline">\(K\)</span>-fold cross-validation difference of 59, with a standard error around 8, suggests that model <code>b12.2</code> is the clear favorite relative to <code>b12.1</code>. For more on the <code>kfold()</code> function, see the <a href="https://cran.r-project.org/web/packages/brms/brms.pdf">brms reference manual</a>.</p>
<p>But here’s our prep work for Figure 12.1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b12.<span class="dv">2</span>)

postMdn &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">coef</span>(b12.<span class="dv">2</span>, <span class="dt">robust =</span> T)<span class="op">$</span>tank[, , ] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(d) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">postMdn =</span> <span class="kw">inv_logit_scaled</span>(Estimate))

postMdn</code></pre></div>
<pre><code>## # A tibble: 48 x 11
##    Estimate Est.Error   Q2.5 Q97.5 density pred  size   surv propsurv  tank postMdn
##       &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;
##  1    2.07      0.854  0.588  4.02      10 no    big       9      0.9     1   0.887
##  2    2.95      1.08   1.16   5.50      10 no    big      10      1       2   0.950
##  3    0.969     0.656 -0.266  2.39      10 no    big       7      0.7     3   0.725
##  4    2.94      1.06   1.15   5.49      10 no    big      10      1       4   0.950
##  5    2.05      0.859  0.588  4.01      10 no    small     9      0.9     5   0.886
##  6    2.07      0.862  0.610  4.04      10 no    small     9      0.9     6   0.888
##  7    2.95      1.10   1.20   5.48      10 no    small    10      1       7   0.950
##  8    2.06      0.851  0.609  4.03      10 no    small     9      0.9     8   0.887
##  9   -0.173     0.601 -1.38   1.01      10 pred  big       4      0.4     9   0.457
## 10    2.05      0.853  0.578  4.01      10 pred  big       9      0.9    10   0.886
## # ... with 38 more rows</code></pre>
<p>For kicks and giggles, let’s use a <a href="https://github.com/alex23lemm/theme_fivethirtyeight">FiveThirtyEight-like theme</a> for our plots. An easy way to do so is with help from the <a href="https://cran.r-project.org/web/packages/ggthemes/index.html">ggthemes package</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;ggthemes&quot;, dependencies = T) </span>

<span class="kw">library</span>(ggthemes) </code></pre></div>
<p>Finally, here’s the ggplot2 code to reproduce Figure 12.1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">postMdn <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> tank, <span class="dt">y =</span> postMdn)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="kw">inv_logit_scaled</span>(<span class="kw">median</span>(post<span class="op">$</span>b_Intercept)), <span class="dt">linetype =</span> <span class="dv">2</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">c</span>(<span class="fl">16.5</span>, <span class="fl">32.5</span>), <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> propsurv), <span class="dt">color =</span> <span class="st">&quot;orange2&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">32</span>, <span class="dv">48</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title    =</span> <span class="st">&quot;Multilevel shrinkage!&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;The empirical proportions are in orange while the model-</span><span class="ch">\n</span><span class="st">implied proportions are the black circles. The dashed line is</span><span class="ch">\n</span><span class="st">the model-implied average survival proportion.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">8</span>, <span class="dv">16</span> <span class="op">+</span><span class="st"> </span><span class="dv">8</span>, <span class="dv">32</span> <span class="op">+</span><span class="st"> </span><span class="dv">8</span>), <span class="dt">y =</span> <span class="dv">0</span>, 
           <span class="dt">label =</span> <span class="kw">c</span>(<span class="st">&quot;small tanks&quot;</span>, <span class="st">&quot;medium tanks&quot;</span>, <span class="st">&quot;large tanks&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-659-1.png" width="480" /></p>
<p>Here is our version of Figure 12.2.a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">5</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">mapply</span>(<span class="cf">function</span>(mean, sd) {
    <span class="kw">stat_function</span>(<span class="dt">fun   =</span> dnorm, 
                  <span class="dt">args  =</span> <span class="kw">list</span>(<span class="dt">mean =</span> mean, <span class="dt">sd =</span> sd), 
                  <span class="dt">alpha =</span> .<span class="dv">2</span>, 
                  <span class="dt">color =</span> <span class="st">&quot;orange2&quot;</span>)
    }, 
    <span class="co"># Enter means and standard deviations here</span>
    <span class="dt">mean =</span> post[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">1</span>],
    <span class="dt">sd   =</span> post[<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">2</span>]
    ) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Population survival distribution&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;The Gaussians are on the log-odds scale.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">4</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title    =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">13</span>),
        <span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">10</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-660-1.png" width="288" /></p>
<p>Note the uncertainty in terms of both location <span class="math inline">\(\alpha\)</span> and scale <span class="math inline">\(\sigma\)</span>. Now here’s the code for Figure 12.2.b.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> post, 
       <span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dt">n    =</span> <span class="kw">nrow</span>(post), 
                     <span class="dt">mean =</span> post[, <span class="dv">1</span>], 
                     <span class="dt">sd   =</span> post[, <span class="dv">2</span>]) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">             </span><span class="kw">inv_logit_scaled</span>())) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;orange2&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Probability of survival&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>()</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-661-1.png" width="288" /></p>
<p>Note how we sampled 12,000 imaginary <code>tanks</code> rather than McElreath’s 8,000. This is because we had 12,000 HMC iterations (i.e., execute <code>nrow(post)</code>).</p>
<p>The <code>aes()</code> code, above, was a bit much. To get a sense of how it worked, consider this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rnorm</span>(<span class="dt">n    =</span> <span class="dv">1</span>, 
      <span class="dt">mean =</span> post[, <span class="dv">1</span>], 
      <span class="dt">sd   =</span> post[, <span class="dv">2</span>]) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">inv_logit_scaled</span>()</code></pre></div>
<pre><code>## [1] 0.8743237</code></pre>
<p>First, we took one random draw from a normal distribution with a mean of the first row in <code>post[, 1]</code> and a standard deviation of the value from the first row in <code>post[, 2]</code>, and passed it through the <code>inv_logit_scaled()</code> function. By replacing the <code>1</code> with <code>nrow(post)</code>, we do this <code>nrow(post)</code> times (i.e., 12,000). So our orange density is the summary of that process.</p>
<div id="overthinking-prior-for-variance-components." class="section level4">
<h4><span class="header-section-number">12.1.0.1</span> Overthinking: Prior for variance components.</h4>
<p>Yep, you can use the exponential distribution for your priors in brms. Here it is for model <code>b12.2</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="fl">2.</span>e &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">update</span>(b12.<span class="dv">2</span>,
         <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),
                   <span class="kw">prior</span>(<span class="kw">exponential</span>(<span class="dv">1</span>), <span class="dt">class =</span> sd)))</code></pre></div>
<p>The model summary:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b12.<span class="fl">2.</span>e)</code></pre></div>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: surv | trials(density) ~ 1 + (1 | tank) 
##    Data: d (Number of observations: 48) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~tank (Number of levels: 48) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.61      0.21     1.24     2.07       2030 1.00
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     1.30      0.25     0.81     1.78       1490 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>If you’re curious how the exponential prior compares to the posterior, you might just plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">6</span>, <span class="dt">by =</span> .<span class="dv">01</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> <span class="kw">dexp</span>(x, <span class="dt">rate =</span> <span class="dv">1</span>)),  <span class="co"># the prior</span>
              <span class="dt">fill =</span> <span class="st">&quot;orange2&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">data =</span> <span class="kw">posterior_samples</span>(b12.<span class="fl">2.</span>e),       <span class="co"># the posterior</span>
               <span class="kw">aes</span>(<span class="dt">x =</span> sd_tank__Intercept), 
               <span class="dt">fill =</span> <span class="st">&quot;orange2&quot;</span>, <span class="dt">size =</span> <span class="dv">0</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Bonus prior/posterior plot</span><span class="ch">\n</span><span class="st">for sd_tank__Intercept&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;The prior is the semitransparent ramp in the</span><span class="ch">\n</span><span class="st">background. The posterior is the solid orange</span><span class="ch">\n</span><span class="st">mound.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>()</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-664-1.png" width="360" /></p>
</div>
</div>
<div id="varying-effects-and-the-underfittingoverfitting-trade-off" class="section level2">
<h2><span class="header-section-number">12.2</span> Varying effects and the underfitting/overfitting trade-off</h2>
<blockquote>
<p>Varying intercepts are just regularized estimates, but adaptively regularized by estimating how diverse the clusters are while estimating the features of each cluster. This fact is not easy to grasp…</p>
<p>A major benefit of using varying effects estimates, instead of the empirical raw estimates, is that they provide more accurate estimates of the individual cluster (tank) intercepts. On average, the varying effects actually provide a better estimate of the individual tank (cluster) means. The reason that the varying intercepts provides better estimates is that they do a better job trading off underfitting and overfitting. (p. 364)</p>
</blockquote>
<p>In this section, we explicate this by contrasting three perspectives:</p>
<ul>
<li>Complete pooling (i.e., a single-<span class="math inline">\(\alpha\)</span> model)</li>
<li>No pooling (i.e., the single-level <span class="math inline">\(\alpha_{\text{tank}_i}\)</span> model)</li>
<li>Partial pooling (i.e., the multilevel model for which <span class="math inline">\(\alpha_{\text{tank}} \sim \text{Normal} (\alpha, \sigma)\)</span>)</li>
</ul>
<blockquote>
<p>To demonstrate [the magic of the multilevel model], we’ll simulate some tadpole data. That way, we’ll know the true per-pond survival probabilities. Then we can compare the no-pooling estimates to the partial pooling estimates, by computing how close each gets to the true values they are trying to estimate. The rest of this section shows how to do such a simulation. (p. 365)</p>
</blockquote>
<div id="the-model.-1" class="section level3">
<h3><span class="header-section-number">12.2.1</span> The model.</h3>
<p>The simulation formula should look familiar.</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{surv}_i &amp; \sim &amp; \text{Binomial} (n_i, p_i) \\
\text{logit} (p_i) &amp; = &amp; \alpha_{\text{pond}_i} \\
\alpha_{\text{pond}} &amp; \sim &amp; \text{Normal} (\alpha, \sigma) \\
\alpha &amp; \sim &amp; \text{Normal} (0, 1) \\
\sigma &amp; \sim &amp; \text{HalfCauchy} (0, 1)
\end{eqnarray}
\]</span></p>
</div>
<div id="assign-values-to-the-parameters." class="section level3">
<h3><span class="header-section-number">12.2.2</span> Assign values to the parameters.</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a       &lt;-<span class="st">  </span><span class="fl">1.4</span>
sigma   &lt;-<span class="st">  </span><span class="fl">1.5</span>
n_ponds &lt;-<span class="st"> </span><span class="dv">60</span>

<span class="kw">set.seed</span>(<span class="dv">1222</span>)  <span class="co"># make results reproducible</span>
(
  dsim &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">pond   =</span> <span class="dv">1</span><span class="op">:</span>n_ponds,
         <span class="dt">ni     =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">35</span>), <span class="dt">each =</span> n_ponds <span class="op">/</span><span class="st"> </span><span class="dv">4</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.integer</span>(),
         <span class="dt">true_a =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> n_ponds, <span class="dt">mean =</span> a, <span class="dt">sd =</span> sigma))
  )</code></pre></div>
<pre><code>## # A tibble: 60 x 3
##     pond    ni true_a
##    &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
##  1     1     5  1.95 
##  2     2     5  0.249
##  3     3     5  0.521
##  4     4     5  1.20 
##  5     5     5 -3.34 
##  6     6     5  0.184
##  7     7     5  1.63 
##  8     8     5  0.336
##  9     9     5  1.83 
## 10    10     5 -0.865
## # ... with 50 more rows</code></pre>
</div>
<div id="sumulate-survivors." class="section level3">
<h3><span class="header-section-number">12.2.3</span> Sumulate survivors.</h3>
<blockquote>
<p>Each pond <span class="math inline">\(i\)</span> has <span class="math inline">\(n_i\)</span> potential survivors, and nature flips each tadpole’s coin, so to speak, with probability of survival <span class="math inline">\(p_i\)</span>. This probability <span class="math inline">\(p_i\)</span> is implied by the model definition, and is equal to:</p>
<p><span class="math display">\[p_i = \frac{\text{exp} (\alpha_i)}{1 + \text{exp} (\alpha_i)}\]</span></p>
<p>The model uses a logit link, and so the probability is defined by the [<code>inv_logit_scaled()</code>] function. (p. 367)</p>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1223</span>)
(
  dsim &lt;-
<span class="st">  </span>dsim <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">si =</span> <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">prob =</span> <span class="kw">inv_logit_scaled</span>(true_a), <span class="dt">size =</span> ni))
  )</code></pre></div>
<pre><code>## # A tibble: 60 x 4
##     pond    ni true_a    si
##    &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;
##  1     1     5  1.95      4
##  2     2     5  0.249     4
##  3     3     5  0.521     4
##  4     4     5  1.20      4
##  5     5     5 -3.34      0
##  6     6     5  0.184     2
##  7     7     5  1.63      5
##  8     8     5  0.336     2
##  9     9     5  1.83      4
## 10    10     5 -0.865     0
## # ... with 50 more rows</code></pre>
</div>
<div id="compute-the-no-pooling-estimates." class="section level3">
<h3><span class="header-section-number">12.2.4</span> Compute the no-pooling estimates.</h3>
<p>The no-pooling estimates (i.e., <span class="math inline">\(\alpha_{\text{tank}_i}\)</span>) are a function of simple algebra.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(
  dsim &lt;-
<span class="st">  </span>dsim <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_nopool =</span> si <span class="op">/</span><span class="st"> </span>ni)
  )</code></pre></div>
<pre><code>## # A tibble: 60 x 5
##     pond    ni true_a    si p_nopool
##    &lt;int&gt; &lt;int&gt;  &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;
##  1     1     5  1.95      4      0.8
##  2     2     5  0.249     4      0.8
##  3     3     5  0.521     4      0.8
##  4     4     5  1.20      4      0.8
##  5     5     5 -3.34      0      0  
##  6     6     5  0.184     2      0.4
##  7     7     5  1.63      5      1  
##  8     8     5  0.336     2      0.4
##  9     9     5  1.83      4      0.8
## 10    10     5 -0.865     0      0  
## # ... with 50 more rows</code></pre>
<p>“These are the same no-pooling estimates you’d get by fitting a model with a dummy variable for each pond and flat priors that induct no regularization” (p. 367).</p>
</div>
<div id="compute-the-partial-pooling-estimates." class="section level3">
<h3><span class="header-section-number">12.2.5</span> Compute the partial-pooling estimates.</h3>
<p>To follow along with McElreath, set <code>chains = 1, cores = 1</code> to fit with one chain.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">3</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> dsim, <span class="dt">family =</span> binomial,
      si <span class="op">|</span><span class="st"> </span><span class="kw">trials</span>(ni) <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>pond),
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd)),
      <span class="dt">iter =</span> <span class="dv">10000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">1</span>, <span class="dt">cores =</span> <span class="dv">1</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b12.<span class="dv">3</span>)</code></pre></div>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: si | trials(ni) ~ 1 + (1 | pond) 
##    Data: dsim (Number of observations: 60) 
## Samples: 1 chains, each with iter = 10000; warmup = 1000; thin = 1;
##          total post-warmup samples = 9000
## 
## Group-Level Effects: 
## ~pond (Number of levels: 60) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.43      0.23     1.04     1.93       3111 1.00
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     1.54      0.22     1.13     1.98       3085 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>I’m not aware that you can use McElreath’s <code>depth=2</code> trick in brms for <code>summary()</code> or <code>print()</code>. But can get that information with the <code>coef()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(b12.<span class="dv">3</span>)<span class="op">$</span>pond[<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dv">59</span><span class="op">:</span><span class="dv">60</span>), , ] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##    Estimate Est.Error  Q2.5 Q97.5
## 1      1.58      0.92 -0.08  3.52
## 2      1.58      0.92 -0.08  3.55
## 59     2.68      0.63  1.58  4.05
## 60     0.99      0.38  0.27  1.76</code></pre>
<p>Note how we just peeked at the top and bottom two rows with the <code>c(1:2, 59:60)</code> part of the code, there. Somewhat discouragingly, <code>coef()</code> doesn’t return the ‘Eff.Sample’ or ‘Rhat’ columns as in McElreath’s output. We can still extract that information, though. For <span class="math inline">\(\hat{R}\)</span>, the solution is simple; use the <code>brms::rhat()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rhat</span>(b12.<span class="dv">3</span>)</code></pre></div>
<pre><code>##          b_Intercept   sd_pond__Intercept  r_pond[1,Intercept]  r_pond[2,Intercept]  r_pond[3,Intercept] 
##            1.0000059            0.9998954            0.9998894            0.9998926            1.0000145 
##  r_pond[4,Intercept]  r_pond[5,Intercept]  r_pond[6,Intercept]  r_pond[7,Intercept]  r_pond[8,Intercept] 
##            0.9998937            0.9998977            0.9998892            0.9999315            0.9999297 
##  r_pond[9,Intercept] r_pond[10,Intercept] r_pond[11,Intercept] r_pond[12,Intercept] r_pond[13,Intercept] 
##            0.9999757            0.9999514            0.9999386            0.9999411            0.9998939 
## r_pond[14,Intercept] r_pond[15,Intercept] r_pond[16,Intercept] r_pond[17,Intercept] r_pond[18,Intercept] 
##            0.9999678            0.9999174            1.0000529            1.0000404            0.9999700 
## r_pond[19,Intercept] r_pond[20,Intercept] r_pond[21,Intercept] r_pond[22,Intercept] r_pond[23,Intercept] 
##            0.9998949            0.9998985            0.9998891            0.9998928            0.9999322 
## r_pond[24,Intercept] r_pond[25,Intercept] r_pond[26,Intercept] r_pond[27,Intercept] r_pond[28,Intercept] 
##            0.9999352            0.9999363            0.9998922            0.9998911            0.9999259 
## r_pond[29,Intercept] r_pond[30,Intercept] r_pond[31,Intercept] r_pond[32,Intercept] r_pond[33,Intercept] 
##            0.9999971            1.0000482            0.9998963            0.9999102            0.9998930 
## r_pond[34,Intercept] r_pond[35,Intercept] r_pond[36,Intercept] r_pond[37,Intercept] r_pond[38,Intercept] 
##            0.9999403            0.9998928            0.9999676            0.9999138            0.9998943 
## r_pond[39,Intercept] r_pond[40,Intercept] r_pond[41,Intercept] r_pond[42,Intercept] r_pond[43,Intercept] 
##            0.9999134            0.9999159            0.9999320            1.0000600            0.9999650 
## r_pond[44,Intercept] r_pond[45,Intercept] r_pond[46,Intercept] r_pond[47,Intercept] r_pond[48,Intercept] 
##            0.9999229            0.9998911            0.9998898            0.9998894            0.9999701 
## r_pond[49,Intercept] r_pond[50,Intercept] r_pond[51,Intercept] r_pond[52,Intercept] r_pond[53,Intercept] 
##            0.9999082            0.9998923            0.9999195            0.9998889            0.9998916 
## r_pond[54,Intercept] r_pond[55,Intercept] r_pond[56,Intercept] r_pond[57,Intercept] r_pond[58,Intercept] 
##            0.9998930            0.9998973            0.9999618            0.9999326            0.9998965 
## r_pond[59,Intercept] r_pond[60,Intercept]                 lp__ 
##            0.9998951            0.9999115            0.9999012</code></pre>
<p>Extracting the ‘Eff.Sample’ values is a little more complicated. There is no <code>effsamples()</code> function. However, we do have <code>neff_ratio()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">neff_ratio</span>(b12.<span class="dv">3</span>)</code></pre></div>
<pre><code>##          b_Intercept   sd_pond__Intercept  r_pond[1,Intercept]  r_pond[2,Intercept]  r_pond[3,Intercept] 
##            0.3427542            0.3456433            1.0000000            1.0000000            1.0000000 
##  r_pond[4,Intercept]  r_pond[5,Intercept]  r_pond[6,Intercept]  r_pond[7,Intercept]  r_pond[8,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
##  r_pond[9,Intercept] r_pond[10,Intercept] r_pond[11,Intercept] r_pond[12,Intercept] r_pond[13,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[14,Intercept] r_pond[15,Intercept] r_pond[16,Intercept] r_pond[17,Intercept] r_pond[18,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[19,Intercept] r_pond[20,Intercept] r_pond[21,Intercept] r_pond[22,Intercept] r_pond[23,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[24,Intercept] r_pond[25,Intercept] r_pond[26,Intercept] r_pond[27,Intercept] r_pond[28,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[29,Intercept] r_pond[30,Intercept] r_pond[31,Intercept] r_pond[32,Intercept] r_pond[33,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[34,Intercept] r_pond[35,Intercept] r_pond[36,Intercept] r_pond[37,Intercept] r_pond[38,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[39,Intercept] r_pond[40,Intercept] r_pond[41,Intercept] r_pond[42,Intercept] r_pond[43,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[44,Intercept] r_pond[45,Intercept] r_pond[46,Intercept] r_pond[47,Intercept] r_pond[48,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[49,Intercept] r_pond[50,Intercept] r_pond[51,Intercept] r_pond[52,Intercept] r_pond[53,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[54,Intercept] r_pond[55,Intercept] r_pond[56,Intercept] r_pond[57,Intercept] r_pond[58,Intercept] 
##            1.0000000            1.0000000            1.0000000            1.0000000            1.0000000 
## r_pond[59,Intercept] r_pond[60,Intercept]                 lp__ 
##            1.0000000            1.0000000            0.2037963</code></pre>
<p>The <code>brms::neff_ratio()</code> function returns ratios of the effective samples over the total number of post-warmup iterations. So if we know the <code>neff_ratio()</code> values and the number of post-warmup iterations, the ‘Eff.Sample’ values are just a little algebra away. A quick solution is to look at the ‘total post-warmup samples’ line at the top of our <code>print()</code> output. Another way is to extract that information from our <code>brm()</code> fit object. I’m not aware of a way to do that directly, but we can extract the <code>iter</code> value (i.e., <code>b12.2$fit@sim$iter</code>), the <code>warmup</code> value (i.e., <code>b12.2$fit@sim$warmup</code>), and the number of <code>chains</code> (i.e., <code>b12.2$fit@sim$chains</code>). With those values in hand, simple algebra will return the ‘total post-warmup samples’ value. E.g.,</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(
  n_iter &lt;-<span class="st"> </span>(b12.<span class="dv">3</span><span class="op">$</span>fit<span class="op">@</span>sim<span class="op">$</span>iter <span class="op">-</span><span class="st"> </span>b12.<span class="dv">3</span><span class="op">$</span>fit<span class="op">@</span>sim<span class="op">$</span>warmup) <span class="op">*</span><span class="st"> </span>b12.<span class="dv">3</span><span class="op">$</span>fit<span class="op">@</span>sim<span class="op">$</span>chains
)</code></pre></div>
<pre><code>## [1] 9000</code></pre>
<p>And now we have <code>n_iter</code>, we can calculate the ‘Eff.Sample’ values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">neff_ratio</span>(b12.<span class="dv">3</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as.data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rownames_to_column</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">parameter  =</span> rowname,
         <span class="dt">neff_ratio =</span> <span class="st">&quot;.&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">eff_sample =</span> (neff_ratio <span class="op">*</span><span class="st"> </span>n_iter) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>()</code></pre></div>
<pre><code>##             parameter neff_ratio eff_sample
## 1         b_Intercept  0.3427542       3085
## 2  sd_pond__Intercept  0.3456433       3111
## 3 r_pond[1,Intercept]  1.0000000       9000
## 4 r_pond[2,Intercept]  1.0000000       9000
## 5 r_pond[3,Intercept]  1.0000000       9000
## 6 r_pond[4,Intercept]  1.0000000       9000</code></pre>
<p>Digressions aside, let’s get ready for the diagnostic plot of Figure 12.3.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dsim <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 60
## Variables: 5
## $ pond     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 2...
## $ ni       &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,...
## $ true_a   &lt;dbl&gt; 1.9473216, 0.2487733, 0.5214389, 1.1987112, -3.3372853, 0.1843209, 1.6260145, 0.3359535,...
## $ si       &lt;int&gt; 4, 4, 4, 4, 0, 2, 5, 2, 4, 0, 1, 5, 5, 5, 5, 10, 0, 5, 10, 10, 7, 10, 7, 6, 10, 9, 6, 10...
## $ p_nopool &lt;dbl&gt; 0.80, 0.80, 0.80, 0.80, 0.00, 0.40, 1.00, 0.40, 0.80, 0.00, 0.20, 1.00, 1.00, 1.00, 1.00...</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># we could have included this step in the block of code below, if we wanted to</span>
p_partpool &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">coef</span>(b12.<span class="dv">3</span>)<span class="op">$</span>pond[, , ] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">p_partpool =</span> <span class="kw">inv_logit_scaled</span>(Estimate))

dsim &lt;-<span class="st"> </span>
<span class="st">  </span>dsim <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(p_partpool) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_true         =</span> <span class="kw">inv_logit_scaled</span>(true_a)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">nopool_error   =</span> <span class="kw">abs</span>(p_nopool   <span class="op">-</span><span class="st"> </span>p_true),
         <span class="dt">partpool_error =</span> <span class="kw">abs</span>(p_partpool <span class="op">-</span><span class="st"> </span>p_true))

dsim <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 60
## Variables: 9
## $ pond           &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,...
## $ ni             &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...
## $ true_a         &lt;dbl&gt; 1.9473216, 0.2487733, 0.5214389, 1.1987112, -3.3372853, 0.1843209, 1.6260145, 0.33...
## $ si             &lt;int&gt; 4, 4, 4, 4, 0, 2, 5, 2, 4, 0, 1, 5, 5, 5, 5, 10, 0, 5, 10, 10, 7, 10, 7, 6, 10, 9,...
## $ p_nopool       &lt;dbl&gt; 0.80, 0.80, 0.80, 0.80, 0.00, 0.40, 1.00, 0.40, 0.80, 0.00, 0.20, 1.00, 1.00, 1.00...
## $ p_partpool     &lt;dbl&gt; 0.8294316, 0.8285394, 0.8288654, 0.8293981, 0.2394738, 0.5428037, 0.9304361, 0.542...
## $ p_true         &lt;dbl&gt; 0.8751543, 0.5618746, 0.6274842, 0.7682954, 0.0343140, 0.5459502, 0.8356229, 0.583...
## $ nopool_error   &lt;dbl&gt; 0.075154292, 0.238125444, 0.172515824, 0.031704565, 0.034314001, 0.145950213, 0.16...
## $ partpool_error &lt;dbl&gt; 0.045722683, 0.266664853, 0.201381248, 0.061102621, 0.205159786, 0.003146557, 0.09...</code></pre>
<p>Here is our code for Figure 12.3. The extra data processing for <code>dfline</code> is how we get the values necessary for the horizontal summary lines.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfline &lt;-<span class="st"> </span>
<span class="st">  </span>dsim <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(ni, nopool_error<span class="op">:</span>partpool_error) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>ni) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(key, ni) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean_error =</span> <span class="kw">mean</span>(value)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x    =</span> <span class="kw">c</span>( <span class="dv">1</span>, <span class="dv">16</span>, <span class="dv">31</span>, <span class="dv">46</span>),
         <span class="dt">xend =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">30</span>, <span class="dv">45</span>, <span class="dv">60</span>))
  
dsim <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> pond)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">c</span>(<span class="fl">15.5</span>, <span class="fl">30.5</span>, <span class="fl">45.4</span>), 
             <span class="dt">color =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">size =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> nopool_error), <span class="dt">color =</span> <span class="st">&quot;orange2&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> partpool_error), <span class="dt">shape =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">data =</span> dfline, 
               <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">xend =</span> xend, 
                   <span class="dt">y =</span> mean_error, <span class="dt">yend =</span> mean_error),
               <span class="dt">color =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;orange2&quot;</span>, <span class="st">&quot;black&quot;</span>), <span class="dt">each =</span> <span class="dv">4</span>),
               <span class="dt">linetype =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dt">each =</span> <span class="dv">4</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y        =</span> <span class="st">&quot;absolute error&quot;</span>,
       <span class="dt">title    =</span> <span class="st">&quot;Estimate error by model type&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;The horizontal axis displays pond number. The vertical axis measures</span><span class="ch">\n</span><span class="st">the absolute error in the predicted proportion of survivors, compared to</span><span class="ch">\n</span><span class="st">the true value used in the simulation. The higher the point, the worse</span><span class="ch">\n</span><span class="st">the estimate. No-pooling shown in orange. Partial pooling shown in black.</span><span class="ch">\n</span><span class="st">The orange and dashed black lines show the average error for each kind</span><span class="ch">\n</span><span class="st">of estimate, across each initial density of tadpoles (pond size). Smaller</span><span class="ch">\n</span><span class="st">ponds produce more error, but the partial pooling estimates are better</span><span class="ch">\n</span><span class="st">on average, especially in smaller ponds.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">60</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">15</span> <span class="op">-</span><span class="st"> </span><span class="fl">7.5</span>, <span class="dv">30</span> <span class="op">-</span><span class="st"> </span><span class="fl">7.5</span>, <span class="dv">45</span> <span class="op">-</span><span class="st"> </span><span class="fl">7.5</span>, <span class="dv">60</span> <span class="op">-</span><span class="st"> </span><span class="fl">7.5</span>), <span class="dt">y =</span> .<span class="dv">45</span>, 
           <span class="dt">label =</span> <span class="kw">c</span>(<span class="st">&quot;tiny (5)&quot;</span>, <span class="st">&quot;small (10)&quot;</span>, <span class="st">&quot;medium (25)&quot;</span>, <span class="st">&quot;large (35)&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid    =</span> <span class="kw">element_blank</span>(),
        <span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">10</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-676-1.png" width="480" /></p>
<p>If you wanted to quantify the difference in simple summaries, you might do something like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dsim <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(ni, nopool_error<span class="op">:</span>partpool_error) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>ni) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean_error   =</span> <span class="kw">mean</span>(value) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">3</span>),
            <span class="dt">median_error =</span> <span class="kw">median</span>(value) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">3</span>))</code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   key            mean_error median_error
##   &lt;chr&gt;               &lt;dbl&gt;        &lt;dbl&gt;
## 1 nopool_error        0.073        0.045
## 2 partpool_error      0.06         0.045</code></pre>
<p>I originally learned about the multilevel model within the context of <a href="http://gseacademic.harvard.edu/alda/">longitudinal data</a>. In that context, I found the basic principles of a multilevel structure quite intuitive. The concept of partial pooling, however, took me some time to wrap my head around. If you’re struggling with this, be patient and keep chipping away.</p>
<p>When McElreath was <a href="https://www.youtube.com/watch?v=82TaniPgzQc&amp;t=2048s&amp;frags=pl%2Cwn">lecturing on this topic in 2015</a>, he traced partial pooling to statistician James Stein. In 1977, Efron and Morris wrote the now classic paper, <a href="http://statweb.stanford.edu/%7Eckirby/brad/other/Article1977.pdf"><em>Stein’s Paradox in Statistics</em></a>, which did a nice job breaking down why partial pooling can be so powerful. One of the primary examples they used in the paper was of 1970 batting average data. If you’d like more practice seeing how partial pooling works–or if you just like baseball–, check out my project on that example, <a href="https://github.com/ASKurz/James-Stein-and-Bayesian-partial-pooling"><em>James-Stein and Bayesian partial pooling</em></a>.</p>
<div id="overthinking-repeating-the-pond-simulation." class="section level4">
<h4><span class="header-section-number">12.2.5.1</span> Overthinking: Repeating the pond simulation.</h4>
<p>Within the brms workflow, we reuse a compiled model with <code>update()</code>. But first, we’ll simulate new data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">a       &lt;-<span class="st">  </span><span class="fl">1.4</span>
sigma   &lt;-<span class="st">  </span><span class="fl">1.5</span>
n_ponds &lt;-<span class="st"> </span><span class="dv">60</span>

<span class="kw">set.seed</span>(<span class="fl">12.251</span>)  <span class="co"># for new data, set a new seed</span>
new_dsim &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">pond   =</span> <span class="dv">1</span><span class="op">:</span>n_ponds,
         <span class="dt">ni     =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">35</span>), <span class="dt">each =</span> n_ponds <span class="op">/</span><span class="st"> </span><span class="dv">4</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.integer</span>(),
         <span class="dt">true_a =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> n_ponds, <span class="dt">mean =</span> a, <span class="dt">sd =</span> sigma)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">si       =</span> <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="kw">n</span>(), <span class="dt">prob =</span> <span class="kw">inv_logit_scaled</span>(true_a), <span class="dt">size =</span> ni)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">p_nopool =</span> si <span class="op">/</span><span class="st"> </span>ni)

<span class="kw">glimpse</span>(new_dsim)</code></pre></div>
<pre><code>## Observations: 60
## Variables: 5
## $ pond     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 2...
## $ ni       &lt;int&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,...
## $ true_a   &lt;dbl&gt; -0.82085139, 3.76575421, -0.03511672, 0.01999213, -1.59646315, 0.99155593, 0.92697693, 0...
## $ si       &lt;int&gt; 2, 5, 4, 1, 2, 3, 3, 3, 3, 4, 2, 1, 1, 5, 5, 4, 9, 8, 8, 7, 9, 10, 9, 6, 4, 7, 8, 7, 9, ...
## $ p_nopool &lt;dbl&gt; 0.40, 1.00, 0.80, 0.20, 0.40, 0.60, 0.60, 0.60, 0.60, 0.80, 0.40, 0.20, 0.20, 1.00, 1.00...</code></pre>
<p>Fit the new model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.3_new &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">update</span>(b12.<span class="dv">3</span>,
         <span class="dt">newdata =</span> new_dsim,
         <span class="dt">iter =</span> <span class="dv">10000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">1</span>, <span class="dt">cores =</span> <span class="dv">1</span>)</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b12.3_new)</code></pre></div>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: si | trials(ni) ~ 1 + (1 | pond) 
##    Data: new_dsim (Number of observations: 60) 
## Samples: 1 chains, each with iter = 10000; warmup = 1000; thin = 1;
##          total post-warmup samples = 9000
## 
## Group-Level Effects: 
## ~pond (Number of levels: 60) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     1.16      0.16     0.89     1.50       3274 1.00
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     1.14      0.18     0.80     1.49       4647 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Why not plot the first simulation versus the second one?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">posterior_samples</span>(b12.<span class="dv">3</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_rows</span>(<span class="kw">posterior_samples</span>(b12.3_new)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">model =</span> <span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;b12.3&quot;</span>, <span class="st">&quot;b12.3_new&quot;</span>), <span class="dt">each =</span> <span class="kw">n</span>()<span class="op">/</span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span>

<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> b_Intercept, <span class="dt">y =</span> sd_pond__Intercept)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_density_2d</span>(<span class="dt">geom =</span> <span class="st">&quot;raster&quot;</span>, 
                  <span class="kw">aes</span>(<span class="dt">fill =</span> <span class="kw">stat</span>(density)), 
                  <span class="dt">contour =</span> F) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> a,     <span class="dt">color =</span> <span class="st">&quot;orange3&quot;</span>, <span class="dt">linetype =</span> <span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> sigma, <span class="dt">color =</span> <span class="st">&quot;orange3&quot;</span>, <span class="dt">linetype =</span> <span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_fill_gradient</span>(<span class="dt">low =</span> <span class="st">&quot;grey25&quot;</span>, <span class="dt">high =</span> <span class="st">&quot;orange3&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Our simulation posteriors contrast a bit&quot;</span>,
          <span class="dt">subtitle =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(alpha, <span class="st">&quot; is on the x and &quot;</span>, sigma, <span class="st">&quot; is on the y, both in log-odds. The dotted lines intersect at the true values.&quot;</span>))) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(.<span class="dv">7</span>, <span class="dv">2</span>),
                  <span class="dt">ylim =</span> <span class="kw">c</span>(.<span class="dv">8</span>, <span class="fl">1.9</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>,
        <span class="dt">panel.grid      =</span> <span class="kw">element_blank</span>()) <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>model, <span class="dt">ncol =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-680-1.png" width="768" /></p>
<p>If you’d like the <code>stanfit</code> portion of your <code>brm()</code> object, subset with <code>$fit</code>. Take <code>b12.3</code>, for example. You might check out its structure via <code>b12.3$fit %&gt;% str()</code>. Here’s the actual Stan code.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">3</span><span class="op">$</span>fit<span class="op">@</span><span class="st"> </span>stanmodel</code></pre></div>
<pre><code>## S4 class stanmodel &#39;0e126f378ddfd8d0780d3e099c4e7266&#39; coded as follows:
## // generated with brms 2.5.0
## functions { 
## } 
## data { 
##   int&lt;lower=1&gt; N;  // total number of observations 
##   int Y[N];  // response variable 
##   int trials[N];  // number of trials 
##   // data for group-level effects of ID 1
##   int&lt;lower=1&gt; J_1[N];
##   int&lt;lower=1&gt; N_1;
##   int&lt;lower=1&gt; M_1;
##   vector[N] Z_1_1;
##   int prior_only;  // should the likelihood be ignored? 
## } 
## transformed data { 
## } 
## parameters { 
##   real temp_Intercept;  // temporary intercept 
##   vector&lt;lower=0&gt;[M_1] sd_1;  // group-level standard deviations
##   vector[N_1] z_1[M_1];  // unscaled group-level effects
## } 
## transformed parameters { 
##   // group-level effects 
##   vector[N_1] r_1_1 = sd_1[1] * (z_1[1]);
## } 
## model { 
##   vector[N] mu = temp_Intercept + rep_vector(0, N);
##   for (n in 1:N) { 
##     mu[n] += r_1_1[J_1[n]] * Z_1_1[n];
##   } 
##   // priors including all constants 
##   target += normal_lpdf(temp_Intercept | 0, 1); 
##   target += cauchy_lpdf(sd_1 | 0, 1)
##     - 1 * cauchy_lccdf(0 | 0, 1); 
##   target += normal_lpdf(z_1[1] | 0, 1);
##   // likelihood including all constants 
##   if (!prior_only) { 
##     target += binomial_logit_lpmf(Y | trials, mu);
##   } 
## } 
## generated quantities { 
##   // actual population-level intercept 
##   real b_Intercept = temp_Intercept; 
## } 
## </code></pre>
<p>And you can get the data of a given <code>brm()</code> fit object like so.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">3</span><span class="op">$</span>data <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">head</span>()</code></pre></div>
<pre><code>##   si ni pond
## 1  4  5    1
## 2  4  5    2
## 3  4  5    3
## 4  4  5    4
## 5  0  5    5
## 6  2  5    6</code></pre>
</div>
</div>
</div>
<div id="more-than-one-type-of-cluster" class="section level2">
<h2><span class="header-section-number">12.3</span> More than one type of cluster</h2>
<p>“We can use and often should use more than one type of cluster in the same model” (p. 370).</p>
<div id="multilevel-chimpanzees." class="section level3">
<h3><span class="header-section-number">12.3.1</span> Multilevel chimpanzees.</h3>
<p>The initial multilevel update from model <code>b10.4</code> from the last chapter follows the statistical formula</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{left_pull}_i &amp; \sim &amp; \text{Binomial} (n_i = 1, p_i) \\
\text{logit} (p_i) &amp; = &amp; \alpha + \alpha_{\text{actor}_i} + (\beta_1 + \beta_2 \text{condition}_i) \text{prosoc_left}_i \\
\alpha_{\text{actor}} &amp; \sim &amp; \text{Normal} (0, \sigma_{\text{actor}}) \\
\alpha &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta_1 &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta_2 &amp; \sim &amp; \text{Normal} (0, 10) \\
\sigma_{\text{actor}} &amp; \sim &amp; \text{HalfCauchy} (0, 1)
\end{eqnarray}
\]</span></p>
<blockquote>
<p>Notice that <span class="math inline">\(\alpha\)</span> is inside the linear model, not inside the Gaussian prior for <span class="math inline">\(\alpha_\text{actor}\)</span>. This is mathematically equivalent to what [we] did with the tadpoles earlier in the chapter. You can always take the mean out of a Gaussian distribution and treat that distribution as a constant plus a Gaussian distribution centered on zero.</p>
<p>This might seem a little weird at first, so it might help train your intuition by experimenting in R. (p. 371)</p>
</blockquote>
<p>Behold our two identical Gaussians in a tidy tibble.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">241</span>)
two_gaussians &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">y1 =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="fl">1e4</span>, <span class="dt">mean =</span> <span class="dv">10</span>, <span class="dt">sd =</span> <span class="dv">1</span>),
         <span class="dt">y2 =</span> <span class="dv">10</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="fl">1e4</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>))</code></pre></div>
<p>Let’s follow McElreath’s advice to make sure they are same by superimposing the density of one on the other.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">two_gaussians <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> y1), 
               <span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;orange1&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> y2), 
               <span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;orange4&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Our simulated Gaussians&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>()</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-684-1.png" width="336" /></p>
<p>Yep, those Gaussians look about the same.</p>
<p>Let’s get the <code>chimpanzees</code> data from rethinking.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(rethinking)
<span class="kw">data</span>(chimpanzees)
d &lt;-<span class="st"> </span>chimpanzees</code></pre></div>
<p>Detach rethinking and reload brms.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rm</span>(chimpanzees)
<span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)</code></pre></div>
<p>For our brms model with varying intercepts for <code>actor</code> but not <code>block</code>, we employ the <code>pulled_left ~ 1 + ... + (1 | actor)</code> syntax, specifically omitting a <code>(1 | block)</code> section.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">4</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> binomial,
      pulled_left <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>prosoc_left <span class="op">+</span><span class="st"> </span>prosoc_left<span class="op">:</span>condition <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>actor),
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> Intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd)),
      <span class="dt">iter =</span> <span class="dv">5000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,  <span class="co"># I&#39;m using 4 cores, instead of the `cores=3` in McElreath&#39;s code</span>
      <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.95</span>))</code></pre></div>
<p>The initial solutions came with a few divergent transitions. Increasing <code>adapt_delta</code> to <code>0.95</code> solved the problem. You can also solve the problem with more strongly regularizing priors such as <code>normal(0, 2)</code> on the intercept and slope parameters (see <a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">recommendations from the Stan team</a>). Consider trying both methods and comparing the results. They’re similar.</p>
<p>Here we add the <code>actor</code>-level deviations to the fixed intercept, the grand mean.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b12.<span class="dv">4</span>)

post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="st">`</span><span class="dt">r_actor[1,Intercept]</span><span class="st">`</span><span class="op">:</span><span class="st">`</span><span class="dt">r_actor[7,Intercept]</span><span class="st">`</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># This is how we add the grand mean to the actor-level deviations</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">value =</span> value <span class="op">+</span><span class="st"> </span>post<span class="op">$</span>b_Intercept) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(value) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>))</code></pre></div>
<pre><code>## # A tibble: 7 x 2
##   key                   mean
##   &lt;chr&gt;                &lt;dbl&gt;
## 1 r_actor[1,Intercept] -0.71
## 2 r_actor[2,Intercept]  4.6 
## 3 r_actor[3,Intercept] -1.02
## 4 r_actor[4,Intercept] -1.02
## 5 r_actor[5,Intercept] -0.71
## 6 r_actor[6,Intercept]  0.23
## 7 r_actor[7,Intercept]  1.76</code></pre>
<p>Here’s another way to get at the same information, this time using <code>coef()</code> and a little formatting help from the <code>stringr::str_c()</code> function. Just for kicks, we’ll throw in the 95% intervals, too.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">coef</span>(b12.<span class="dv">4</span>)<span class="op">$</span>actor[ , <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span><span class="op">:</span><span class="dv">4</span>), <span class="dv">1</span>] <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># Here we put the credible intervals in an APA-6-style format</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">95% CIs</span><span class="st">`</span> =<span class="st"> </span><span class="kw">str_c</span>(<span class="st">&quot;[&quot;</span>, Q2.<span class="dv">5</span>, <span class="st">&quot;, &quot;</span>, Q97.<span class="dv">5</span>, <span class="st">&quot;]&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">actor =</span> <span class="kw">str_c</span>(<span class="st">&quot;chimp #&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">7</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">mean =</span> Estimate) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(actor, mean, <span class="st">`</span><span class="dt">95% CIs</span><span class="st">`</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>()</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">actor</th>
<th align="right">mean</th>
<th align="left">95% CIs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">chimp #1</td>
<td align="right">-0.71</td>
<td align="left">[-1.24, -0.18]</td>
</tr>
<tr class="even">
<td align="left">chimp #2</td>
<td align="right">4.60</td>
<td align="left">[2.57, 8.54]</td>
</tr>
<tr class="odd">
<td align="left">chimp #3</td>
<td align="right">-1.02</td>
<td align="left">[-1.57, -0.48]</td>
</tr>
<tr class="even">
<td align="left">chimp #4</td>
<td align="right">-1.02</td>
<td align="left">[-1.59, -0.48]</td>
</tr>
<tr class="odd">
<td align="left">chimp #5</td>
<td align="right">-0.71</td>
<td align="left">[-1.24, -0.19]</td>
</tr>
<tr class="even">
<td align="left">chimp #6</td>
<td align="right">0.23</td>
<td align="left">[-0.3, 0.77]</td>
</tr>
<tr class="odd">
<td align="left">chimp #7</td>
<td align="right">1.76</td>
<td align="left">[1.06, 2.55]</td>
</tr>
</tbody>
</table>
<p>If you prefer the posterior median to the mean, just add a <code>robust = T</code> argument inside the <code>coef()</code> function.</p>
</div>
<div id="two-types-of-cluster." class="section level3">
<h3><span class="header-section-number">12.3.2</span> Two types of cluster.</h3>
<p>The full statistical model follows the form</p>
<p><span class="math display">\[\begin{eqnarray}
\text{left_pull}_i &amp; \sim &amp; \text{Binomial} (n_i = 1, p_i) \\
\text{logit} (p_i) &amp; = &amp; \alpha + \alpha_{\text{actor}_i} + \alpha_{\text{block}_i} + (\beta_1 + \beta_2 \text{condition}_i) \text{prosoc_left}_i \\
\alpha_{\text{actor}} &amp; \sim &amp; \text{Normal} (0, \sigma_{\text{actor}}) \\
\alpha_{\text{block}} &amp; \sim &amp; \text{Normal} (0, \sigma_{\text{actor}}) \\
\alpha &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta_1 &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta_2 &amp; \sim &amp; \text{Normal} (0, 10) \\
\sigma_{\text{actor}} &amp; \sim &amp; \text{HalfCauchy} (0, 1) \\
\sigma_{\text{block}} &amp; \sim &amp; \text{HalfCauchy} (0, 1)
\end{eqnarray}\]</span></p>
<p>Our brms model with varying intercepts for both <code>actor</code> and <code>block</code> now employs the <code>... (1 | actor) + (1 | block)</code> syntax.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">5</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">update</span>(b12.<span class="dv">4</span>,
         <span class="dt">newdata =</span> d,
         <span class="dt">formula =</span> pulled_left <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>prosoc_left <span class="op">+</span><span class="st"> </span>prosoc_left<span class="op">:</span>condition <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>actor) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>block),
         <span class="dt">iter =</span> <span class="dv">6000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">4</span>, <span class="dt">chains =</span> <span class="dv">4</span>, 
         <span class="dt">control =</span> <span class="kw">list</span>(<span class="dt">adapt_delta =</span> <span class="fl">0.99</span>))</code></pre></div>
<p>This time we increased <code>adapt_delta</code> to <code>0.99</code> to avoid divergent transitions. We can look at the primary coefficients with <code>print()</code>. McElreath encouraged us to inspect the trace plots. Here they are.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bayesplot)
<span class="kw">color_scheme_set</span>(<span class="st">&quot;orange&quot;</span>)

post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b12.<span class="dv">5</span>, <span class="dt">add_chain =</span> T)

post <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>lp__, <span class="op">-</span>iter) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mcmc_trace</span>(<span class="dt">facet_args =</span> <span class="kw">list</span>(<span class="dt">ncol =</span> <span class="dv">4</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">2500</span>, <span class="dv">5000</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="kw">c</span>(.<span class="dv">75</span>, .<span class="dv">06</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-689-1.png" width="768" /></p>
<p>The trace plots look great. We may as well examine the <span class="math inline">\(n_\text{eff} / N\)</span> ratios, too.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">neff_ratio</span>(b12.<span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mcmc_neff</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>()</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-690-1.png" width="768" /></p>
<p>About half of them are lower than we might like, but none are in the embarrassing <span class="math inline">\(n_\text{eff} / N \leq .1\)</span> range. Let’s look at the summary of the main parameters.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(b12.<span class="dv">5</span>)</code></pre></div>
<pre><code>##  Family: binomial 
##   Links: mu = logit 
## Formula: pulled_left ~ prosoc_left + (1 | actor) + (1 | block) + prosoc_left:condition 
##    Data: d (Number of observations: 504) 
## Samples: 4 chains, each with iter = 6000; warmup = 1000; thin = 1;
##          total post-warmup samples = 20000
## 
## Group-Level Effects: 
## ~actor (Number of levels: 7) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     2.27      0.93     1.13     4.58       5159 1.00
## 
## ~block (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.22      0.18     0.01     0.67       7999 1.00
## 
## Population-Level Effects: 
##                       Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept                 0.43      0.93    -1.34     2.43       4822 1.00
## prosoc_left               0.83      0.26     0.31     1.34      15231 1.00
## prosoc_left:condition    -0.13      0.30    -0.72     0.46      15826 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>This time, we’ll need to use <code>brms::ranef()</code> to get those <code>depth=2</code>-type estimates in the same metric displayed in the text. With <code>ranef()</code>, you get the group-specific estimates in a deviance metric. The <code>coef()</code> function, in contrast, yields the group-specific estimates in what you might call the natural metric. We’ll get more language for this in the next chapter.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ranef</span>(b12.<span class="dv">5</span>)<span class="op">$</span>actor[, , <span class="st">&quot;Intercept&quot;</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##   Estimate Est.Error  Q2.5 Q97.5
## 1    -1.15      0.94 -3.15  0.63
## 2     4.19      1.64  1.80  8.14
## 3    -1.46      0.94 -3.48  0.33
## 4    -1.46      0.94 -3.48  0.32
## 5    -1.15      0.94 -3.18  0.64
## 6    -0.20      0.94 -2.19  1.59
## 7     1.34      0.97 -0.71  3.22</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ranef</span>(b12.<span class="dv">5</span>)<span class="op">$</span>block[, , <span class="st">&quot;Intercept&quot;</span>] <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<pre><code>##   Estimate Est.Error  Q2.5 Q97.5
## 1    -0.17      0.23 -0.74  0.13
## 2     0.04      0.19 -0.32  0.47
## 3     0.05      0.19 -0.29  0.49
## 4     0.01      0.18 -0.37  0.41
## 5    -0.03      0.18 -0.44  0.34
## 6     0.11      0.21 -0.20  0.62</code></pre>
<p>We might make the coefficient plot of Figure 12.4.a like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stanplot</span>(b12.<span class="dv">5</span>, <span class="dt">pars =</span> <span class="kw">c</span>(<span class="st">&quot;^r_&quot;</span>, <span class="st">&quot;^b_&quot;</span>, <span class="st">&quot;^sd_&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">axis.text.y =</span> <span class="kw">element_text</span>(<span class="dt">hjust =</span> <span class="dv">0</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-693-1.png" width="336" /></p>
<p>Once we get the posterior samples, it’s easy to compare the random variances as in Figure 12.4.b.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sd_actor__Intercept)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;orange1&quot;</span>, <span class="dt">alpha =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(<span class="dt">x =</span> sd_block__Intercept), 
               <span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;orange4&quot;</span>, <span class="dt">alpha =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>)  <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">4</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="kw">expression</span>(sigma)) <span class="op">+</span>
<span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">y =</span> <span class="dv">2</span>, <span class="dt">label =</span> <span class="st">&quot;block&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;orange4&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> <span class="dv">2</span>, <span class="dt">y =</span> <span class="dv">3</span><span class="op">/</span><span class="dv">4</span>, <span class="dt">label =</span> <span class="st">&quot;actor&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;orange1&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-694-1.png" width="288" /></p>
<p>We might compare our models by their PSIS-LOO values.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l.b12.<span class="dv">4</span> &lt;-<span class="st"> </span><span class="kw">loo</span>(b12.<span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>)
l.b12.<span class="dv">5</span> &lt;-<span class="st"> </span><span class="kw">loo</span>(b12.<span class="dv">5</span>, <span class="dt">cores =</span> <span class="dv">4</span>)

<span class="kw">compare_ic</span>(l.b12.<span class="dv">4</span>, l.b12.<span class="dv">5</span>)</code></pre></div>
<pre><code>##                LOOIC    SE
## b12.4         531.61 19.50
## b12.5         532.75 19.68
## b12.4 - b12.5  -1.14  1.72</code></pre>
<p>And you can get the LOO version of the <code>p_waic</code>, the <code>p_loo</code>, like so.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l.b12.<span class="dv">4</span><span class="op">$</span><span class="st"> </span>estimates</code></pre></div>
<pre><code>##             Estimate         SE
## elpd_loo -265.806641  9.7518758
## p_loo       8.236901  0.4396798
## looic     531.613283 19.5037517</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">l.b12.<span class="dv">5</span><span class="op">$</span><span class="st"> </span>estimates</code></pre></div>
<pre><code>##            Estimate         SE
## elpd_loo -266.37486  9.8389698
## p_loo      10.39833  0.5325361
## looic     532.74972 19.6779396</code></pre>
<p>And if you peek at the structure of the loo objects, you’ll see you can call the <code>p_loo</code> values directly with something like <code>l.b12.5$ estimates[&quot;p_loo&quot;, 1]</code>. The results are quite similar to those in the text.</p>
<p>Anyways, the two models yield nearly-equivalent information criteria values. Yet recall what McElreath wrote: “There is nothing to gain here by selecting either model. The comparison of the two models tells a richer story” (p. 367).</p>
</div>
</div>
<div id="multilevel-posterior-predictions" class="section level2">
<h2><span class="header-section-number">12.4</span> Multilevel posterior predictions</h2>
<blockquote>
<p>… producing implied predictions from a fit model, is very helpful for understanding what the model means. Every model is a merger of sense and nonsense. When we understand a model, we can find its sense and control its nonsense. But as models get more complex, it is very difficult to impossible to understand them just by inspecting tables of posterior means and intervals. Exploring implied posterior predictions helps much more…</p>
<p>… The introduction of varying effects does introduce nuance, however.</p>
<p>First, we should no longer expect the model to exactly retrodict the sample, because adaptive regularization has as its goal to trade off poorer fit in sample for better inference and hopefully better fit out of sample. This is what shrinkage does for us…</p>
<p>Second, “prediction” in the context of a multilevel model requires additional choices. If we wish to validate a model against the specific clusters used to fit the model, that is one thing. But if we instead wish to compute predictions for new clusters, other than the one observed in the sample, that is quite another. We’ll consider each of these in turn, continuing to use the chimpanzees model from the previous section. (p. 376)</p>
</blockquote>
<div id="posterior-prediction-for-same-clusters." class="section level3">
<h3><span class="header-section-number">12.4.1</span> Posterior prediction for same clusters.</h3>
<p>Like McElreath did in the text, we’ll do this two ways. Recall we use <code>brms::fitted()</code> in place of <code>rethinking::link()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chimp &lt;-<span class="st"> </span><span class="dv">2</span>
nd &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">prosoc_left =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
         <span class="dt">condition   =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>),
         <span class="dt">actor       =</span> chimp)

(
  chimp_2_fitted &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b12.<span class="dv">4</span>,
         <span class="dt">newdata =</span> nd) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">factor</span>(<span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>), 
                            <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>)))
  )</code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   Estimate Est.Error  Q2.5 Q97.5 condition
##      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    
## 1    0.981   0.0195  0.929 1.000 0/0      
## 2    0.991   0.00949 0.965 1.000 1/0      
## 3    0.981   0.0195  0.929 1.000 0/1      
## 4    0.990   0.0107  0.961 1.000 1/1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(
  chimp_2_d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(actor <span class="op">==</span><span class="st"> </span>chimp) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(prosoc_left, condition) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">prob =</span> <span class="kw">mean</span>(pulled_left)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">str_c</span>(prosoc_left, <span class="st">&quot;/&quot;</span>, condition)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">factor</span>(condition, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>)))
)</code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   prosoc_left condition  prob
##         &lt;int&gt; &lt;fct&gt;     &lt;dbl&gt;
## 1           0 0/0           1
## 2           0 0/1           1
## 3           1 1/0           1
## 4           1 1/1           1</code></pre>
<p>McElreath didn’t show the corresponding plot in the text. It might look like this.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chimp_2_fitted <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># if you want to use `geom_line()` or `geom_ribbon()` with a factor on the x axis,</span>
<span class="st">  </span><span class="co"># you need to code something like `group = 1` in `aes()`</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> Estimate, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q2.<span class="dv">5</span>, <span class="dt">ymax =</span> Q97.<span class="dv">5</span>), <span class="dt">fill =</span> <span class="st">&quot;orange1&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> chimp_2_d,
             <span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> prob),
             <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Chimp #2&quot;</span>,
          <span class="dt">subtitle =</span> <span class="st">&quot;The posterior mean and 95%</span><span class="ch">\n</span><span class="st">intervals are the blue line</span><span class="ch">\n</span><span class="st">and orange band, respectively.</span><span class="ch">\n</span><span class="st">The empirical means are</span><span class="ch">\n</span><span class="st">the charcoal dots.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">c</span>(.<span class="dv">75</span>, <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">10</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-698-1.png" width="240" /></p>
<p>Do note how severely we’ve restricted the y-axis range. But okay, now let’s do things by hand. We’ll need to extract the posterior samples and look at the structure of the data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b12.<span class="dv">4</span>)

<span class="kw">glimpse</span>(post)</code></pre></div>
<pre><code>## Observations: 16,000
## Variables: 12
## $ b_Intercept               &lt;dbl&gt; 2.84660836, 3.31678210, 0.92818980, 0.97523659, 1.06284714, -1.57315237...
## $ b_prosoc_left             &lt;dbl&gt; 0.8027592, 0.6465404, 1.0693015, 1.0108346, 1.0995699, 0.5916456, 0.628...
## $ `b_prosoc_left:condition` &lt;dbl&gt; -0.304525935, -0.366690285, -0.183819656, -0.367542935, -0.434902624, 0...
## $ sd_actor__Intercept       &lt;dbl&gt; 3.947720, 3.301699, 4.001243, 3.917649, 3.835672, 2.342017, 1.791982, 2...
## $ `r_actor[1,Intercept]`    &lt;dbl&gt; -3.9548165, -3.7774344, -1.7728771, -1.7907886, -1.8501038, 0.9077583, ...
## $ `r_actor[2,Intercept]`    &lt;dbl&gt; 6.114119, 4.679728, 2.563180, 3.707954, 2.191760, 5.983084, 6.056797, 6...
## $ `r_actor[3,Intercept]`    &lt;dbl&gt; -4.0365853, -3.9685120, -2.1543374, -1.9182331, -2.1817965, 0.7542737, ...
## $ `r_actor[4,Intercept]`    &lt;dbl&gt; -3.86370546, -4.37117423, -2.05761046, -2.29637822, -2.19367525, 0.7843...
## $ `r_actor[5,Intercept]`    &lt;dbl&gt; -3.40039529, -3.90678422, -1.71947109, -1.79589150, -1.87454021, 0.9572...
## $ `r_actor[6,Intercept]`    &lt;dbl&gt; -2.6719766, -2.8518619, -0.8761091, -0.5816997, -0.9458346, 1.5937625, ...
## $ `r_actor[7,Intercept]`    &lt;dbl&gt; -0.988928592, -1.515283707, 1.451833859, 0.271678419, 1.194536366, 3.22...
## $ lp__                      &lt;dbl&gt; -280.3395, -281.0325, -278.8489, -278.2605, -278.8375, -280.8820, -283....</code></pre>
<p>McElreath didn’t show what his R code 12.29 <code>dens( post$a_actor[,5] )</code> would look like. But here’s our analogue.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="dt">actor_5 =</span><span class="st">`</span><span class="dt">r_actor[5,Intercept]</span><span class="st">`</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> actor_<span class="dv">5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Chimp #5&#39;s density&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>()</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-700-1.png" width="384" /></p>
<p>McElreath built his own <code>link()</code> function. Here we’ll build an alternative to <code>fitted()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># our hand-made `brms::fitted()` alternative</span>
my_fitted &lt;-<span class="st"> </span><span class="cf">function</span>(prosoc_left, condition){
  post <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">transmute</span>(<span class="dt">fitted =</span> (b_Intercept <span class="op">+</span><span class="st"> </span>
<span class="st">                          `</span><span class="dt">r_actor[5,Intercept]</span><span class="st">`</span> <span class="op">+</span><span class="st"> </span>
<span class="st">                          </span>b_prosoc_left <span class="op">*</span><span class="st"> </span>prosoc_left <span class="op">+</span><span class="st"> </span>
<span class="st">                          `</span><span class="dt">b_prosoc_left:condition</span><span class="st">`</span> <span class="op">*</span><span class="st"> </span>prosoc_left <span class="op">*</span><span class="st"> </span>condition) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                </span><span class="kw">inv_logit_scaled</span>())
}

<span class="co"># the posterior summaries</span>
(
  chimp_5_my_fitted &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">prosoc_left =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
       <span class="dt">condition     =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">post =</span> <span class="kw">map2</span>(prosoc_left, condition, my_fitted)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">unnest</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">str_c</span>(prosoc_left, <span class="st">&quot;/&quot;</span>, condition)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">factor</span>(condition, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(condition) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tidybayes<span class="op">::</span><span class="kw">mean_qi</span>(fitted)
  )</code></pre></div>
<pre><code>## # A tibble: 4 x 7
##   condition fitted .lower .upper .width .point .interval
##   &lt;fct&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 0/0        0.332  0.224  0.452   0.95 mean   qi       
## 2 1/0        0.527  0.382  0.670   0.95 mean   qi       
## 3 0/1        0.332  0.224  0.452   0.95 mean   qi       
## 4 1/1        0.495  0.351  0.637   0.95 mean   qi</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the empirical summaries</span>
chimp &lt;-<span class="st"> </span><span class="dv">5</span>
(
  chimp_5_d &lt;-
<span class="st">  </span>d <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">filter</span>(actor <span class="op">==</span><span class="st"> </span>chimp) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(prosoc_left, condition) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">prob =</span> <span class="kw">mean</span>(pulled_left)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">str_c</span>(prosoc_left, <span class="st">&quot;/&quot;</span>, condition)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">factor</span>(condition, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>)))
)</code></pre></div>
<pre><code>## # A tibble: 4 x 3
##   prosoc_left condition  prob
##         &lt;int&gt; &lt;fct&gt;     &lt;dbl&gt;
## 1           0 0/0       0.333
## 2           0 0/1       0.278
## 3           1 1/0       0.556
## 4           1 1/1       0.5</code></pre>
<p>Okay, let’s see how good we are at retrodicting the <code>pulled_left</code> probabilities for <code>actor == 5</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chimp_5_my_fitted <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> fitted, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> .lower, <span class="dt">ymax =</span> .upper), <span class="dt">fill =</span> <span class="st">&quot;orange1&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> chimp_5_d,
             <span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> prob),
             <span class="dt">color =</span> <span class="st">&quot;grey25&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Chimp #5&quot;</span>,
          <span class="dt">subtitle =</span> <span class="st">&quot;This plot is like the last except</span><span class="ch">\n</span><span class="st">we did more by hand.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.subtitle =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">10</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-702-1.png" width="240" /></p>
<p>Not bad.</p>
</div>
<div id="posterior-prediction-for-new-clusters." class="section level3">
<h3><span class="header-section-number">12.4.2</span> Posterior prediction for new clusters.</h3>
<p>By average actor, McElreath referred to a chimp with an intercept exactly at the population mean <span class="math inline">\(\alpha\)</span>. So this time we’ll only be working with the population parameters or what are also sometimes called the fixed effects. When you work with <code>brms::posterior_samples()</code> output, this would mean working with columns beginning with the <code>b_</code> prefix (i.e., <code>b_Intercept</code>, <code>b_prosoc_left</code>, and <code>b_prosoc_left:condition</code>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">post_average_actor &lt;-
<span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># here we use the linear regression formula to get the log_odds for the 4 conditions</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">0/0</span><span class="st">`</span> =<span class="st"> </span>b_Intercept,
            <span class="st">`</span><span class="dt">1/0</span><span class="st">`</span> =<span class="st"> </span>b_Intercept <span class="op">+</span><span class="st"> </span>b_prosoc_left,
            <span class="st">`</span><span class="dt">0/1</span><span class="st">`</span> =<span class="st"> </span>b_Intercept,
            <span class="st">`</span><span class="dt">1/1</span><span class="st">`</span> =<span class="st"> </span>b_Intercept <span class="op">+</span><span class="st"> </span>b_prosoc_left <span class="op">+</span><span class="st"> `</span><span class="dt">b_prosoc_left:condition</span><span class="st">`</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># with `mutate_all()` we can convert the estimates to probabilities in one fell swoop</span>
<span class="st">  </span><span class="kw">mutate_all</span>(inv_logit_scaled) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># putting the data in the long format and grouping by condition (i.e., `key`)</span>
<span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">level =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="co"># here we get the summary values for the plot</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">m  =</span> <span class="kw">mean</span>(value),
            <span class="co"># note we&#39;re using 80% intervals</span>
            <span class="dt">ll =</span> <span class="kw">quantile</span>(value, <span class="dt">probs =</span> .<span class="dv">1</span>),
            <span class="dt">ul =</span> <span class="kw">quantile</span>(value, <span class="dt">probs =</span> .<span class="dv">9</span>))

post_average_actor</code></pre></div>
<pre><code>## # A tibble: 4 x 4
##   key       m    ll    ul
##   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 0/0   0.587 0.344 0.822
## 2 1/0   0.744 0.539 0.914
## 3 0/1   0.587 0.344 0.822
## 4 1/1   0.721 0.506 0.903</code></pre>
<p>Figure 12.5.a.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p1 &lt;-
<span class="st">  </span>post_average_actor <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> key, <span class="dt">y =</span> m, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> ll, <span class="dt">ymax =</span> ul), <span class="dt">fill =</span> <span class="st">&quot;orange1&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Average actor&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">hjust =</span> .<span class="dv">5</span>))

p1</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-704-1.png" width="240" /></p>
<p>If we want to depict the variability across the chimps, we need to include <code>sd_actor__Intercept</code> into the calculations. In the first block of code, below, we simulate a bundle of new intercepts defined by</p>
<p><span class="math display">\[\alpha_\text{actor} \sim \text{Normal} (0, \sigma_\text{actor})\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the random effects</span>
<span class="kw">set.seed</span>(<span class="fl">12.42</span>)
ran_ef &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">random_effect =</span> <span class="kw">rnorm</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> post<span class="op">$</span>sd_actor__Intercept)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># with the `., ., ., .` syntax, we quadruple the previous line </span>
<span class="st">  </span><span class="kw">bind_rows</span>(., ., ., .) 

<span class="co"># the fixed effects (i.e., the population parameters)</span>
fix_ef &lt;-
<span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">transmute</span>(<span class="st">`</span><span class="dt">0/0</span><span class="st">`</span> =<span class="st"> </span>b_Intercept,
            <span class="st">`</span><span class="dt">1/0</span><span class="st">`</span> =<span class="st"> </span>b_Intercept <span class="op">+</span><span class="st"> </span>b_prosoc_left,
            <span class="st">`</span><span class="dt">0/1</span><span class="st">`</span> =<span class="st"> </span>b_Intercept,
            <span class="st">`</span><span class="dt">1/1</span><span class="st">`</span> =<span class="st"> </span>b_Intercept <span class="op">+</span><span class="st"> </span>b_prosoc_left <span class="op">+</span><span class="st"> `</span><span class="dt">b_prosoc_left:condition</span><span class="st">`</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">rename</span>(<span class="dt">condition    =</span> key, 
         <span class="dt">fixed_effect =</span> value) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">factor</span>(condition, <span class="dt">level =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>)))

<span class="co"># combine them</span>
ran_and_fix_ef &lt;-
<span class="st">  </span><span class="kw">bind_cols</span>(ran_ef, fix_ef) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">intercept =</span> fixed_effect <span class="op">+</span><span class="st"> </span>random_effect) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prob      =</span> <span class="kw">inv_logit_scaled</span>(intercept))

<span class="co"># to simplify things, we&#39;ll reduce them to summaries</span>
(
  marginal_effects &lt;-
<span class="st">  </span>ran_and_fix_ef <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">group_by</span>(condition) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">summarise</span>(<span class="dt">m  =</span> <span class="kw">mean</span>(prob),
            <span class="dt">ll =</span> <span class="kw">quantile</span>(prob, <span class="dt">probs =</span> .<span class="dv">1</span>),
            <span class="dt">ul =</span> <span class="kw">quantile</span>(prob, <span class="dt">probs =</span> .<span class="dv">9</span>))
  )</code></pre></div>
<pre><code>## # A tibble: 4 x 4
##   condition     m     ll    ul
##   &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 0/0       0.552 0.0772 0.970
## 2 1/0       0.661 0.159  0.986
## 3 0/1       0.552 0.0772 0.970
## 4 1/1       0.647 0.142  0.984</code></pre>
<p>Behold Figure 12.5.b.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p2 &lt;-
<span class="st">  </span>marginal_effects <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> m, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> ll, <span class="dt">ymax =</span> ul), <span class="dt">fill =</span> <span class="st">&quot;orange1&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Marginal of actor&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">hjust =</span> .<span class="dv">5</span>))

p2</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-706-1.png" width="240" /></p>
<p>Figure 12.5.c just takes a tiny bit more wrangling.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p3 &lt;-
<span class="st">  </span>ran_and_fix_ef <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="kw">rep</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>, <span class="dt">times =</span> <span class="dv">4</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(iter <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> prob, <span class="dt">group =</span> iter)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;orange3&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;50 simulated actors&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">hjust =</span> .<span class="dv">5</span>))

p3</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-707-1.png" width="240" /></p>
<p>For the finale, we’ll stitch the three plots together.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gridExtra)

<span class="kw">grid.arrange</span>(p1, p2, p3, <span class="dt">ncol =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-708-1.png" width="720" /></p>
<div id="bonus-lets-use-fitted-this-time." class="section level4">
<h4><span class="header-section-number">12.4.2.1</span> Bonus: Let’s use <code>fitted()</code> this time.</h4>
<p>We just made those plots using various wrangled versions of <code>post</code>, the data frame returned by <code>posterior_samples(b.12.4)</code>. If you followed along closely, part of what made that a great exercise is that it forced you to consider what the various vectors in <code>post</code> meant with respect to the model formula. But it’s also handy to see how to do that from a different perspective. So in this section, we’ll repeat that process by relying on the <code>fitted()</code> function, instead. We’ll go in the same order, starting with the average actor.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nd &lt;-
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">prosoc_left =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
         <span class="dt">condition   =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>))

(
  fitd_b12.<span class="dv">4</span> &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b12.<span class="dv">4</span>,
       <span class="dt">newdata =</span> nd,
       <span class="dt">re_formula =</span> <span class="ot">NA</span>,
       <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">1</span>, .<span class="dv">9</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">str_c</span>(prosoc_left, <span class="st">&quot;/&quot;</span>, condition) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">           </span><span class="kw">factor</span>(., <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>)))
  )</code></pre></div>
<pre><code>## # A tibble: 4 x 6
##   Estimate Est.Error   Q10   Q90 prosoc_left condition
##      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;    
## 1    0.587     0.182 0.344 0.822           0 0/0      
## 2    0.744     0.152 0.539 0.914           1 1/0      
## 3    0.587     0.182 0.344 0.822           0 0/1      
## 4    0.721     0.159 0.506 0.903           1 1/1</code></pre>
<p>You should notice a few things. Since <code>b12.4</code> is a multilevel model, it had three predictors: <code>prosoc_left</code>, <code>condition</code>, and <code>actor</code>. However, our <code>nd</code> data only included the first two of those predictors. The reason <code>fitted()</code> permitted that was because we set <code>re_formula = NA</code>. When you do that, you tell <code>fitted()</code> to ignore group-level effects (i.e., focus only on the fixed effects). This was our <code>fitted()</code> version of ignoring the <code>r_</code> vectors returned by <code>posterior_samples()</code>. Here’s the plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p4 &lt;-
<span class="st">  </span>fitd_b12.<span class="dv">4</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> Estimate, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q10, <span class="dt">ymax =</span> Q90), <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;orange1&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Average actor&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">hjust =</span> .<span class="dv">5</span>))

p4</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-710-1.png" width="240" /></p>
<p>For marginal of actor, we can continue using the same <code>nd</code> data. This time we’ll be sticking with the default <code>re_formula</code> setting, which will accommodate the multilevel nature of the model. However, we’ll also be adding <code>allow_new_levels = T</code> and <code>sample_new_levels = &quot;gaussian&quot;</code>. The former will allow us to marginalize across the specific actors in our data and the latter will instruct <code>fitted()</code> to use the multivariate normal distribution implied by the random effects. It’ll make more sense why I say <em>multivariate</em> normal by the end of the next chapter. For now, just go with it.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(
  fitd_b12.<span class="dv">4</span> &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b12.<span class="dv">4</span>,
         <span class="dt">newdata =</span> nd,
         <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">1</span>, .<span class="dv">9</span>),
         <span class="dt">allow_new_levels =</span> T,
         <span class="dt">sample_new_levels =</span> <span class="st">&quot;gaussian&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">condition =</span> <span class="kw">str_c</span>(prosoc_left, <span class="st">&quot;/&quot;</span>, condition) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">           </span><span class="kw">factor</span>(., <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>)))
  )</code></pre></div>
<pre><code>## # A tibble: 4 x 6
##   Estimate Est.Error    Q10   Q90 prosoc_left condition
##      &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;    
## 1    0.556     0.330 0.0679 0.970           0 0/0      
## 2    0.665     0.312 0.144  0.987           1 1/0      
## 3    0.556     0.330 0.0679 0.970           0 0/1      
## 4    0.648     0.316 0.124  0.985           1 1/1</code></pre>
<p>Here’s our <code>fitted()</code>-based marginal of <code>actor</code> plot.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p5 &lt;-
<span class="st">  </span>fitd_b12.<span class="dv">4</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> Estimate, <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q10, <span class="dt">ymax =</span> Q90), <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;orange1&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Marginal of actor&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">hjust =</span> .<span class="dv">5</span>))

p5</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-712-1.png" width="240" /></p>
<p>For the simulated actors plot, we’ll just amend our process from the last one. This time we’re setting <code>summary = F</code>, in order to keep the iteration-specific results, and setting <code>nsamples = n_sim</code>. <code>n_sim</code> is just a name for the number of actors we’d like to simulate (i.e., 50, as in the text).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># how many simulated actors would you like?</span>
n_sim &lt;-<span class="st"> </span><span class="dv">50</span>

(
  fitd_b12.<span class="dv">4</span> &lt;-
<span class="st">  </span><span class="kw">fitted</span>(b12.<span class="dv">4</span>,
         <span class="dt">newdata =</span> nd,
         <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">1</span>, .<span class="dv">9</span>),
         <span class="dt">allow_new_levels =</span> T,
         <span class="dt">sample_new_levels =</span> <span class="st">&quot;gaussian&quot;</span>,
         <span class="dt">summary =</span> F,
         <span class="dt">nsamples =</span> n_sim) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span>n_sim) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>iter) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">              </span><span class="kw">transmute</span>(<span class="dt">condition =</span> <span class="kw">str_c</span>(prosoc_left, <span class="st">&quot;/&quot;</span>, condition) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                          </span><span class="kw">factor</span>(., <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;0/0&quot;</span>, <span class="st">&quot;1/0&quot;</span>, <span class="st">&quot;0/1&quot;</span>, <span class="st">&quot;1/1&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">              </span><span class="kw">expand</span>(condition, <span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span>n_sim))
  )</code></pre></div>
<pre><code>## # A tibble: 200 x 5
##     iter key     value condition iter1
##    &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;fct&gt;     &lt;int&gt;
##  1     1 V1    0.00971 0/0           1
##  2     2 V1    0.498   0/0           2
##  3     3 V1    0.670   0/0           3
##  4     4 V1    0.615   0/0           4
##  5     5 V1    0.896   0/0           5
##  6     6 V1    0.436   0/0           6
##  7     7 V1    0.220   0/0           7
##  8     8 V1    0.510   0/0           8
##  9     9 V1    0.945   0/0           9
## 10    10 V1    0.326   0/0          10
## # ... with 190 more rows</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p6 &lt;-
<span class="st">  </span>fitd_b12.<span class="dv">4</span> <span class="op">%&gt;%</span>
<span class="st">  </span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> condition, <span class="dt">y =</span> value, <span class="dt">group =</span> iter)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;50 simulated actors&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">14</span>, <span class="dt">hjust =</span> .<span class="dv">5</span>))

p6</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-714-1.png" width="240" /></p>
<p>Here they are altogether.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">grid.arrange</span>(p4, p5, p6, <span class="dt">ncol =</span> <span class="dv">3</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-715-1.png" width="720" /></p>
</div>
</div>
<div id="focus-and-multilevel-prediction." class="section level3">
<h3><span class="header-section-number">12.4.3</span> Focus and multilevel prediction.</h3>
<p>First, let’s load the <code>Kline</code> data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># prep data</span>
<span class="kw">library</span>(rethinking)
<span class="kw">data</span>(Kline)
d &lt;-<span class="st"> </span>Kline</code></pre></div>
<p>Switch out the packages, once again.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)
<span class="kw">library</span>(brms)
<span class="kw">rm</span>(Kline)</code></pre></div>
<p>The statistical formula for our multilevel count model is</p>
<p><span class="math display">\[
\begin{eqnarray}
\text{total_tools}_i &amp; \sim &amp; \text{Poisson} (\mu_i) \\
\text{log} (\mu_i) &amp; = &amp; \alpha + \alpha_{\text{culture}_i} + \beta \text{log} (\text{population}_i) \\
\alpha &amp; \sim &amp; \text{Normal} (0, 10) \\
\beta &amp; \sim &amp; \text{Normal} (0, 1) \\
\alpha_{\text{culture}} &amp; \sim &amp; \text{Normal} (0, \sigma_{\text{culture}}) \\
\sigma_{\text{culture}} &amp; \sim &amp; \text{HalfCauchy} (0, 1) \\
\end{eqnarray}
\]</span></p>
<p>With brms, we don’t actually need to make the <code>logpop</code> or <code>society</code> variables. We’re ready to fit the multilevel <code>Kline</code> model with the data in hand.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b12.<span class="dv">6</span> &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> poisson,
      total_tools <span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>intercept <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(population) <span class="op">+</span><span class="st"> </span>
<span class="st">        </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>culture),
      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b, <span class="dt">coef =</span> intercept),
                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> b),
                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sd)),
      <span class="dt">iter =</span> <span class="dv">4000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">cores =</span> <span class="dv">3</span>, <span class="dt">chains =</span> <span class="dv">3</span>)</code></pre></div>
<p>Note how we used the special <code>0 + intercept</code> syntax rather than using the default Intercept. This is because our predictor variable was not mean centered. For more info, see <a href="https://github.com/paul-buerkner/brms/issues/114">here</a>. Though we used the <code>0 + intercept</code> syntax for the fixed effect, it was not necessary for the random effect. Both ways work.</p>
<p>Here is the data-processing work for our variant of Figure 12.6.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nd &lt;-<span class="st"> </span>
<span class="st">  </span><span class="kw">tibble</span>(<span class="dt">population =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">1000</span>, <span class="dt">to =</span> <span class="dv">400000</span>, <span class="dt">by =</span> <span class="dv">5000</span>),
         <span class="co"># To &quot;simulate counterfactual societies, using the hyper-parameters&quot; (p. 383), </span>
         <span class="co"># we&#39;ll plug a new island into the `culture` variable</span>
         <span class="dt">culture    =</span> <span class="st">&quot;my_island&quot;</span>) 

pred_<span class="fl">12.6</span> &lt;-
<span class="st">  </span><span class="kw">predict</span>(b12.<span class="dv">6</span>,
          <span class="co"># This allows us to simulate values for our counterfactual island, &quot;my_island&quot;</span>
          <span class="dt">allow_new_levels =</span> T,
          <span class="co"># Here we explicitly tell brms we want to include the group-level effects</span>
          <span class="dt">re_formula =</span> <span class="op">~</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>culture),
          <span class="co"># From the brms manual, this uses the &quot;(multivariate) normal distribution implied by </span>
          <span class="co"># the group-level standard deviations and correlations&quot;, which appears to be </span>
          <span class="co"># what McElreath did in the text.</span>
          <span class="dt">sample_new_levels =</span> <span class="st">&quot;gaussian&quot;</span>,
          <span class="dt">newdata =</span> nd,
          <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">015</span>, .<span class="dv">055</span>, .<span class="dv">165</span>, .<span class="dv">835</span>, .<span class="dv">945</span>, .<span class="dv">985</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>(nd)

pred_<span class="fl">12.6</span> <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span><span class="kw">glimpse</span>()</code></pre></div>
<pre><code>## Observations: 80
## Variables: 10
## $ Estimate   &lt;dbl&gt; 19.69167, 31.10667, 36.57911, 40.37367, 43.45178, 45.96167, 48.30811, 50.49456, 52.206...
## $ Est.Error  &lt;dbl&gt; 9.576842, 14.402249, 17.682183, 20.466952, 22.705786, 24.992111, 27.111403, 29.735646,...
## $ Q1.5       &lt;dbl&gt; 5.000, 10.000, 13.000, 14.000, 15.000, 16.000, 17.000, 18.000, 18.000, 19.000, 19.000,...
## $ Q5.5       &lt;dbl&gt; 8, 15, 18, 20, 21, 23, 23, 25, 26, 26, 27, 27, 28, 29, 29, 29, 30, 30, 30, 31, 31, 32,...
## $ Q16.5      &lt;dbl&gt; 11, 20, 24, 26, 28, 30, 31, 33, 34, 35, 35, 36, 37, 38, 39, 39, 40, 40, 41, 41, 42, 43...
## $ Q83.5      &lt;dbl&gt; 27.000, 41.000, 48.000, 53.000, 57.000, 60.000, 63.000, 66.000, 68.000, 70.000, 72.000...
## $ Q94.5      &lt;dbl&gt; 35.000, 53.000, 62.000, 68.000, 73.000, 77.055, 81.055, 86.000, 88.000, 91.000, 95.000...
## $ Q98.5      &lt;dbl&gt; 47.000, 70.000, 80.000, 91.000, 96.000, 104.015, 110.000, 116.000, 122.015, 127.015, 1...
## $ population &lt;dbl&gt; 1000, 6000, 11000, 16000, 21000, 26000, 31000, 36000, 41000, 46000, 51000, 56000, 6100...
## $ culture    &lt;chr&gt; &quot;my_island&quot;, &quot;my_island&quot;, &quot;my_island&quot;, &quot;my_island&quot;, &quot;my_island&quot;, &quot;my_island&quot;, &quot;my_isla...</code></pre>
<p>For a detailed discussion on this way of using <code>brms::predict()</code>, see <a href="http://thestudyofthehousehold.com/2018/02/13/2018-02-13-easily-made-fitted-and-predicted-values-made-easy/">Andrew MacDonald’s great blogpost on this very figure</a>. Here’s what we’ve been working for:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred_<span class="fl">12.6</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="kw">log</span>(population), <span class="dt">y =</span> Estimate)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q1.<span class="dv">5</span>,  <span class="dt">ymax =</span> Q98.<span class="dv">5</span>), <span class="dt">fill =</span> <span class="st">&quot;orange2&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q5.<span class="dv">5</span>,  <span class="dt">ymax =</span> Q94.<span class="dv">5</span>), <span class="dt">fill =</span> <span class="st">&quot;orange2&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="kw">aes</span>(<span class="dt">ymin =</span> Q16.<span class="dv">5</span>, <span class="dt">ymax =</span> Q83.<span class="dv">5</span>), <span class="dt">fill =</span> <span class="st">&quot;orange2&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">ylim =</span> <span class="kw">range</span>(d<span class="op">$</span>total_tools)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">color =</span> <span class="st">&quot;orange4&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="dt">data =</span> d, <span class="kw">aes</span>(<span class="dt">y =</span> total_tools, <span class="dt">label =</span> culture), 
            <span class="dt">size =</span> <span class="fl">2.33</span>, <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&quot;Total tools as a function of log(population)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_fivethirtyeight</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme</span>(<span class="dt">plot.title =</span> <span class="kw">element_text</span>(<span class="dt">size =</span> <span class="dv">12</span>, <span class="dt">hjust =</span> .<span class="dv">5</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-719-1.png" width="360" /></p>
<p>Glorious.</p>
<blockquote>
<p>The envelope of predictions is a lot wider here than it was back in Chapter 10. This is a consequene of the varying intercepts, combined with the fact that there is much more variation in the data than a pure-Poisson model anticipates. (p. 384)</p>
</blockquote>
</div>
</div>
<div id="reference-11" class="section level2 unnumbered">
<h2>Reference</h2>
<p><a href="https://xcelab.net/rm/statistical-rethinking/">McElreath, R. (2016). <em>Statistical rethinking: A Bayesian course with examples in R and Stan.</em> Chapman &amp; Hall/CRC Press.</a></p>
</div>
<div id="session-info-11" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sessionInfo</span>()</code></pre></div>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] grid      parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] gridExtra_2.3      bayesplot_1.6.0    ggthemes_3.5.0     forcats_0.3.0      stringr_1.3.1     
##  [6] dplyr_0.7.6        purrr_0.2.5        readr_1.1.1        tidyr_0.8.1        tibble_1.4.2      
## [11] tidyverse_1.2.1    brms_2.5.0         Rcpp_0.12.18       rstan_2.17.3       StanHeaders_2.17.2
## [16] ggplot2_3.0.0     
## 
## loaded via a namespace (and not attached):
##   [1] pacman_0.4.6              utf8_1.1.4                ggstance_0.3              tidyselect_0.2.4         
##   [5] htmlwidgets_1.2           munsell_0.5.0             codetools_0.2-15          nleqslv_3.3.2            
##   [9] DT_0.4                    miniUI_0.1.1.1            withr_2.1.2               Brobdingnag_1.2-5        
##  [13] colorspace_1.3-2          highr_0.7                 knitr_1.20                rstudioapi_0.7           
##  [17] stats4_3.5.1              Rttf2pt1_1.3.7            labeling_0.3              mnormt_1.5-5             
##  [21] bridgesampling_0.4-0      rprojroot_1.3-2           coda_0.19-1               xfun_0.3                 
##  [25] R6_2.2.2                  markdown_0.8              HDInterval_0.2.0          reshape_0.8.7            
##  [29] assertthat_0.2.0          promises_1.0.1            scales_0.5.0              beeswarm_0.2.3           
##  [33] gtable_0.2.0              rlang_0.2.1               extrafontdb_1.0           lazyeval_0.2.1           
##  [37] broom_0.4.5               inline_0.3.15             yaml_2.1.19               reshape2_1.4.3           
##  [41] abind_1.4-5               modelr_0.1.2              threejs_0.3.1             crosstalk_1.0.0          
##  [45] backports_1.1.2           httpuv_1.4.4.2            rsconnect_0.8.8           extrafont_0.17           
##  [49] tools_3.5.1               bookdown_0.7              psych_1.8.4               RColorBrewer_1.1-2       
##  [53] ggridges_0.5.0            plyr_1.8.4                base64enc_0.1-3           progress_1.2.0           
##  [57] prettyunits_1.0.2         zoo_1.8-2                 LaplacesDemon_16.1.1      haven_1.1.2              
##  [61] magrittr_1.5              colourpicker_1.0          mvtnorm_1.0-8             tidybayes_1.0.1          
##  [65] matrixStats_0.54.0        hms_0.4.2                 shinyjs_1.0               mime_0.5                 
##  [69] evaluate_0.10.1           arrayhelpers_1.0-20160527 xtable_1.8-2              shinystan_2.5.0          
##  [73] readxl_1.1.0              rstantools_1.5.0          compiler_3.5.1            maps_3.3.0               
##  [77] crayon_1.3.4              htmltools_0.3.6           later_0.7.3               lubridate_1.7.4          
##  [81] MASS_7.3-50               Matrix_1.2-14             cli_1.0.0                 bindr_0.1.1              
##  [85] igraph_1.2.1              pkgconfig_2.0.1           foreign_0.8-70            xml2_1.2.0               
##  [89] svUnit_0.7-12             dygraphs_1.1.1.5          vipor_0.4.5               rvest_0.3.2              
##  [93] digest_0.6.15             rmarkdown_1.10            cellranger_1.1.0          shiny_1.1.0              
##  [97] gtools_3.8.1              nlme_3.1-137              jsonlite_1.5              bindrcpp_0.2.2           
## [101] mapproj_1.2.6             viridisLite_0.3.0         pillar_1.2.3              lattice_0.20-35          
## [105] loo_2.0.0                 httr_1.3.1                glue_1.2.0                xts_0.10-2               
## [109] shinythemes_1.1.1         pander_0.6.2              stringi_1.2.3</code></pre>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="monsters-and-mixtures.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="adventures-in-covariance.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
