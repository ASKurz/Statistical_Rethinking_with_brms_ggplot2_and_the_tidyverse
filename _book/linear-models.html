<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Linear Models | Statistical rethinking with brms, ggplot2, and the tidyverse</title>
  <meta name="description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Linear Models | Statistical rethinking with brms, ggplot2, and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  <meta name="github-repo" content="ASKURZ/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Linear Models | Statistical rethinking with brms, ggplot2, and the tidyverse" />
  <meta name="twitter:site" content="@SolomonKurz" />
  <meta name="twitter:description" content="This project is an attempt to re-express the code in McElreath’s textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style." />
  

<meta name="author" content="A Solomon Kurz" />


<meta name="date" content="2020-10-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sampling-the-imaginary.html"/>
<link rel="next" href="multivariate-linear-models.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>This is a love letter</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-this"><i class="fa fa-check"></i>Why this?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#my-assumptions-about-you"><i class="fa fa-check"></i>My assumptions about you</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-and-understand-this-project"><i class="fa fa-check"></i>How to use and understand this project</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#you-can-do-this-too"><i class="fa fa-check"></i>You can do this, too</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#we-have-updates"><i class="fa fa-check"></i>We have updates</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-0.9.0."><i class="fa fa-check"></i>Version 0.9.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.0.0."><i class="fa fa-check"></i>Version 1.0.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.0.1."><i class="fa fa-check"></i>Version 1.0.1.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.1.0."><i class="fa fa-check"></i>Version 1.1.0.</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-1.2.0."><i class="fa fa-check"></i>Version 1.2.0.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#is-this-material-obsolete"><i class="fa fa-check"></i>Is this material obsolete?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#thank-yous-are-in-order"><i class="fa fa-check"></i>Thank-you’s are in order</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html"><i class="fa fa-check"></i><b>1</b> The Golem of Prague</a><ul>
<li class="chapter" data-level="" data-path="the-golem-of-prague.html"><a href="the-golem-of-prague.html#session-info"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html"><i class="fa fa-check"></i><b>2</b> Small Worlds and Large Worlds</a><ul>
<li class="chapter" data-level="2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#the-garden-of-forking-data"><i class="fa fa-check"></i><b>2.1</b> The garden of forking data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#counting-possibilities."><i class="fa fa-check"></i><b>2.1.1</b> Counting possibilities.</a></li>
<li class="chapter" data-level="2.1.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#using-prior-information."><i class="fa fa-check"></i><b>2.1.2</b> Using prior information.</a></li>
<li class="chapter" data-level="2.1.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#from-counts-to-probability."><i class="fa fa-check"></i><b>2.1.3</b> From counts to probability.</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#building-a-model"><i class="fa fa-check"></i><b>2.2</b> Building a model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#a-data-story."><i class="fa fa-check"></i><b>2.2.1</b> A data story.</a></li>
<li class="chapter" data-level="2.2.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#bayesian-updating."><i class="fa fa-check"></i><b>2.2.2</b> Bayesian updating.</a></li>
<li class="chapter" data-level="2.2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#evaluate."><i class="fa fa-check"></i><b>2.2.3</b> Evaluate.</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#components-of-the-model"><i class="fa fa-check"></i><b>2.3</b> Components of the model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#likelihood."><i class="fa fa-check"></i><b>2.3.1</b> Likelihood.</a></li>
<li class="chapter" data-level="2.3.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#parameters."><i class="fa fa-check"></i><b>2.3.2</b> Parameters.</a></li>
<li class="chapter" data-level="2.3.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#prior."><i class="fa fa-check"></i><b>2.3.3</b> Prior.</a></li>
<li class="chapter" data-level="2.3.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#posterior."><i class="fa fa-check"></i><b>2.3.4</b> Posterior.</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#making-the-model-go"><i class="fa fa-check"></i><b>2.4</b> Making the model go</a><ul>
<li class="chapter" data-level="2.4.1" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#grid-approximation."><i class="fa fa-check"></i><b>2.4.1</b> Grid approximation.</a></li>
<li class="chapter" data-level="2.4.2" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#quadratic-approximation."><i class="fa fa-check"></i><b>2.4.2</b> Quadratic approximation.</a></li>
<li class="chapter" data-level="2.4.3" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#markov-chain-monte-carlo."><i class="fa fa-check"></i><b>2.4.3</b> Markov chain Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="small-worlds-and-large-worlds.html"><a href="small-worlds-and-large-worlds.html#session-info-1"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html"><i class="fa fa-check"></i><b>3</b> Sampling the Imaginary</a><ul>
<li class="chapter" data-level="3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-from-a-grid-like-approximate-posterior"><i class="fa fa-check"></i><b>3.1</b> Sampling from a grid-like approximate posterior</a></li>
<li class="chapter" data-level="3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-summarize"><i class="fa fa-check"></i><b>3.2</b> Sampling to summarize</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-boundaries."><i class="fa fa-check"></i><b>3.2.1</b> Intervals of defined boundaries.</a></li>
<li class="chapter" data-level="3.2.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#intervals-of-defined-mass."><i class="fa fa-check"></i><b>3.2.2</b> Intervals of defined mass.</a></li>
<li class="chapter" data-level="3.2.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#point-estimates."><i class="fa fa-check"></i><b>3.2.3</b> Point estimates.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#sampling-to-simulate-prediction"><i class="fa fa-check"></i><b>3.3</b> Sampling to simulate prediction</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#dummy-data."><i class="fa fa-check"></i><b>3.3.1</b> Dummy data.</a></li>
<li class="chapter" data-level="3.3.2" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#model-checking."><i class="fa fa-check"></i><b>3.3.2</b> Model checking.</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#summary-lets-practice-with-brms"><i class="fa fa-check"></i><b>3.4</b> <del>Summary</del> Let’s practice with brms</a></li>
<li class="chapter" data-level="" data-path="sampling-the-imaginary.html"><a href="sampling-the-imaginary.html#session-info-2"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>4</b> Linear Models</a><ul>
<li class="chapter" data-level="4.1" data-path="linear-models.html"><a href="linear-models.html#why-normal-distributions-are-normal"><i class="fa fa-check"></i><b>4.1</b> Why normal distributions are normal</a><ul>
<li class="chapter" data-level="4.1.1" data-path="linear-models.html"><a href="linear-models.html#normal-by-addition."><i class="fa fa-check"></i><b>4.1.1</b> Normal by addition.</a></li>
<li class="chapter" data-level="4.1.2" data-path="linear-models.html"><a href="linear-models.html#normal-by-multiplication."><i class="fa fa-check"></i><b>4.1.2</b> Normal by multiplication.</a></li>
<li class="chapter" data-level="4.1.3" data-path="linear-models.html"><a href="linear-models.html#normal-by-log-multiplication."><i class="fa fa-check"></i><b>4.1.3</b> Normal by log-multiplication.</a></li>
<li class="chapter" data-level="4.1.4" data-path="linear-models.html"><a href="linear-models.html#using-gaussian-distributions."><i class="fa fa-check"></i><b>4.1.4</b> Using Gaussian distributions.</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-models.html"><a href="linear-models.html#a-language-for-describing-models"><i class="fa fa-check"></i><b>4.2</b> A language for describing models</a><ul>
<li class="chapter" data-level="4.2.1" data-path="linear-models.html"><a href="linear-models.html#re-describing-the-globe-tossing-model."><i class="fa fa-check"></i><b>4.2.1</b> Re-describing the globe tossing model.</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-models.html"><a href="linear-models.html#a-gaussian-model-of-height"><i class="fa fa-check"></i><b>4.3</b> A Gaussian model of height</a><ul>
<li class="chapter" data-level="4.3.1" data-path="linear-models.html"><a href="linear-models.html#the-data."><i class="fa fa-check"></i><b>4.3.1</b> The data.</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-models.html"><a href="linear-models.html#the-model."><i class="fa fa-check"></i><b>4.3.2</b> The model.</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-models.html"><a href="linear-models.html#grid-approximation-of-the-posterior-distribution."><i class="fa fa-check"></i><b>4.3.3</b> Grid approximation of the posterior distribution.</a></li>
<li class="chapter" data-level="4.3.4" data-path="linear-models.html"><a href="linear-models.html#sampling-from-the-posterior."><i class="fa fa-check"></i><b>4.3.4</b> Sampling from the posterior.</a></li>
<li class="chapter" data-level="4.3.5" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model-with-map-brm."><i class="fa fa-check"></i><b>4.3.5</b> Fitting the model with <del><code>map</code></del> <code>brm()</code>.</a></li>
<li class="chapter" data-level="4.3.6" data-path="linear-models.html"><a href="linear-models.html#sampling-from-a-map-brm-fit."><i class="fa fa-check"></i><b>4.3.6</b> Sampling from a <del><code>map</code></del> <code>brm()</code> fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-models.html"><a href="linear-models.html#adding-a-predictor"><i class="fa fa-check"></i><b>4.4</b> Adding a predictor</a><ul>
<li class="chapter" data-level="4.4.1" data-path="linear-models.html"><a href="linear-models.html#the-linear-model-strategy."><i class="fa fa-check"></i><b>4.4.1</b> The linear model strategy.</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-models.html"><a href="linear-models.html#fitting-the-model."><i class="fa fa-check"></i><b>4.4.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="4.4.3" data-path="linear-models.html"><a href="linear-models.html#interpreting-the-model-fit."><i class="fa fa-check"></i><b>4.4.3</b> Interpreting the model fit.</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="linear-models.html"><a href="linear-models.html#polynomial-regression"><i class="fa fa-check"></i><b>4.5</b> Polynomial regression</a></li>
<li class="chapter" data-level="" data-path="linear-models.html"><a href="linear-models.html#session-info-3"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html"><i class="fa fa-check"></i><b>5</b> Multivariate Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#spurious-associations"><i class="fa fa-check"></i><b>5.1</b> Spurious associations</a><ul>
<li class="chapter" data-level="5.1.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multivariate-notation."><i class="fa fa-check"></i><b>5.1.1</b> Multivariate notation.</a></li>
<li class="chapter" data-level="5.1.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#fitting-the-model.-1"><i class="fa fa-check"></i><b>5.1.2</b> Fitting the model.</a></li>
<li class="chapter" data-level="5.1.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#plotting-multivariate-posteriors."><i class="fa fa-check"></i><b>5.1.3</b> Plotting multivariate posteriors.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#masked-relationship"><i class="fa fa-check"></i><b>5.2</b> Masked relationship</a></li>
<li class="chapter" data-level="5.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinearity"><i class="fa fa-check"></i><b>5.3</b> Multicollinearity</a><ul>
<li class="chapter" data-level="5.3.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-legs."><i class="fa fa-check"></i><b>5.3.1</b> Multicollinear legs.</a></li>
<li class="chapter" data-level="5.3.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#multicollinear-milk."><i class="fa fa-check"></i><b>5.3.2</b> Multicollinear <code>milk</code>.</a></li>
<li class="chapter" data-level="5.3.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#post-treatment-bias."><i class="fa fa-check"></i><b>5.3.3</b> Post-treatment bias.</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#categorical-variables"><i class="fa fa-check"></i><b>5.4</b> Categorical variables</a><ul>
<li class="chapter" data-level="5.4.1" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#binary-categories."><i class="fa fa-check"></i><b>5.4.1</b> Binary categories.</a></li>
<li class="chapter" data-level="5.4.2" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#many-categories."><i class="fa fa-check"></i><b>5.4.2</b> Many categories.</a></li>
<li class="chapter" data-level="5.4.3" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#adding-regular-predictor-variables."><i class="fa fa-check"></i><b>5.4.3</b> Adding regular predictor variables.</a></li>
<li class="chapter" data-level="5.4.4" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#another-approach-unique-intercepts."><i class="fa fa-check"></i><b>5.4.4</b> Another approach: Unique intercepts.</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#ordinary-least-squares-and-lm"><i class="fa fa-check"></i><b>5.5</b> <del>Ordinary least squares and <code>lm()</code></del></a></li>
<li class="chapter" data-level="" data-path="multivariate-linear-models.html"><a href="multivariate-linear-models.html#session-info-4"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html"><i class="fa fa-check"></i><b>6</b> Overfitting, Regularization, and Information Criteria</a><ul>
<li class="chapter" data-level="6.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#the-problem-with-parameters"><i class="fa fa-check"></i><b>6.1</b> The problem with parameters</a><ul>
<li class="chapter" data-level="6.1.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#more-parameters-always-improve-fit."><i class="fa fa-check"></i><b>6.1.1</b> More parameters always improve fit.</a></li>
<li class="chapter" data-level="6.1.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#too-few-parameters-hurts-too."><i class="fa fa-check"></i><b>6.1.2</b> Too few parameters hurts, too.</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-theory-and-model-performance"><i class="fa fa-check"></i><b>6.2</b> Information theory and model performance</a><ul>
<li class="chapter" data-level="6.2.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#firing-the-weatherperson."><i class="fa fa-check"></i><b>6.2.1</b> Firing the weatherperson.</a></li>
<li class="chapter" data-level="6.2.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-and-uncertainty."><i class="fa fa-check"></i><b>6.2.2</b> Information and uncertainty.</a></li>
<li class="chapter" data-level="6.2.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-entropy-to-accuracy."><i class="fa fa-check"></i><b>6.2.3</b> From entropy to accuracy.</a></li>
<li class="chapter" data-level="6.2.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-divergence-to-deviance."><i class="fa fa-check"></i><b>6.2.4</b> From divergence to deviance.</a></li>
<li class="chapter" data-level="6.2.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#from-deviance-to-out-of-sample."><i class="fa fa-check"></i><b>6.2.5</b> From deviance to out-of-sample.</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#regularization"><i class="fa fa-check"></i><b>6.3</b> Regularization</a></li>
<li class="chapter" data-level="6.4" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#information-criteria"><i class="fa fa-check"></i><b>6.4</b> Information criteria</a><ul>
<li class="chapter" data-level="6.4.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic."><i class="fa fa-check"></i><b>6.4.1</b> DIC.</a></li>
<li class="chapter" data-level="6.4.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#waic."><i class="fa fa-check"></i><b>6.4.2</b> WAIC.</a></li>
<li class="chapter" data-level="6.4.3" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#dic-and-waic-as-estimates-of-deviance."><i class="fa fa-check"></i><b>6.4.3</b> DIC and WAIC as estimates of deviance.</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#using-information-criteria"><i class="fa fa-check"></i><b>6.5</b> Using information criteria</a><ul>
<li class="chapter" data-level="6.5.1" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-comparison."><i class="fa fa-check"></i><b>6.5.1</b> Model comparison.</a></li>
<li class="chapter" data-level="6.5.2" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#model-averaging."><i class="fa fa-check"></i><b>6.5.2</b> Model averaging.</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#summary-bonus-r2-talk"><i class="fa fa-check"></i><b>6.6</b> <del>Summary</del> Bonus: <span class="math inline">\(R^2\)</span> talk</a></li>
<li class="chapter" data-level="" data-path="overfitting-regularization-and-information-criteria.html"><a href="overfitting-regularization-and-information-criteria.html#session-info-5"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>7</b> Interactions</a><ul>
<li class="chapter" data-level="7.1" data-path="interactions.html"><a href="interactions.html#building-an-interaction."><i class="fa fa-check"></i><b>7.1</b> Building an interaction.</a><ul>
<li class="chapter" data-level="7.1.1" data-path="interactions.html"><a href="interactions.html#adding-a-dummy-variable-doesnt-work."><i class="fa fa-check"></i><b>7.1.1</b> Adding a dummy variable doesn’t work.</a></li>
<li class="chapter" data-level="7.1.2" data-path="interactions.html"><a href="interactions.html#adding-a-linear-interaction-does-work."><i class="fa fa-check"></i><b>7.1.2</b> Adding a linear interaction does work.</a></li>
<li class="chapter" data-level="7.1.3" data-path="interactions.html"><a href="interactions.html#plotting-the-interaction."><i class="fa fa-check"></i><b>7.1.3</b> Plotting the interaction.</a></li>
<li class="chapter" data-level="7.1.4" data-path="interactions.html"><a href="interactions.html#interpreting-an-interaction-estimate."><i class="fa fa-check"></i><b>7.1.4</b> Interpreting an interaction estimate.</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="interactions.html"><a href="interactions.html#symmetry-of-the-linear-interaction."><i class="fa fa-check"></i><b>7.2</b> Symmetry of the linear interaction.</a><ul>
<li class="chapter" data-level="7.2.1" data-path="interactions.html"><a href="interactions.html#buridans-interaction."><i class="fa fa-check"></i><b>7.2.1</b> Buridan’s interaction.</a></li>
<li class="chapter" data-level="7.2.2" data-path="interactions.html"><a href="interactions.html#africa-depends-upon-ruggedness."><i class="fa fa-check"></i><b>7.2.2</b> Africa depends upon ruggedness.</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="interactions.html"><a href="interactions.html#continuous-interactions"><i class="fa fa-check"></i><b>7.3</b> Continuous interactions</a><ul>
<li class="chapter" data-level="7.3.1" data-path="interactions.html"><a href="interactions.html#the-data.-1"><i class="fa fa-check"></i><b>7.3.1</b> The data.</a></li>
<li class="chapter" data-level="7.3.2" data-path="interactions.html"><a href="interactions.html#the-un-centered-models."><i class="fa fa-check"></i><b>7.3.2</b> The un-centered models.</a></li>
<li class="chapter" data-level="7.3.3" data-path="interactions.html"><a href="interactions.html#center-and-re-estimate."><i class="fa fa-check"></i><b>7.3.3</b> Center and re-estimate.</a></li>
<li class="chapter" data-level="7.3.4" data-path="interactions.html"><a href="interactions.html#plotting-implied-predictions."><i class="fa fa-check"></i><b>7.3.4</b> Plotting implied predictions.</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="interactions.html"><a href="interactions.html#interactions-in-design-formulas"><i class="fa fa-check"></i><b>7.4</b> Interactions in design formulas</a></li>
<li class="chapter" data-level="7.5" data-path="interactions.html"><a href="interactions.html#summary-bonus-marginal_effectsconditional_effects"><i class="fa fa-check"></i><b>7.5</b> <del>Summary</del> Bonus: <code>marginal_effects()</code>/<code>conditional_effects()</code></a></li>
<li class="chapter" data-level="" data-path="interactions.html"><a href="interactions.html#session-info-6"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html"><i class="fa fa-check"></i><b>8</b> Markov Chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#good-king-markov-and-his-island-kingdom"><i class="fa fa-check"></i><b>8.1</b> Good King Markov and His island kingdom</a></li>
<li class="chapter" data-level="8.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#markov-chain-monte-carlo-1"><i class="fa fa-check"></i><b>8.2</b> Markov chain Monte Carlo</a><ul>
<li class="chapter" data-level="8.2.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#gibbs-sampling."><i class="fa fa-check"></i><b>8.2.1</b> Gibbs sampling.</a></li>
<li class="chapter" data-level="8.2.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#hamiltonian-monte-carlo."><i class="fa fa-check"></i><b>8.2.2</b> Hamiltonian Monte Carlo.</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#easy-hmc-map2stan-brm"><i class="fa fa-check"></i><b>8.3</b> Easy HMC: <del>map2stan</del> <code>brm()</code></a><ul>
<li class="chapter" data-level="8.3.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#preparation."><i class="fa fa-check"></i><b>8.3.1</b> Preparation.</a></li>
<li class="chapter" data-level="8.3.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#estimation."><i class="fa fa-check"></i><b>8.3.2</b> Estimation.</a></li>
<li class="chapter" data-level="8.3.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#sampling-again-in-parallel."><i class="fa fa-check"></i><b>8.3.3</b> Sampling again, in parallel.</a></li>
<li class="chapter" data-level="8.3.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#visualization."><i class="fa fa-check"></i><b>8.3.4</b> Visualization.</a></li>
<li class="chapter" data-level="8.3.5" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#using-the-samples."><i class="fa fa-check"></i><b>8.3.5</b> Using the samples.</a></li>
<li class="chapter" data-level="8.3.6" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#checking-the-chain."><i class="fa fa-check"></i><b>8.3.6</b> Checking the chain.</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#care-and-feeding-of-your-markov-chain."><i class="fa fa-check"></i><b>8.4</b> Care and feeding of your Markov chain.</a><ul>
<li class="chapter" data-level="8.4.1" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-samples-do-you-need"><i class="fa fa-check"></i><b>8.4.1</b> How many samples do you need?</a></li>
<li class="chapter" data-level="8.4.2" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#how-many-chains-do-you-need"><i class="fa fa-check"></i><b>8.4.2</b> How many chains do you need?</a></li>
<li class="chapter" data-level="8.4.3" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#taming-a-wild-chain."><i class="fa fa-check"></i><b>8.4.3</b> Taming a wild chain.</a></li>
<li class="chapter" data-level="8.4.4" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#non-identifiable-parameters."><i class="fa fa-check"></i><b>8.4.4</b> Non-identifiable parameters.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="markov-chain-monte-carlo.html"><a href="markov-chain-monte-carlo.html#session-info-7"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html"><i class="fa fa-check"></i><b>9</b> Big Entropy and the Generalized Linear Model</a><ul>
<li class="chapter" data-level="9.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#maximum-entropy"><i class="fa fa-check"></i><b>9.1</b> Maximum entropy</a><ul>
<li class="chapter" data-level="9.1.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#gaussian."><i class="fa fa-check"></i><b>9.1.1</b> Gaussian.</a></li>
<li class="chapter" data-level="9.1.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#binomial."><i class="fa fa-check"></i><b>9.1.2</b> Binomial.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#generalized-linear-models"><i class="fa fa-check"></i><b>9.2</b> Generalized linear models</a><ul>
<li class="chapter" data-level="9.2.1" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#meet-the-family."><i class="fa fa-check"></i><b>9.2.1</b> Meet the family.</a></li>
<li class="chapter" data-level="9.2.2" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions."><i class="fa fa-check"></i><b>9.2.2</b> Linking linear models to distributions.</a></li>
<li class="chapter" data-level="9.2.3" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#absolute-and-relative-differences."><i class="fa fa-check"></i><b>9.2.3</b> Absolute and relative differences.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="big-entropy-and-the-generalized-linear-model.html"><a href="big-entropy-and-the-generalized-linear-model.html#session-info-8"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="counting-and-classification.html"><a href="counting-and-classification.html"><i class="fa fa-check"></i><b>10</b> Counting and Classification</a><ul>
<li class="chapter" data-level="10.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#binomial-regression"><i class="fa fa-check"></i><b>10.1</b> Binomial regression</a><ul>
<li class="chapter" data-level="10.1.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#logistic-regression-prosocial-chimpanzees."><i class="fa fa-check"></i><b>10.1.1</b> Logistic regression: Prosocial chimpanzees.</a></li>
<li class="chapter" data-level="10.1.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-chimpanzees-again-condensed."><i class="fa fa-check"></i><b>10.1.2</b> Aggregated binomial: Chimpanzees again, condensed.</a></li>
<li class="chapter" data-level="10.1.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#aggregated-binomial-graduate-school-admissions."><i class="fa fa-check"></i><b>10.1.3</b> Aggregated binomial: Graduate school admissions.</a></li>
<li class="chapter" data-level="10.1.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#fitting-binomial-regressions-with-glm."><i class="fa fa-check"></i><b>10.1.4</b> Fitting binomial regressions with <code>glm()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#poisson-regression"><i class="fa fa-check"></i><b>10.2</b> Poisson regression</a><ul>
<li class="chapter" data-level="10.2.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-oceanic-tool-complexity."><i class="fa fa-check"></i><b>10.2.1</b> Example: Oceanic tool complexity.</a></li>
<li class="chapter" data-level="10.2.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#mcmc-islands."><i class="fa fa-check"></i><b>10.2.2</b> MCMC islands.</a></li>
<li class="chapter" data-level="10.2.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#example-exposure-and-the-offset."><i class="fa fa-check"></i><b>10.2.3</b> Example: Exposure and the offset.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="counting-and-classification.html"><a href="counting-and-classification.html#other-count-regressions"><i class="fa fa-check"></i><b>10.3</b> Other count regressions</a><ul>
<li class="chapter" data-level="10.3.1" data-path="counting-and-classification.html"><a href="counting-and-classification.html#multinomial."><i class="fa fa-check"></i><b>10.3.1</b> Multinomial.</a></li>
<li class="chapter" data-level="10.3.2" data-path="counting-and-classification.html"><a href="counting-and-classification.html#geometric."><i class="fa fa-check"></i><b>10.3.2</b> Geometric.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="counting-and-classification.html"><a href="counting-and-classification.html#summary"><i class="fa fa-check"></i><b>10.4</b> Summary</a></li>
<li class="chapter" data-level="" data-path="counting-and-classification.html"><a href="counting-and-classification.html#session-info-9"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html"><i class="fa fa-check"></i><b>11</b> Monsters and Mixtures</a><ul>
<li class="chapter" data-level="11.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#ordered-categorical-outcomes"><i class="fa fa-check"></i><b>11.1</b> Ordered categorical outcomes</a><ul>
<li class="chapter" data-level="11.1.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-moral-intuition."><i class="fa fa-check"></i><b>11.1.1</b> Example: Moral intuition.</a></li>
<li class="chapter" data-level="11.1.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#describing-an-ordered-distribution-with-intercepts."><i class="fa fa-check"></i><b>11.1.2</b> Describing an ordered distribution with intercepts.</a></li>
<li class="chapter" data-level="11.1.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#adding-predictor-variables."><i class="fa fa-check"></i><b>11.1.3</b> Adding predictor variables.</a></li>
<li class="chapter" data-level="11.1.4" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#bonus-figure-11.3-alternative."><i class="fa fa-check"></i><b>11.1.4</b> Bonus: Figure 11.3 alternative.</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#zero-inflated-outcomes"><i class="fa fa-check"></i><b>11.2</b> Zero-inflated outcomes</a><ul>
<li class="chapter" data-level="11.2.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#example-zero-inflated-poisson."><i class="fa fa-check"></i><b>11.2.1</b> Example: Zero-inflated Poisson.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersed-outcomes"><i class="fa fa-check"></i><b>11.3</b> Over-dispersed outcomes</a><ul>
<li class="chapter" data-level="11.3.1" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#beta-binomial."><i class="fa fa-check"></i><b>11.3.1</b> Beta-binomial.</a></li>
<li class="chapter" data-level="11.3.2" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#negative-binomial-or-gamma-poisson."><i class="fa fa-check"></i><b>11.3.2</b> Negative-binomial or gamma-Poisson.</a></li>
<li class="chapter" data-level="11.3.3" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#over-dispersion-entropy-and-information-criteria."><i class="fa fa-check"></i><b>11.3.3</b> Over-dispersion, entropy, and information criteria.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="monsters-and-mixtures.html"><a href="monsters-and-mixtures.html#session-info-10"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multilevel-models.html"><a href="multilevel-models.html"><i class="fa fa-check"></i><b>12</b> Multilevel Models</a><ul>
<li class="chapter" data-level="12.1" data-path="multilevel-models.html"><a href="multilevel-models.html#example-multilevel-tadpoles"><i class="fa fa-check"></i><b>12.1</b> Example: Multilevel tadpoles</a></li>
<li class="chapter" data-level="12.2" data-path="multilevel-models.html"><a href="multilevel-models.html#varying-effects-and-the-underfittingoverfitting-trade-off"><i class="fa fa-check"></i><b>12.2</b> Varying effects and the underfitting/overfitting trade-off</a><ul>
<li class="chapter" data-level="12.2.1" data-path="multilevel-models.html"><a href="multilevel-models.html#the-model.-1"><i class="fa fa-check"></i><b>12.2.1</b> The model.</a></li>
<li class="chapter" data-level="12.2.2" data-path="multilevel-models.html"><a href="multilevel-models.html#assign-values-to-the-parameters."><i class="fa fa-check"></i><b>12.2.2</b> Assign values to the parameters.</a></li>
<li class="chapter" data-level="12.2.3" data-path="multilevel-models.html"><a href="multilevel-models.html#sumulate-survivors."><i class="fa fa-check"></i><b>12.2.3</b> Sumulate survivors.</a></li>
<li class="chapter" data-level="12.2.4" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-no-pooling-estimates."><i class="fa fa-check"></i><b>12.2.4</b> Compute the no-pooling estimates.</a></li>
<li class="chapter" data-level="12.2.5" data-path="multilevel-models.html"><a href="multilevel-models.html#compute-the-partial-pooling-estimates."><i class="fa fa-check"></i><b>12.2.5</b> Compute the partial-pooling estimates.</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multilevel-models.html"><a href="multilevel-models.html#more-than-one-type-of-cluster"><i class="fa fa-check"></i><b>12.3</b> More than one type of cluster</a><ul>
<li class="chapter" data-level="12.3.1" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-chimpanzees."><i class="fa fa-check"></i><b>12.3.1</b> Multilevel chimpanzees.</a></li>
<li class="chapter" data-level="12.3.2" data-path="multilevel-models.html"><a href="multilevel-models.html#two-types-of-cluster."><i class="fa fa-check"></i><b>12.3.2</b> Two types of cluster.</a></li>
<li class="chapter" data-level="12.3.3" data-path="multilevel-models.html"><a href="multilevel-models.html#even-more-clusters."><i class="fa fa-check"></i><b>12.3.3</b> Even more clusters.</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multilevel-models.html"><a href="multilevel-models.html#multilevel-posterior-predictions"><i class="fa fa-check"></i><b>12.4</b> Multilevel posterior predictions</a><ul>
<li class="chapter" data-level="12.4.1" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-same-clusters."><i class="fa fa-check"></i><b>12.4.1</b> Posterior prediction for same clusters.</a></li>
<li class="chapter" data-level="12.4.2" data-path="multilevel-models.html"><a href="multilevel-models.html#posterior-prediction-for-new-clusters."><i class="fa fa-check"></i><b>12.4.2</b> Posterior prediction for new clusters.</a></li>
<li class="chapter" data-level="12.4.3" data-path="multilevel-models.html"><a href="multilevel-models.html#focus-and-multilevel-prediction."><i class="fa fa-check"></i><b>12.4.3</b> Focus and multilevel prediction.</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="multilevel-models.html"><a href="multilevel-models.html#summary-bonus-put-your-random-effects-to-work"><i class="fa fa-check"></i><b>12.5</b> <del>Summary</del> Bonus: Put your random effects to work</a><ul>
<li class="chapter" data-level="12.5.1" data-path="multilevel-models.html"><a href="multilevel-models.html#intercepts-only-models-with-one-or-two-grouping-variables."><i class="fa fa-check"></i><b>12.5.1</b> Intercepts-only models with one or two grouping variables.</a></li>
<li class="chapter" data-level="12.5.2" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsposterior_samples."><i class="fa fa-check"></i><b>12.5.2</b> <code>brms::posterior_samples()</code>.</a></li>
<li class="chapter" data-level="12.5.3" data-path="multilevel-models.html"><a href="multilevel-models.html#brmscoef."><i class="fa fa-check"></i><b>12.5.3</b> <code>brms::coef()</code>.</a></li>
<li class="chapter" data-level="12.5.4" data-path="multilevel-models.html"><a href="multilevel-models.html#brmsfitted."><i class="fa fa-check"></i><b>12.5.4</b> <code>brms::fitted()</code>.</a></li>
<li class="chapter" data-level="12.5.5" data-path="multilevel-models.html"><a href="multilevel-models.html#tidybayesspread_draws."><i class="fa fa-check"></i><b>12.5.5</b> <code>tidybayes::spread_draws()</code>.</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multilevel-models.html"><a href="multilevel-models.html#session-info-11"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html"><i class="fa fa-check"></i><b>13</b> Adventures in Covariance</a><ul>
<li class="chapter" data-level="13.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-slopes-by-construction"><i class="fa fa-check"></i><b>13.1</b> Varying slopes by construction</a><ul>
<li class="chapter" data-level="13.1.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-the-population."><i class="fa fa-check"></i><b>13.1.1</b> Simulate the population.</a></li>
<li class="chapter" data-level="13.1.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#simulate-observations."><i class="fa fa-check"></i><b>13.1.2</b> Simulate observations.</a></li>
<li class="chapter" data-level="13.1.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#the-varying-slopes-model."><i class="fa fa-check"></i><b>13.1.3</b> The varying slopes model.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-admission-decisions-and-gender"><i class="fa fa-check"></i><b>13.2</b> Example: Admission decisions and gender</a><ul>
<li class="chapter" data-level="13.2.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-intercepts."><i class="fa fa-check"></i><b>13.2.1</b> Varying intercepts.</a></li>
<li class="chapter" data-level="13.2.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#varying-effects-of-being-male."><i class="fa fa-check"></i><b>13.2.2</b> Varying effects of being <code>male</code>.</a></li>
<li class="chapter" data-level="13.2.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#shrinkage."><i class="fa fa-check"></i><b>13.2.3</b> Shrinkage.</a></li>
<li class="chapter" data-level="13.2.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#model-comparison.-1"><i class="fa fa-check"></i><b>13.2.4</b> Model comparison.</a></li>
<li class="chapter" data-level="13.2.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#more-slopes."><i class="fa fa-check"></i><b>13.2.5</b> More slopes.</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-cross-classified-chimpanzees-with-varying-slopes"><i class="fa fa-check"></i><b>13.3</b> Example: Cross-classified <code>chimpanzees</code> with varying slopes</a></li>
<li class="chapter" data-level="13.4" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#continuous-categories-and-the-gaussian-process"><i class="fa fa-check"></i><b>13.4</b> Continuous categories and the Gaussian process</a><ul>
<li class="chapter" data-level="13.4.1" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#example-spatial-autocorrelation-in-oceanic-tools."><i class="fa fa-check"></i><b>13.4.1</b> Example: Spatial autocorrelation in Oceanic tools.</a></li>
<li class="chapter" data-level="13.4.2" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#other-kinds-of-distance."><i class="fa fa-check"></i><b>13.4.2</b> Other kinds of “distance”.</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#summary-bonus-another-berkley-admissions-data-like-example."><i class="fa fa-check"></i><b>13.5</b> <del>Summary</del> Bonus: Another Berkley-admissions-data-like example.</a></li>
<li class="chapter" data-level="" data-path="adventures-in-covariance.html"><a href="adventures-in-covariance.html#session-info-12"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html"><i class="fa fa-check"></i><b>14</b> Missing Data and Other Opportunities</a><ul>
<li class="chapter" data-level="14.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#measurement-error"><i class="fa fa-check"></i><b>14.1</b> Measurement error</a><ul>
<li class="chapter" data-level="14.1.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-the-outcome."><i class="fa fa-check"></i><b>14.1.1</b> Error on the outcome.</a></li>
<li class="chapter" data-level="14.1.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#error-on-both-outcome-and-predictor."><i class="fa fa-check"></i><b>14.1.2</b> Error on both outcome and predictor.</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#missing-data"><i class="fa fa-check"></i><b>14.2</b> Missing data</a><ul>
<li class="chapter" data-level="14.2.1" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#imputing-neocortex"><i class="fa fa-check"></i><b>14.2.1</b> Imputing <code>neocortex</code></a></li>
<li class="chapter" data-level="14.2.2" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#improving-the-imputation-model"><i class="fa fa-check"></i><b>14.2.2</b> Improving the imputation model</a></li>
<li class="chapter" data-level="14.2.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#bonus-mi-can-replace-me"><i class="fa fa-check"></i><b>14.2.3</b> Bonus: <code>mi()</code> can replace <code>me()</code></a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#summary-bonus-meta-analysis"><i class="fa fa-check"></i><b>14.3</b> <del>Summary</del> Bonus: Meta-analysis</a></li>
<li class="chapter" data-level="" data-path="missing-data-and-other-opportunities.html"><a href="missing-data-and-other-opportunities.html#session-info-13"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html"><i class="fa fa-check"></i><b>15</b> <del>Horoscopes</del> Insights</a><ul>
<li class="chapter" data-level="15.1" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-r-notebooks"><i class="fa fa-check"></i><b>15.1</b> Use R Notebooks</a></li>
<li class="chapter" data-level="15.2" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#save-your-model-fits"><i class="fa fa-check"></i><b>15.2</b> Save your model fits</a></li>
<li class="chapter" data-level="15.3" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#build-your-models-slowly"><i class="fa fa-check"></i><b>15.3</b> Build your models slowly</a></li>
<li class="chapter" data-level="15.4" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#look-at-your-data"><i class="fa fa-check"></i><b>15.4</b> Look at your data</a></li>
<li class="chapter" data-level="15.5" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#use-the-0-intercept-syntax"><i class="fa fa-check"></i><b>15.5</b> Use the <code>0 + Intercept</code> syntax</a></li>
<li class="chapter" data-level="15.6" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-workflow"><i class="fa fa-check"></i><b>15.6</b> Annotate your workflow</a></li>
<li class="chapter" data-level="15.7" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#annotate-your-code"><i class="fa fa-check"></i><b>15.7</b> Annotate your code</a></li>
<li class="chapter" data-level="15.8" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#break-up-your-workflow"><i class="fa fa-check"></i><b>15.8</b> Break up your workflow</a></li>
<li class="chapter" data-level="15.9" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#code-in-public"><i class="fa fa-check"></i><b>15.9</b> Code in public</a></li>
<li class="chapter" data-level="15.10" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#read-gelmans-blog"><i class="fa fa-check"></i><b>15.10</b> Read Gelman’s blog</a></li>
<li class="chapter" data-level="15.11" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#check-out-other-social-media-too"><i class="fa fa-check"></i><b>15.11</b> Check out other social media, too</a></li>
<li class="chapter" data-level="15.12" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#parting-wisdom"><i class="fa fa-check"></i><b>15.12</b> Parting wisdom</a></li>
<li class="chapter" data-level="" data-path="horoscopes-insights.html"><a href="horoscopes-insights.html#session-info-14"><i class="fa fa-check"></i>Session info</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><em>Statistical rethinking</em> with brms, ggplot2, and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-models" class="section level1">
<h1><span class="header-section-number">4</span> Linear Models</h1>
<blockquote>
<p>Linear regression is the geocentric model of applied statistics. By “linear regression”, we will mean a family of simple statistical golems that attempt to learn about the mean and variance of some measurement, using an additive combination of other measurements. Like geocentrism, linear regression can usefully describe a very large variety of natural phenomena. Like geocentrism, linear is a descriptive model that corresponds to many different process models. If we read its structure too literally, we’re likely to make mistakes. But used wisely, these little linear golems continue to be useful. <span class="citation">(McElreath, <a href="#ref-mcelreathStatisticalRethinkingBayesian2015" role="doc-biblioref">2015</a>, p. 71)</span></p>
</blockquote>
<div id="why-normal-distributions-are-normal" class="section level2">
<h2><span class="header-section-number">4.1</span> Why normal distributions are normal</h2>
<p>After laying out his soccer field coin toss shuffle premise, McElreath wrote:</p>
<blockquote>
<p>It’s hard to say where any individual person will end up, but you can say with great confidence what the collection of positions will be. The distances will be distributed in approximately normal, or Gaussian, fashion. This is true even though the underlying distribution is binomial. It does this because there are so many more possible ways to realize a sequence of left-right steps that sums to zero. There are slightly fewer ways to realize a sequence that ends up one step left or right of zero, and so on, with the number of possible sequences declining in the characteristic bell curve of the normal distribution. (p. 72)</p>
</blockquote>
<div id="normal-by-addition." class="section level3">
<h3><span class="header-section-number">4.1.1</span> Normal by addition.</h3>
<p>Here’s a way to do the simulation necessary for the plot in the top panel of Figure 4.2.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="linear-models.html#cb211-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb211-2"><a href="linear-models.html#cb211-2"></a></span>
<span id="cb211-3"><a href="linear-models.html#cb211-3"></a><span class="co"># we set the seed to make the results of `runif()` reproducible.</span></span>
<span id="cb211-4"><a href="linear-models.html#cb211-4"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb211-5"><a href="linear-models.html#cb211-5"></a></span>
<span id="cb211-6"><a href="linear-models.html#cb211-6"></a>pos &lt;-<span class="st"> </span></span>
<span id="cb211-7"><a href="linear-models.html#cb211-7"></a><span class="st">  </span><span class="co"># make data with 100 people, 16 steps each with a starting point of `step == 0` (i.e., 17 rows per person)</span></span>
<span id="cb211-8"><a href="linear-models.html#cb211-8"></a><span class="st">  </span><span class="kw">crossing</span>(<span class="dt">person =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>,</span>
<span id="cb211-9"><a href="linear-models.html#cb211-9"></a>           <span class="dt">step   =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">16</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb211-10"><a href="linear-models.html#cb211-10"></a><span class="st">  </span><span class="co"># for all steps above `step == 0` simulate a `deviation`</span></span>
<span id="cb211-11"><a href="linear-models.html#cb211-11"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">deviation =</span> <span class="kw">map_dbl</span>(step, <span class="op">~</span><span class="kw">if_else</span>(. <span class="op">==</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">0</span>, <span class="kw">runif</span>(<span class="dv">1</span>, <span class="dv">-1</span>, <span class="dv">1</span>)))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb211-12"><a href="linear-models.html#cb211-12"></a><span class="st">  </span><span class="co"># after grouping by `person`, compute the cumulative sum of the deviations, then `ungroup()`</span></span>
<span id="cb211-13"><a href="linear-models.html#cb211-13"></a><span class="st">  </span><span class="kw">group_by</span>(person) <span class="op">%&gt;%</span></span>
<span id="cb211-14"><a href="linear-models.html#cb211-14"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">position =</span> <span class="kw">cumsum</span>(deviation)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb211-15"><a href="linear-models.html#cb211-15"></a><span class="st">  </span><span class="kw">ungroup</span>() </span></code></pre></div>
<p>That <code>map_dbl()</code> code within the first <code>mutate()</code> line might look odd. Go <a href="https://purrr.tidyverse.org/reference/map.html">here</a> to learn more about iterating with <code>purrr::map_dbl()</code>.</p>
<p>We might <code>glimpse()</code> at the data.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="linear-models.html#cb212-1"></a><span class="kw">glimpse</span>(pos)</span></code></pre></div>
<pre><code>## Rows: 1,700
## Columns: 4
## $ person    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…
## $ step      &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 0, 1, 2, 3, 4, 5, 6, …
## $ deviation &lt;dbl&gt; 0.00000000, -0.98210841, -0.41252078, -0.44525008, 0.62714843, -0.47914446, 0.4…
## $ position  &lt;dbl&gt; 0.0000000, -0.9821084, -1.3946292, -1.8398793, -1.2127308, -1.6918753, -1.24306…</code></pre>
<p>Here’s the actual plot code.</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="linear-models.html#cb214-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> pos, </span>
<span id="cb214-2"><a href="linear-models.html#cb214-2"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> step, <span class="dt">y =</span> position, <span class="dt">group =</span> person)) <span class="op">+</span></span>
<span id="cb214-3"><a href="linear-models.html#cb214-3"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">16</span>), <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb214-4"><a href="linear-models.html#cb214-4"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">color =</span> person <span class="op">&lt;</span><span class="st"> </span><span class="dv">2</span>, <span class="dt">alpha  =</span> person <span class="op">&lt;</span><span class="st"> </span><span class="dv">2</span>)) <span class="op">+</span></span>
<span id="cb214-5"><a href="linear-models.html#cb214-5"></a><span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;skyblue4&quot;</span>, <span class="st">&quot;black&quot;</span>)) <span class="op">+</span></span>
<span id="cb214-6"><a href="linear-models.html#cb214-6"></a><span class="st">  </span><span class="kw">scale_alpha_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">5</span>, <span class="dv">1</span>)) <span class="op">+</span></span>
<span id="cb214-7"><a href="linear-models.html#cb214-7"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;step number&quot;</span>, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">8</span>, <span class="dv">12</span>, <span class="dv">16</span>)) <span class="op">+</span></span>
<span id="cb214-8"><a href="linear-models.html#cb214-8"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-4-1.png" width="614.4" /></p>
<p>Now here’s the code for the bottom three plots of Figure 4.2.</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="linear-models.html#cb215-1"></a><span class="co"># Figure 4.2.a.</span></span>
<span id="cb215-2"><a href="linear-models.html#cb215-2"></a>p1 &lt;-</span>
<span id="cb215-3"><a href="linear-models.html#cb215-3"></a><span class="st">  </span>pos <span class="op">%&gt;%</span></span>
<span id="cb215-4"><a href="linear-models.html#cb215-4"></a><span class="st">  </span><span class="kw">filter</span>(step <span class="op">==</span><span class="st"> </span><span class="dv">4</span>) <span class="op">%&gt;%</span></span>
<span id="cb215-5"><a href="linear-models.html#cb215-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> position)) <span class="op">+</span></span>
<span id="cb215-6"><a href="linear-models.html#cb215-6"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">stat =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;dodgerblue1&quot;</span>) <span class="op">+</span></span>
<span id="cb215-7"><a href="linear-models.html#cb215-7"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>)) <span class="op">+</span></span>
<span id="cb215-8"><a href="linear-models.html#cb215-8"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;4 steps&quot;</span>)</span>
<span id="cb215-9"><a href="linear-models.html#cb215-9"></a></span>
<span id="cb215-10"><a href="linear-models.html#cb215-10"></a><span class="co"># Figure 4.2.b.</span></span>
<span id="cb215-11"><a href="linear-models.html#cb215-11"></a>p2 &lt;-</span>
<span id="cb215-12"><a href="linear-models.html#cb215-12"></a><span class="st">  </span>pos <span class="op">%&gt;%</span></span>
<span id="cb215-13"><a href="linear-models.html#cb215-13"></a><span class="st">  </span><span class="kw">filter</span>(step <span class="op">==</span><span class="st"> </span><span class="dv">8</span>) <span class="op">%&gt;%</span></span>
<span id="cb215-14"><a href="linear-models.html#cb215-14"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> position)) <span class="op">+</span></span>
<span id="cb215-15"><a href="linear-models.html#cb215-15"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">color =</span> <span class="st">&quot;dodgerblue2&quot;</span>) <span class="op">+</span></span>
<span id="cb215-16"><a href="linear-models.html#cb215-16"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>)) <span class="op">+</span></span>
<span id="cb215-17"><a href="linear-models.html#cb215-17"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;8 steps&quot;</span>)</span>
<span id="cb215-18"><a href="linear-models.html#cb215-18"></a></span>
<span id="cb215-19"><a href="linear-models.html#cb215-19"></a><span class="co"># this is an intermediary step to get an SD value</span></span>
<span id="cb215-20"><a href="linear-models.html#cb215-20"></a>pos <span class="op">%&gt;%</span></span>
<span id="cb215-21"><a href="linear-models.html#cb215-21"></a><span class="st">  </span><span class="kw">filter</span>(step <span class="op">==</span><span class="st"> </span><span class="dv">16</span>) <span class="op">%&gt;%</span></span>
<span id="cb215-22"><a href="linear-models.html#cb215-22"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">sd =</span> <span class="kw">sd</span>(position))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##      sd
##   &lt;dbl&gt;
## 1  2.36</code></pre>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="linear-models.html#cb217-1"></a><span class="co"># Figure 4.2.c.</span></span>
<span id="cb217-2"><a href="linear-models.html#cb217-2"></a>p3 &lt;-</span>
<span id="cb217-3"><a href="linear-models.html#cb217-3"></a><span class="st">  </span>pos <span class="op">%&gt;%</span></span>
<span id="cb217-4"><a href="linear-models.html#cb217-4"></a><span class="st">  </span><span class="kw">filter</span>(step <span class="op">==</span><span class="st"> </span><span class="dv">16</span>) <span class="op">%&gt;%</span></span>
<span id="cb217-5"><a href="linear-models.html#cb217-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> position)) <span class="op">+</span></span>
<span id="cb217-6"><a href="linear-models.html#cb217-6"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, </span>
<span id="cb217-7"><a href="linear-models.html#cb217-7"></a>                <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="fl">2.180408</span>),</span>
<span id="cb217-8"><a href="linear-models.html#cb217-8"></a>                <span class="dt">linetype =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st">  </span><span class="co"># 2.180408 came from the previous code block</span></span>
<span id="cb217-9"><a href="linear-models.html#cb217-9"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>, <span class="dt">fill =</span> <span class="st">&quot;dodgerblue3&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb217-10"><a href="linear-models.html#cb217-10"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">6</span>, <span class="dv">6</span>)) <span class="op">+</span></span>
<span id="cb217-11"><a href="linear-models.html#cb217-11"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;16 steps&quot;</span>,</span>
<span id="cb217-12"><a href="linear-models.html#cb217-12"></a>       <span class="dt">y =</span> <span class="st">&quot;density&quot;</span>)</span>
<span id="cb217-13"><a href="linear-models.html#cb217-13"></a></span>
<span id="cb217-14"><a href="linear-models.html#cb217-14"></a><span class="kw">library</span>(patchwork)</span>
<span id="cb217-15"><a href="linear-models.html#cb217-15"></a></span>
<span id="cb217-16"><a href="linear-models.html#cb217-16"></a><span class="co"># combine the ggplots</span></span>
<span id="cb217-17"><a href="linear-models.html#cb217-17"></a>p1 <span class="op">|</span><span class="st"> </span>p2 <span class="op">|</span><span class="st"> </span>p3</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-5-1.png" width="768" /></p>
<p>While we were at it, we explored a few ways to express densities. The main action was with the <code>geom_line()</code>, <code>geom_density()</code>, and <code>stat_function()</code> functions, respectively.</p>
<blockquote>
<p>Any process that ads together random values from the same distribution converges to a normal. But it’s not easy to grasp why addition should result in a bell curve of sums. Here’s a conceptual way to think of the process. Whatever the average value of the source distribution, each sample from it can be thought of as a fluctuation from the average value. When we begin to add these fluctuations together, they also begin to cancel one another out. A large positive fluctuation will cancel a large negative one. The more terms in the sum, the more chances for each fluctuation to be canceled by another, or by a series of smaller ones in the opposite direction. So eventually the most likely sum, in the sense that there are the most ways to realize it, will be a sum in which every fluctuation is canceled by another, a sum of zero (relative to the mean). (pp. 73–74)</p>
</blockquote>
</div>
<div id="normal-by-multiplication." class="section level3">
<h3><span class="header-section-number">4.1.2</span> Normal by multiplication.</h3>
<p>Here’s McElreath’s simple random growth rate.</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="linear-models.html#cb218-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb218-2"><a href="linear-models.html#cb218-2"></a><span class="kw">prod</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.1</span>))</span></code></pre></div>
<pre><code>## [1] 1.774719</code></pre>
<p>In the <code>runif()</code> part of that code, we generated 12 random draws from the uniform distribution with bounds <span class="math inline">\([0, 0.1]\)</span>. Within the <code>prod()</code> function, we first added <code>1</code> to each of those values and then computed their product. Consider a more explicit variant of the code.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="linear-models.html#cb220-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb220-2"><a href="linear-models.html#cb220-2"></a><span class="kw">tibble</span>(<span class="dt">a =</span> <span class="dv">1</span>,</span>
<span id="cb220-3"><a href="linear-models.html#cb220-3"></a>       <span class="dt">b =</span> <span class="kw">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.1</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb220-4"><a href="linear-models.html#cb220-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c =</span> a <span class="op">+</span><span class="st"> </span>b) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb220-5"><a href="linear-models.html#cb220-5"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">p =</span> <span class="kw">prod</span>(c))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##       p
##   &lt;dbl&gt;
## 1  1.77</code></pre>
<p>Same result. Rather than using base R <code>replicate()</code> to do this many times, let’s practice with <code>purrr::map_dbl()</code> like before.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="linear-models.html#cb222-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb222-2"><a href="linear-models.html#cb222-2"></a>growth &lt;-<span class="st"> </span></span>
<span id="cb222-3"><a href="linear-models.html#cb222-3"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">growth =</span> <span class="kw">map_dbl</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>, <span class="op">~</span><span class="st"> </span><span class="kw">prod</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.1</span>))))</span>
<span id="cb222-4"><a href="linear-models.html#cb222-4"></a></span>
<span id="cb222-5"><a href="linear-models.html#cb222-5"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> growth, <span class="kw">aes</span>(<span class="dt">x =</span> growth)) <span class="op">+</span></span>
<span id="cb222-6"><a href="linear-models.html#cb222-6"></a><span class="st">  </span><span class="kw">geom_density</span>()</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-8-1.png" width="312" /></p>
<p>“The smaller the effect of each locus, the better this additive approximation will be” (p. 74). Let’s compare big and small.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="linear-models.html#cb223-1"></a><span class="co"># simulate</span></span>
<span id="cb223-2"><a href="linear-models.html#cb223-2"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb223-3"><a href="linear-models.html#cb223-3"></a></span>
<span id="cb223-4"><a href="linear-models.html#cb223-4"></a>samples &lt;-</span>
<span id="cb223-5"><a href="linear-models.html#cb223-5"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">big   =</span> <span class="kw">map_dbl</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>, <span class="op">~</span><span class="st"> </span><span class="kw">prod</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.5</span>))),</span>
<span id="cb223-6"><a href="linear-models.html#cb223-6"></a>         <span class="dt">small =</span> <span class="kw">map_dbl</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10000</span>, <span class="op">~</span><span class="st"> </span><span class="kw">prod</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.01</span>)))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb223-7"><a href="linear-models.html#cb223-7"></a><span class="st">  </span><span class="co"># wrangle</span></span>
<span id="cb223-8"><a href="linear-models.html#cb223-8"></a><span class="st">  </span><span class="kw">gather</span>(distribution, samples) </span>
<span id="cb223-9"><a href="linear-models.html#cb223-9"></a></span>
<span id="cb223-10"><a href="linear-models.html#cb223-10"></a><span class="co"># plot</span></span>
<span id="cb223-11"><a href="linear-models.html#cb223-11"></a>samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb223-12"><a href="linear-models.html#cb223-12"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> samples)) <span class="op">+</span></span>
<span id="cb223-13"><a href="linear-models.html#cb223-13"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>) <span class="op">+</span></span>
<span id="cb223-14"><a href="linear-models.html#cb223-14"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>distribution, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>) </span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-9-1.png" width="576" /></p>
<p>Yep, the <code>small</code> samples were more Gaussian.</p>
</div>
<div id="normal-by-log-multiplication." class="section level3">
<h3><span class="header-section-number">4.1.3</span> Normal by log-multiplication.</h3>
<p>Instead of saving our tibble, we’ll just feed it directly into our plot.</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="linear-models.html#cb224-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb224-2"><a href="linear-models.html#cb224-2"></a></span>
<span id="cb224-3"><a href="linear-models.html#cb224-3"></a><span class="kw">tibble</span>(<span class="dt">samples =</span> <span class="kw">map_dbl</span>(<span class="dv">1</span><span class="op">:</span><span class="fl">1e4</span>, <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(<span class="kw">prod</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.5</span>))))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb224-4"><a href="linear-models.html#cb224-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> samples)) <span class="op">+</span></span>
<span id="cb224-5"><a href="linear-models.html#cb224-5"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">color =</span> <span class="st">&quot;transparent&quot;</span>, </span>
<span id="cb224-6"><a href="linear-models.html#cb224-6"></a>               <span class="dt">fill =</span> <span class="st">&quot;gray33&quot;</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-10-1.png" width="312" /></p>
<p>What we did was really compact. Walking it out a bit, here’s what we all did within the second argument within <code>map_dbl()</code> (i.e., everything within <code>log()</code>).</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="linear-models.html#cb225-1"></a><span class="kw">tibble</span>(<span class="dt">a =</span> <span class="kw">runif</span>(<span class="dv">12</span>, <span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb225-2"><a href="linear-models.html#cb225-2"></a>       <span class="dt">b =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb225-3"><a href="linear-models.html#cb225-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">c =</span> a <span class="op">+</span><span class="st"> </span>b) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb225-4"><a href="linear-models.html#cb225-4"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">p =</span> <span class="kw">prod</span>(c) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">log</span>())</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##       p
##   &lt;dbl&gt;
## 1  2.82</code></pre>
<p>And based on the first argument within <code>map_dbl()</code>, we did that 10,000 times, after which we converted the results to a tibble and then fed those data into ggplot2. Anyway, “we get the Gaussian distribution back, because adding logs is equivalent to multiplying the original numbers. So even multiplicative interactions of large deviations can produce Gaussian distributions, once we measure the outcomes on the log scale” (p. 75).</p>
</div>
<div id="using-gaussian-distributions." class="section level3">
<h3><span class="header-section-number">4.1.4</span> Using Gaussian distributions.</h3>
<p>I really like the justifications in the following subsections.</p>
<div id="ontological-justification." class="section level4">
<h4><span class="header-section-number">4.1.4.1</span> Ontological justification.</h4>
<p>The Gaussian is</p>
<blockquote>
<p>a widespread pattern, appearing again and again at different scales and in different domains. Measurement errors, variations in growth, and the velocities of molecules all tend towards Gaussian distributions. These processes do this because at their heart, these processes add together fluctuations. And repeatedly adding finite fluctuations results in a distribution of sums that have shed all information about the underlying process, aside from mean and spread.</p>
<p>One consequence of this is that statistical models based on Gaussian distributions cannot reliably identify micro-process. (p. 75)</p>
</blockquote>
<p>But they can still be useful.</p>
</div>
<div id="epistemological-justification." class="section level4">
<h4><span class="header-section-number">4.1.4.2</span> Epistemological justification.</h4>
<blockquote>
<p>Another route to justifying the Gaussian as our choice of skeleton, and a route that will help us appreciate later why it is often a poor choice, is that it represents a particular state of ignorance. When all we know or are willing to say about a distribution of measures (measures are continuous values on the real number line) is their mean and variance, then the Gaussian distribution arises as the most consistent with our assumptions.</p>
<p>That is to say that the Gaussian distribution is the most natural expression of our state of ignorance, because if all we are willing to assume is that a measure has finite variance, the Gaussian distribution is the shape that can be realized in the largest number of ways and does not introduce any new assumptions. It is the least surprising and least informative assumption to make. In this way, the Gaussian is the distribution most consistent with our assumptions… If you don’t think the distribution should be Gaussian, then that implies that you know something else that you should tell your golem about, something that would improve inference. (pp. 75–76)</p>
</blockquote>
</div>
<div id="overthinking-gaussian-distribution." class="section level4">
<h4><span class="header-section-number">4.1.4.3</span> Overthinking: Gaussian distribution.</h4>
<p>Let <span class="math inline">\(y\)</span> be the criterion, <span class="math inline">\(\mu\)</span> be the mean, and <span class="math inline">\(\sigma\)</span> be the standard deviation. Then the probability density of some Gaussian value <span class="math inline">\(y\)</span> is</p>
<p><span class="math display">\[p(y|\mu, \sigma) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left (- \frac{(y - \mu)^2}{2 \sigma^2} \right).\]</span></p>
<p>McElreath’s right. “This looks monstrous” (p. 76). Why not demystify that monster with a little R code? For simplicity, we’ll look at <span class="math inline">\(p(y)\)</span> over a series of <span class="math inline">\(y\)</span> values ranging from -4 to 4, holding <span class="math inline">\(\mu = 0\)</span> and <span class="math inline">\(\sigma = 1\)</span>. Then we’ll plot.</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="linear-models.html#cb227-1"></a><span class="co"># define our input values</span></span>
<span id="cb227-2"><a href="linear-models.html#cb227-2"></a><span class="kw">tibble</span>(<span class="dt">y     =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-4</span>, <span class="dt">to =</span> <span class="dv">4</span>, <span class="dt">by =</span> <span class="fl">.1</span>),</span>
<span id="cb227-3"><a href="linear-models.html#cb227-3"></a>       <span class="dt">mu    =</span> <span class="dv">0</span>,</span>
<span id="cb227-4"><a href="linear-models.html#cb227-4"></a>       <span class="dt">sigma =</span> <span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb227-5"><a href="linear-models.html#cb227-5"></a><span class="st">  </span><span class="co"># compute p(y) using a hand-made Gaussian likelihood</span></span>
<span id="cb227-6"><a href="linear-models.html#cb227-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p_y =</span> (<span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pi <span class="op">*</span><span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span>)) <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>(y <span class="op">-</span><span class="st"> </span>mu)<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb227-7"><a href="linear-models.html#cb227-7"></a><span class="st">  </span></span>
<span id="cb227-8"><a href="linear-models.html#cb227-8"></a><span class="st">  </span><span class="co"># plot!</span></span>
<span id="cb227-9"><a href="linear-models.html#cb227-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> y, <span class="dt">y =</span> p_y)) <span class="op">+</span></span>
<span id="cb227-10"><a href="linear-models.html#cb227-10"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb227-11"><a href="linear-models.html#cb227-11"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="kw">expression</span>(<span class="kw">italic</span>(p)(<span class="kw">italic</span>(<span class="st">&quot;y|&quot;</span>)<span class="op">*</span>mu<span class="op">==</span><span class="dv">0</span><span class="op">*</span><span class="st">&quot;,&quot;</span><span class="op">~</span>sigma<span class="op">==</span><span class="dv">1</span>)))</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-12-1.png" width="384" /></p>
<p>You get the same results is you switch out that mutate line with <code>mutate(p_y = dnorm(y)) %&gt;%</code>. To learn more, execute <code>?dnorm</code>.</p>
</div>
</div>
</div>
<div id="a-language-for-describing-models" class="section level2">
<h2><span class="header-section-number">4.2</span> A language for describing models</h2>
<p>Our mathy ways of summarizing models will be something like</p>
<p><span class="math display">\[\begin{align*}
\text{criterion}_i &amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i  &amp; = \beta \times \text{predictor}_i \\
\beta  &amp; \sim \operatorname{Normal}(0, 10) \\
\sigma &amp; \sim \operatorname{HalfCauchy}(0, 1).
\end{align*}\]</span></p>
<p>And as McElreath then followed up with, “If that doesn’t make much sense, good. That indicates that you are holding the right textbook” (p. 77). Welcome applied statistics!</p>
<div id="re-describing-the-globe-tossing-model." class="section level3">
<h3><span class="header-section-number">4.2.1</span> Re-describing the globe tossing model.</h3>
<p>For the globe tossing model, the probability <span class="math inline">\(p\)</span> of a count of water <span class="math inline">\(w\)</span> based on <span class="math inline">\(n\)</span> trials was</p>
<p><span class="math display">\[\begin{align*}
w &amp; \sim \operatorname{Binomial}(n, p) \\
p &amp; \sim \operatorname{Uniform}(0, 1).
\end{align*}\]</span></p>
<p>We can break McElreath’s R code 4.6 down a little bit with a tibble like so.</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="linear-models.html#cb228-1"></a><span class="co"># how many `p_grid` points would you like?</span></span>
<span id="cb228-2"><a href="linear-models.html#cb228-2"></a>n_points &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb228-3"><a href="linear-models.html#cb228-3"></a></span>
<span id="cb228-4"><a href="linear-models.html#cb228-4"></a>d &lt;-</span>
<span id="cb228-5"><a href="linear-models.html#cb228-5"></a><span class="st">  </span><span class="kw">tibble</span>(<span class="dt">p_grid =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">0</span>, <span class="dt">to =</span> <span class="dv">1</span>, <span class="dt">length.out =</span> n_points),</span>
<span id="cb228-6"><a href="linear-models.html#cb228-6"></a>         <span class="dt">w      =</span> <span class="dv">6</span>, </span>
<span id="cb228-7"><a href="linear-models.html#cb228-7"></a>         <span class="dt">n      =</span> <span class="dv">9</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb228-8"><a href="linear-models.html#cb228-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prior      =</span> <span class="kw">dunif</span>(p_grid, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb228-9"><a href="linear-models.html#cb228-9"></a>         <span class="dt">likelihood =</span> <span class="kw">dbinom</span>(w, n, p_grid)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb228-10"><a href="linear-models.html#cb228-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">posterior =</span> likelihood <span class="op">*</span><span class="st"> </span>prior <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(likelihood <span class="op">*</span><span class="st"> </span>prior))</span>
<span id="cb228-11"><a href="linear-models.html#cb228-11"></a></span>
<span id="cb228-12"><a href="linear-models.html#cb228-12"></a><span class="kw">head</span>(d)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 6
##   p_grid     w     n prior likelihood posterior
##    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;
## 1 0          6     9     1   0.        0.      
## 2 0.0101     6     9     1   8.65e-11  8.74e-12
## 3 0.0202     6     9     1   5.37e- 9  5.43e-10
## 4 0.0303     6     9     1   5.93e- 8  5.99e- 9
## 5 0.0404     6     9     1   3.23e- 7  3.26e- 8
## 6 0.0505     6     9     1   1.19e- 6  1.21e- 7</code></pre>
<p>In case you were curious, here’s what they look like.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="linear-models.html#cb230-1"></a>d <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb230-2"><a href="linear-models.html#cb230-2"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>w, <span class="op">-</span>n) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb230-3"><a href="linear-models.html#cb230-3"></a><span class="st">  </span><span class="kw">gather</span>(key, value, <span class="op">-</span>p_grid) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb230-4"><a href="linear-models.html#cb230-4"></a><span class="st">  </span><span class="co"># this line allows us to dictate the order the panels will appear in</span></span>
<span id="cb230-5"><a href="linear-models.html#cb230-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">key =</span> <span class="kw">factor</span>(key, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;prior&quot;</span>, <span class="st">&quot;likelihood&quot;</span>, <span class="st">&quot;posterior&quot;</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb230-6"><a href="linear-models.html#cb230-6"></a><span class="st">  </span></span>
<span id="cb230-7"><a href="linear-models.html#cb230-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> p_grid, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> value, <span class="dt">fill =</span> key)) <span class="op">+</span></span>
<span id="cb230-8"><a href="linear-models.html#cb230-8"></a><span class="st">  </span><span class="kw">geom_ribbon</span>() <span class="op">+</span></span>
<span id="cb230-9"><a href="linear-models.html#cb230-9"></a><span class="st">  </span><span class="kw">scale_fill_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;purple&quot;</span>)) <span class="op">+</span></span>
<span id="cb230-10"><a href="linear-models.html#cb230-10"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb230-11"><a href="linear-models.html#cb230-11"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>) <span class="op">+</span></span>
<span id="cb230-12"><a href="linear-models.html#cb230-12"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-14-1.png" width="768" /></p>
<p>The posterior is a combination of the prior and the likelihood. When the prior is flat across the parameter space, the posterior is just the likelihood re-expressed as a probability. As we go along, you’ll see that we almost never use flat priors in practice.</p>
</div>
</div>
<div id="a-gaussian-model-of-height" class="section level2">
<h2><span class="header-section-number">4.3</span> A Gaussian model of height</h2>
<blockquote>
<p>There are an infinite number of possible Gaussian distributions. Some have small means. Others have large means. Some are wide, with a large <span class="math inline">\(\sigma\)</span>. Others are narrow. We want our Bayesian machine to consider every possible distribution, each defined by a combination of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, and rank them by posterior plausibility. (p. 79)</p>
</blockquote>
<div id="the-data." class="section level3">
<h3><span class="header-section-number">4.3.1</span> The data.</h3>
<p>Let’s get the Howell <span class="citation">(<a href="#ref-howell2001demography" role="doc-biblioref">2001</a>, <a href="#ref-howell2010life" role="doc-biblioref">2010</a>)</span> data from McElreath’s <span class="citation">(<a href="#ref-R-rethinking" role="doc-biblioref">2020</a><a href="#ref-R-rethinking" role="doc-biblioref">a</a>)</span> <a href="https://xcelab.net/rm/software/"><strong>rethinking</strong> package</a>.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="linear-models.html#cb231-1"></a><span class="kw">library</span>(rethinking)</span>
<span id="cb231-2"><a href="linear-models.html#cb231-2"></a><span class="kw">data</span>(Howell1)</span>
<span id="cb231-3"><a href="linear-models.html#cb231-3"></a>d &lt;-<span class="st"> </span>Howell1</span></code></pre></div>
<p>Here we open our main statistical package, Bürkner’s <a href="https://github.com/paul-buerkner/brms">brms</a>. But before we do, we’ll want to detach the rethinking package. R will not allow users to use a function from one package that shares the same name as a different function from another package if both packages are open at the same time. The rethinking and brms packages are designed for similar purposes and, unsurprisingly, overlap in the names of their functions. To prevent problems, it is a good idea to make sure rethinking is detached before using brms. To learn more on the topic, see <a href="https://www.r-bloggers.com/r-and-package-masking-a-real-life-example/">this R-bloggers post</a>.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="linear-models.html#cb232-1"></a><span class="kw">rm</span>(Howell1)</span>
<span id="cb232-2"><a href="linear-models.html#cb232-2"></a><span class="kw">detach</span>(package<span class="op">:</span>rethinking, <span class="dt">unload =</span> T)</span>
<span id="cb232-3"><a href="linear-models.html#cb232-3"></a><span class="kw">library</span>(brms)</span></code></pre></div>
<p>Go ahead and investigate the data with <code>str()</code>, the tidyverse analogue for which is <code>glimpse()</code>.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="linear-models.html#cb233-1"></a>d <span class="op">%&gt;%</span></span>
<span id="cb233-2"><a href="linear-models.html#cb233-2"></a><span class="st">  </span><span class="kw">str</span>()</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    544 obs. of  4 variables:
##  $ height: num  152 140 137 157 145 ...
##  $ weight: num  47.8 36.5 31.9 53 41.3 ...
##  $ age   : num  63 63 65 41 51 35 32 27 19 54 ...
##  $ male  : int  1 0 0 1 0 1 0 1 0 1 ...</code></pre>
<p>Here are the <code>height</code> values.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="linear-models.html#cb235-1"></a>d <span class="op">%&gt;%</span></span>
<span id="cb235-2"><a href="linear-models.html#cb235-2"></a><span class="st">  </span><span class="kw">select</span>(height) <span class="op">%&gt;%</span></span>
<span id="cb235-3"><a href="linear-models.html#cb235-3"></a><span class="st">  </span><span class="kw">head</span>()</span></code></pre></div>
<pre><code>##    height
## 1 151.765
## 2 139.700
## 3 136.525
## 4 156.845
## 5 145.415
## 6 163.830</code></pre>
<p>We can use <code>filter()</code> to make an adults-only data frame.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="linear-models.html#cb237-1"></a>d2 &lt;-<span class="st"> </span></span>
<span id="cb237-2"><a href="linear-models.html#cb237-2"></a><span class="st">  </span>d <span class="op">%&gt;%</span></span>
<span id="cb237-3"><a href="linear-models.html#cb237-3"></a><span class="st">  </span><span class="kw">filter</span>(age <span class="op">&gt;=</span><span class="st"> </span><span class="dv">18</span>)</span></code></pre></div>
<p>There are a lot of ways we can make sure our <code>d2</code> has 352 rows. Here’s one.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="linear-models.html#cb238-1"></a>d2 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb238-2"><a href="linear-models.html#cb238-2"></a><span class="st">  </span><span class="kw">count</span>()</span></code></pre></div>
<pre><code>##     n
## 1 352</code></pre>
<div id="overthinking-data-frames." class="section level4">
<h4><span class="header-section-number">4.3.1.1</span> Overthinking: Data frames.</h4>
<p>This probably reflects my training history, but the structure of a data frame seems natural and inherently appealing, to me. So I can’t relate to the “annoying” comment. But if you’re in the other camp, do check out either of these two data wrangling talks (<a href="https://www.youtube.com/watch?v=4MfUCX_KpdE&amp;t=23s&amp;frags=pl%2Cwn">here</a> and <a href="https://www.youtube.com/watch?v=GapSskrtUzU&amp;t=1249s&amp;frags=pl%2Cwn">here</a>) by the ineffable <a href="https://twitter.com/jennybryan?lang=en">Jenny Bryan</a>.</p>
</div>
<div id="overthinking-index-magic." class="section level4">
<h4><span class="header-section-number">4.3.1.2</span> Overthinking: Index magic.</h4>
<p>For more on indexing, check out <a href="https://bookdown.org/rdpeng/rprogdatascience/subsetting-r-objects.html">Chapter 9</a> of Peng’s <span class="citation">(<a href="#ref-pengProgrammingDataScience2019" role="doc-biblioref">2019</a>)</span> text, <em>R programming for data science</em>, or even the <a href="http://r4ds.had.co.nz/vectors.html#subsetting-1">Subsetting</a> subsection from <em>R4DS</em>.</p>
</div>
</div>
<div id="the-model." class="section level3">
<h3><span class="header-section-number">4.3.2</span> The model.</h3>
<p>The likelihood for our model is</p>
<p><span class="math display">\[h_i \sim \operatorname{Normal}(\mu, \sigma),\]</span></p>
<p>our <span class="math inline">\(\mu\)</span> prior will be</p>
<p><span class="math display">\[\mu \sim \operatorname{Normal}(178, 20),\]</span></p>
<p>and our prior for <span class="math inline">\(\sigma\)</span> will be</p>
<p><span class="math display">\[\sigma \sim \operatorname{Uniform}(0, 50).\]</span></p>
<p>Here’s the shape of the prior for <span class="math inline">\(\mu\)</span> in <span class="math inline">\(N(178, 20)\)</span>.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="linear-models.html#cb240-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">100</span>, <span class="dt">to =</span> <span class="dv">250</span>, <span class="dt">by =</span> <span class="fl">.1</span>)), </span>
<span id="cb240-2"><a href="linear-models.html#cb240-2"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">178</span>, <span class="dt">sd =</span> <span class="dv">20</span>))) <span class="op">+</span></span>
<span id="cb240-3"><a href="linear-models.html#cb240-3"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb240-4"><a href="linear-models.html#cb240-4"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;density&quot;</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-21-1.png" width="288" /></p>
<p>And here’s the ggplot2 code for our prior for <span class="math inline">\(\sigma\)</span>, a uniform distribution with a minimum value of 0 and a maximum value of 50. We don’t really need the y axis when looking at the shapes of a density, so we’ll just remove it with <code>scale_y_continuous()</code>.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="linear-models.html#cb241-1"></a><span class="kw">tibble</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">-10</span>, <span class="dt">to =</span> <span class="dv">60</span>, <span class="dt">by =</span> <span class="fl">.1</span>)) <span class="op">%&gt;%</span></span>
<span id="cb241-2"><a href="linear-models.html#cb241-2"></a><span class="st">  </span></span>
<span id="cb241-3"><a href="linear-models.html#cb241-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">dunif</span>(x, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> <span class="dv">50</span>))) <span class="op">+</span></span>
<span id="cb241-4"><a href="linear-models.html#cb241-4"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb241-5"><a href="linear-models.html#cb241-5"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb241-6"><a href="linear-models.html#cb241-6"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-22-1.png" width="288" /></p>
<p>We can simulate from both priors at once to get a prior probability distribution of <code>heights</code>.</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="linear-models.html#cb242-1"></a>n &lt;-<span class="st"> </span><span class="fl">1e4</span></span>
<span id="cb242-2"><a href="linear-models.html#cb242-2"></a></span>
<span id="cb242-3"><a href="linear-models.html#cb242-3"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb242-4"><a href="linear-models.html#cb242-4"></a><span class="kw">tibble</span>(<span class="dt">sample_mu    =</span> <span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="dv">178</span>,       <span class="dt">sd  =</span> <span class="dv">20</span>),</span>
<span id="cb242-5"><a href="linear-models.html#cb242-5"></a>       <span class="dt">sample_sigma =</span> <span class="kw">runif</span>(n, <span class="dt">min  =</span> <span class="dv">0</span>,         <span class="dt">max =</span> <span class="dv">50</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb242-6"><a href="linear-models.html#cb242-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(n, <span class="dt">mean =</span> sample_mu, <span class="dt">sd  =</span> sample_sigma)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb242-7"><a href="linear-models.html#cb242-7"></a><span class="st">  </span></span>
<span id="cb242-8"><a href="linear-models.html#cb242-8"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x)) <span class="op">+</span></span>
<span id="cb242-9"><a href="linear-models.html#cb242-9"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">size =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb242-10"><a href="linear-models.html#cb242-10"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb242-11"><a href="linear-models.html#cb242-11"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="kw">expression</span>(Prior<span class="op">~</span>predictive<span class="op">~</span>distribution<span class="op">~</span><span class="st">&quot;for&quot;</span><span class="op">~</span><span class="kw">italic</span>(h[i])),</span>
<span id="cb242-12"><a href="linear-models.html#cb242-12"></a>       <span class="dt">x =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb242-13"><a href="linear-models.html#cb242-13"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-23-1.png" width="288" /></p>
<p>As McElreath wrote, we’ve made a “vaguely bell-shaped density with thick tails. It is the expected distribution of heights, averaged over the prior” (p. 83).</p>
</div>
<div id="grid-approximation-of-the-posterior-distribution." class="section level3">
<h3><span class="header-section-number">4.3.3</span> Grid approximation of the posterior distribution.</h3>
<p>As McElreath explained, you’ll never use the grid approximation approach for practical data analysis. But I found this helped me better understanding what exactly we’re doing with Bayesian estimation. So let’s play along. This is our version of the first three lines in McElreath’s R code 4.14.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="linear-models.html#cb243-1"></a>n &lt;-<span class="st"> </span><span class="dv">200</span></span>
<span id="cb243-2"><a href="linear-models.html#cb243-2"></a></span>
<span id="cb243-3"><a href="linear-models.html#cb243-3"></a>d_grid &lt;-</span>
<span id="cb243-4"><a href="linear-models.html#cb243-4"></a><span class="st">  </span><span class="co"># we&#39;ll accomplish with `tidyr::crossing()` what McElreath did with base R `expand.grid()`</span></span>
<span id="cb243-5"><a href="linear-models.html#cb243-5"></a><span class="st">  </span><span class="kw">crossing</span>(<span class="dt">mu    =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">140</span>, <span class="dt">to =</span> <span class="dv">160</span>, <span class="dt">length.out =</span> n),</span>
<span id="cb243-6"><a href="linear-models.html#cb243-6"></a>           <span class="dt">sigma =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">4</span>,   <span class="dt">to =</span> <span class="dv">9</span>,   <span class="dt">length.out =</span> n))</span>
<span id="cb243-7"><a href="linear-models.html#cb243-7"></a></span>
<span id="cb243-8"><a href="linear-models.html#cb243-8"></a><span class="kw">glimpse</span>(d_grid)</span></code></pre></div>
<pre><code>## Rows: 40,000
## Columns: 2
## $ mu    &lt;dbl&gt; 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140, 140…
## $ sigma &lt;dbl&gt; 4.000000, 4.025126, 4.050251, 4.075377, 4.100503, 4.125628, 4.150754, 4.175879, 4.2…</code></pre>
<p><code>d_grid</code> contains every combination of <code>mu</code> and <code>sigma</code> across their specified values. Instead of base R <code>sapply()</code>, we’ll do the computations by making a custom function which we’ll plug into <code>purrr::map2().</code></p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="linear-models.html#cb245-1"></a>grid_function &lt;-<span class="st"> </span><span class="cf">function</span>(mu, sigma) {</span>
<span id="cb245-2"><a href="linear-models.html#cb245-2"></a>  </span>
<span id="cb245-3"><a href="linear-models.html#cb245-3"></a>  <span class="kw">dnorm</span>(d2<span class="op">$</span>height, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma, <span class="dt">log =</span> T) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb245-4"><a href="linear-models.html#cb245-4"></a><span class="st">    </span><span class="kw">sum</span>()</span>
<span id="cb245-5"><a href="linear-models.html#cb245-5"></a>  </span>
<span id="cb245-6"><a href="linear-models.html#cb245-6"></a>}</span></code></pre></div>
<p>Now we’re ready to complete the tibble.</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="linear-models.html#cb246-1"></a>d_grid &lt;-</span>
<span id="cb246-2"><a href="linear-models.html#cb246-2"></a><span class="st">  </span>d_grid <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb246-3"><a href="linear-models.html#cb246-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_likelihood =</span> <span class="kw">map2</span>(mu, sigma, grid_function)) <span class="op">%&gt;%</span></span>
<span id="cb246-4"><a href="linear-models.html#cb246-4"></a><span class="st">  </span><span class="kw">unnest</span>(log_likelihood) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb246-5"><a href="linear-models.html#cb246-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prior_mu    =</span> <span class="kw">dnorm</span>(mu,    <span class="dt">mean =</span> <span class="dv">178</span>, <span class="dt">sd  =</span> <span class="dv">20</span>, <span class="dt">log =</span> T),</span>
<span id="cb246-6"><a href="linear-models.html#cb246-6"></a>         <span class="dt">prior_sigma =</span> <span class="kw">dunif</span>(sigma, <span class="dt">min  =</span> <span class="dv">0</span>,   <span class="dt">max =</span> <span class="dv">50</span>, <span class="dt">log =</span> T)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb246-7"><a href="linear-models.html#cb246-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">product =</span> log_likelihood <span class="op">+</span><span class="st"> </span>prior_mu <span class="op">+</span><span class="st"> </span>prior_sigma) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb246-8"><a href="linear-models.html#cb246-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">probability =</span> <span class="kw">exp</span>(product <span class="op">-</span><span class="st"> </span><span class="kw">max</span>(product)))</span>
<span id="cb246-9"><a href="linear-models.html#cb246-9"></a>  </span>
<span id="cb246-10"><a href="linear-models.html#cb246-10"></a><span class="kw">head</span>(d_grid)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 7
##      mu sigma log_likelihood prior_mu prior_sigma product probability
##   &lt;dbl&gt; &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;
## 1   140  4            -3813.    -5.72       -3.91  -3822.           0
## 2   140  4.03         -3778.    -5.72       -3.91  -3787.           0
## 3   140  4.05         -3743.    -5.72       -3.91  -3753.           0
## 4   140  4.08         -3709.    -5.72       -3.91  -3719.           0
## 5   140  4.10         -3676.    -5.72       -3.91  -3686.           0
## 6   140  4.13         -3644.    -5.72       -3.91  -3653.           0</code></pre>
<p>In the final <code>d_grid</code>, the <code>probability</code> vector contains the posterior probabilities across values of <code>mu</code> and <code>sigma</code>. We can make a contour plot with <code>geom_contour()</code>.</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="linear-models.html#cb248-1"></a>d_grid <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb248-2"><a href="linear-models.html#cb248-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">y =</span> sigma, <span class="dt">z =</span> probability)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb248-3"><a href="linear-models.html#cb248-3"></a><span class="st">  </span><span class="kw">geom_contour</span>() <span class="op">+</span></span>
<span id="cb248-4"><a href="linear-models.html#cb248-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu),</span>
<span id="cb248-5"><a href="linear-models.html#cb248-5"></a>       <span class="dt">y =</span> <span class="kw">expression</span>(sigma)) <span class="op">+</span></span>
<span id="cb248-6"><a href="linear-models.html#cb248-6"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d_grid<span class="op">$</span>mu),</span>
<span id="cb248-7"><a href="linear-models.html#cb248-7"></a>                  <span class="dt">ylim =</span> <span class="kw">range</span>(d_grid<span class="op">$</span>sigma)) <span class="op">+</span></span>
<span id="cb248-8"><a href="linear-models.html#cb248-8"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-27-1.png" width="384" /></p>
<p>We’ll make our heat map with <code>geom_raster(aes(fill = probability))</code>.</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="linear-models.html#cb249-1"></a>d_grid <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb249-2"><a href="linear-models.html#cb249-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">y =</span> sigma)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb249-3"><a href="linear-models.html#cb249-3"></a><span class="st">  </span><span class="kw">geom_raster</span>(<span class="kw">aes</span>(<span class="dt">fill =</span> probability),</span>
<span id="cb249-4"><a href="linear-models.html#cb249-4"></a>              <span class="dt">interpolate =</span> T) <span class="op">+</span></span>
<span id="cb249-5"><a href="linear-models.html#cb249-5"></a><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>(<span class="dt">option =</span> <span class="st">&quot;A&quot;</span>) <span class="op">+</span></span>
<span id="cb249-6"><a href="linear-models.html#cb249-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu),</span>
<span id="cb249-7"><a href="linear-models.html#cb249-7"></a>       <span class="dt">y =</span> <span class="kw">expression</span>(sigma)) <span class="op">+</span></span>
<span id="cb249-8"><a href="linear-models.html#cb249-8"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-28-1.png" width="480" /></p>
</div>
<div id="sampling-from-the-posterior." class="section level3">
<h3><span class="header-section-number">4.3.4</span> Sampling from the posterior.</h3>
<p>We can use <code>dplyr::sample_n()</code> to sample rows, with replacement, from <code>d_grid</code>.</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="linear-models.html#cb250-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb250-2"><a href="linear-models.html#cb250-2"></a>d_grid_samples &lt;-<span class="st"> </span></span>
<span id="cb250-3"><a href="linear-models.html#cb250-3"></a><span class="st">  </span>d_grid <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb250-4"><a href="linear-models.html#cb250-4"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="fl">1e4</span>, <span class="dt">replace =</span> T, <span class="dt">weight =</span> probability)</span>
<span id="cb250-5"><a href="linear-models.html#cb250-5"></a></span>
<span id="cb250-6"><a href="linear-models.html#cb250-6"></a>d_grid_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb250-7"><a href="linear-models.html#cb250-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">y =</span> sigma)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb250-8"><a href="linear-models.html#cb250-8"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">.9</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">15</span>) <span class="op">+</span></span>
<span id="cb250-9"><a href="linear-models.html#cb250-9"></a><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>() <span class="op">+</span></span>
<span id="cb250-10"><a href="linear-models.html#cb250-10"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu[samples]),</span>
<span id="cb250-11"><a href="linear-models.html#cb250-11"></a>       <span class="dt">y =</span> <span class="kw">expression</span>(sigma[samples])) <span class="op">+</span></span>
<span id="cb250-12"><a href="linear-models.html#cb250-12"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-29-1.png" width="384" /></p>
<p>We can use <code>gather()</code> and then <code>facet_warp()</code> to plot the densities for both <code>mu</code> and <code>sigma</code> at once.</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="linear-models.html#cb251-1"></a>d_grid_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb251-2"><a href="linear-models.html#cb251-2"></a><span class="st">  </span><span class="kw">select</span>(mu, sigma) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb251-3"><a href="linear-models.html#cb251-3"></a><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb251-4"><a href="linear-models.html#cb251-4"></a></span>
<span id="cb251-5"><a href="linear-models.html#cb251-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb251-6"><a href="linear-models.html#cb251-6"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&quot;grey33&quot;</span>, <span class="dt">size =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb251-7"><a href="linear-models.html#cb251-7"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb251-8"><a href="linear-models.html#cb251-8"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb251-9"><a href="linear-models.html#cb251-9"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></span>
<span id="cb251-10"><a href="linear-models.html#cb251-10"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-30-1.png" width="576" /></p>
<p>We’ll use the tidybayes package to compute their posterior modes and 95% HDIs.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="linear-models.html#cb252-1"></a><span class="kw">library</span>(tidybayes)</span>
<span id="cb252-2"><a href="linear-models.html#cb252-2"></a></span>
<span id="cb252-3"><a href="linear-models.html#cb252-3"></a>d_grid_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb252-4"><a href="linear-models.html#cb252-4"></a><span class="st">  </span><span class="kw">select</span>(mu, sigma) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb252-5"><a href="linear-models.html#cb252-5"></a><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb252-6"><a href="linear-models.html#cb252-6"></a><span class="st">  </span><span class="kw">group_by</span>(key) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb252-7"><a href="linear-models.html#cb252-7"></a><span class="st">  </span><span class="kw">mode_hdi</span>(value)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   key    value .lower .upper .width .point .interval
##   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 mu    155.   154.   155.     0.95 mode   hdi      
## 2 sigma   7.82   7.14   8.30   0.95 mode   hdi</code></pre>
<p>Let’s say you wanted their posterior medians and 50% quantile-based intervals, instead. Just switch out the last line for <code>median_qi(value, .width = .5)</code>.</p>
<div id="overthinking-sample-size-and-the-normality-of-sigmas-posterior." class="section level4">
<h4><span class="header-section-number">4.3.4.1</span> Overthinking: Sample size and the normality of <span class="math inline">\(\sigma\)</span>’s posterior.</h4>
<p>Since we’ll be fitting models with brms almost exclusively from here on out, this section is largely moot. But we’ll do it anyway for the sake of practice. I’m going to break the steps up like before rather than compress the code together. Here’s <code>d3</code>.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="linear-models.html#cb254-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb254-2"><a href="linear-models.html#cb254-2"></a>(d3 &lt;-<span class="st"> </span><span class="kw">sample</span>(d2<span class="op">$</span>height, <span class="dt">size =</span> <span class="dv">20</span>))</span></code></pre></div>
<pre><code>##  [1] 147.3200 154.9400 168.9100 156.8450 165.7350 151.7650 165.7350 156.2100 144.7800 154.9400
## [11] 151.1300 147.9550 149.8600 162.5600 161.9250 164.4650 160.9852 151.7650 163.8300 149.8600</code></pre>
<p>For our first step using <code>d3</code>, we’ll redefine <code>d_grid</code>.</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="linear-models.html#cb256-1"></a>n &lt;-<span class="st"> </span><span class="dv">200</span></span>
<span id="cb256-2"><a href="linear-models.html#cb256-2"></a></span>
<span id="cb256-3"><a href="linear-models.html#cb256-3"></a><span class="co"># note we&#39;ve redefined the ranges of `mu` and `sigma`</span></span>
<span id="cb256-4"><a href="linear-models.html#cb256-4"></a>d_grid &lt;-</span>
<span id="cb256-5"><a href="linear-models.html#cb256-5"></a><span class="st">  </span><span class="kw">crossing</span>(<span class="dt">mu    =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">150</span>, <span class="dt">to =</span> <span class="dv">170</span>, <span class="dt">length.out =</span> n),</span>
<span id="cb256-6"><a href="linear-models.html#cb256-6"></a>           <span class="dt">sigma =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">4</span>,   <span class="dt">to =</span> <span class="dv">20</span>,  <span class="dt">length.out =</span> n))</span></code></pre></div>
<p>Second, we’ll redefine our custom <code>grid_function()</code> function to operate over the <code>height</code> values of <code>d3</code>.</p>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="linear-models.html#cb257-1"></a>grid_function &lt;-<span class="st"> </span><span class="cf">function</span>(mu, sigma) {</span>
<span id="cb257-2"><a href="linear-models.html#cb257-2"></a>  </span>
<span id="cb257-3"><a href="linear-models.html#cb257-3"></a>  <span class="kw">dnorm</span>(d3, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma, <span class="dt">log =</span> T) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb257-4"><a href="linear-models.html#cb257-4"></a><span class="st">    </span><span class="kw">sum</span>()</span>
<span id="cb257-5"><a href="linear-models.html#cb257-5"></a>  </span>
<span id="cb257-6"><a href="linear-models.html#cb257-6"></a>}</span></code></pre></div>
<p>Now we’ll use the amended <code>grid_function()</code> to make the posterior.</p>
<div class="sourceCode" id="cb258"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb258-1"><a href="linear-models.html#cb258-1"></a>d_grid &lt;-</span>
<span id="cb258-2"><a href="linear-models.html#cb258-2"></a><span class="st">  </span>d_grid <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb258-3"><a href="linear-models.html#cb258-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">log_likelihood =</span> <span class="kw">map2_dbl</span>(mu, sigma, grid_function)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb258-4"><a href="linear-models.html#cb258-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prior_mu    =</span> <span class="kw">dnorm</span>(mu,    <span class="dt">mean =</span> <span class="dv">178</span>, <span class="dt">sd  =</span> <span class="dv">20</span>, <span class="dt">log =</span> T),</span>
<span id="cb258-5"><a href="linear-models.html#cb258-5"></a>         <span class="dt">prior_sigma =</span> <span class="kw">dunif</span>(sigma, <span class="dt">min  =</span> <span class="dv">0</span>,   <span class="dt">max =</span> <span class="dv">50</span>, <span class="dt">log =</span> T)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb258-6"><a href="linear-models.html#cb258-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">product =</span> log_likelihood <span class="op">+</span><span class="st"> </span>prior_mu <span class="op">+</span><span class="st"> </span>prior_sigma) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb258-7"><a href="linear-models.html#cb258-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">probability =</span> <span class="kw">exp</span>(product <span class="op">-</span><span class="st"> </span><span class="kw">max</span>(product)))</span></code></pre></div>
<p>Did you catch our use of <code>purrr::map2_dbl()</code>, there, in place of <code>purrr::map2()</code>? It turns out that <code>purrr::map()</code> and <code>purrr::map2()</code> always return a list (see <a href="https://purrr.tidyverse.org/reference/map.html">here</a> and <a href="https://purrr.tidyverse.org/reference/map2.html">here</a>). However, we can add the <code>_dbl</code> suffix to those functions, which will instruct the purrr package to return a double vector (i.e., a <a href="https://r4ds.had.co.nz/vectors.html#important-types-of-atomic-vector">common kind of numeric vector</a>). The advantage of that approach is we no longer need to follow our <code>map()</code> or <code>map2()</code> lines with <code>unnest()</code>. To learn more about the ins and outs of the <code>map()</code> family, check out <a href="https://r4ds.had.co.nz/iteration.html#the-map-functions">this section</a> from <em>R4DS</em> or Jenny Bryan’s <a href="https://jennybc.github.io/purrr-tutorial/"><em>purrr tutorial</em></a>.</p>
<p>Next we’ll <code>sample_n()</code> and plot.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="linear-models.html#cb259-1"></a><span class="kw">set.seed</span>(<span class="dv">4</span>)</span>
<span id="cb259-2"><a href="linear-models.html#cb259-2"></a>d_grid_samples &lt;-<span class="st"> </span></span>
<span id="cb259-3"><a href="linear-models.html#cb259-3"></a><span class="st">  </span>d_grid <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb259-4"><a href="linear-models.html#cb259-4"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dt">size =</span> <span class="fl">1e4</span>, <span class="dt">replace =</span> T, <span class="dt">weight =</span> probability)</span>
<span id="cb259-5"><a href="linear-models.html#cb259-5"></a></span>
<span id="cb259-6"><a href="linear-models.html#cb259-6"></a>d_grid_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb259-7"><a href="linear-models.html#cb259-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu, <span class="dt">y =</span> sigma)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb259-8"><a href="linear-models.html#cb259-8"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="fl">.9</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">15</span>) <span class="op">+</span></span>
<span id="cb259-9"><a href="linear-models.html#cb259-9"></a><span class="st">  </span><span class="kw">scale_fill_viridis_c</span>() <span class="op">+</span></span>
<span id="cb259-10"><a href="linear-models.html#cb259-10"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu[samples]),</span>
<span id="cb259-11"><a href="linear-models.html#cb259-11"></a>       <span class="dt">y =</span> <span class="kw">expression</span>(sigma[samples])) <span class="op">+</span></span>
<span id="cb259-12"><a href="linear-models.html#cb259-12"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-36-1.png" width="384" /></p>
<p>Behold the updated densities.</p>
<div class="sourceCode" id="cb260"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb260-1"><a href="linear-models.html#cb260-1"></a>d_grid_samples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb260-2"><a href="linear-models.html#cb260-2"></a><span class="st">  </span><span class="kw">select</span>(mu, sigma) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb260-3"><a href="linear-models.html#cb260-3"></a><span class="st">  </span><span class="kw">gather</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb260-4"><a href="linear-models.html#cb260-4"></a></span>
<span id="cb260-5"><a href="linear-models.html#cb260-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb260-6"><a href="linear-models.html#cb260-6"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">fill =</span> <span class="st">&quot;grey33&quot;</span>, <span class="dt">size =</span> <span class="dv">0</span>) <span class="op">+</span></span>
<span id="cb260-7"><a href="linear-models.html#cb260-7"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb260-8"><a href="linear-models.html#cb260-8"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb260-9"><a href="linear-models.html#cb260-9"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></span>
<span id="cb260-10"><a href="linear-models.html#cb260-10"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="op">~</span>key, <span class="dt">scales =</span> <span class="st">&quot;free&quot;</span>, <span class="dt">labeller =</span> label_parsed)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-37-1.png" width="576" /></p>
<p>That <code>labeller = label_parsed</code> bit in the <code>facet_wrap()</code> function is what converted our subplot strip labels into Greek. Anyway, <span class="math inline">\(\sigma\)</span> is not so Gaussian with that small <span class="math inline">\(n\)</span>.</p>
<p>This is the point in the project where we hop off the grid-approximation train. On the one hand, I think this is a great idea. Most of y’all reading this will never use grid approximation in a real-world applied data analysis. On the other hand, there is some pedagogical utility in practicing with it. It can help you grasp what it is we’re dong when we apply Bayes’ theorem. If you’d like more practice, check out the first several chapters in John Kruschke’s <span class="citation">(<a href="#ref-kruschkeDoingBayesianData2015" role="doc-biblioref">2015</a>)</span> <a href="https://sites.google.com/site/doingbayesiandataanalysis/">textbook</a> and the corresponding chapters in my <span class="citation">(<a href="#ref-kurzDoingBayesianData2020" role="doc-biblioref">2020</a><a href="#ref-kurzDoingBayesianData2020" role="doc-biblioref">a</a>)</span> <a href="https://bookdown.org/content/3686/">ebook</a> translating it into <strong>brms</strong> and <strong>tidyverse</strong>.</p>
</div>
</div>
<div id="fitting-the-model-with-map-brm." class="section level3">
<h3><span class="header-section-number">4.3.5</span> Fitting the model with <del><code>map</code></del> <code>brm()</code>.</h3>
<p>We won’t actually use <code>rethinking::map()</code>–which you should not conflate with <code>purrr::map()</code>–, but will jump straight to the primary brms modeling function, <code>brm()</code>. In the text, McElreath indexed his models with names like <code>m4.1</code>. I will largely follow that convention, but will replace the <em>m</em> with a <em>b</em> to stand for the brms package. Plus, once in a blue moon we will actually use the rethinking package to fit a model in order to contrast it to one fit with brms. On those occasions, we will index them using the <em>m</em> prefix. Here’s the first model with <code>brm()</code>.</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="linear-models.html#cb261-1"></a>b4<span class="fl">.1</span> &lt;-<span class="st"> </span></span>
<span id="cb261-2"><a href="linear-models.html#cb261-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2, </span>
<span id="cb261-3"><a href="linear-models.html#cb261-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb261-4"><a href="linear-models.html#cb261-4"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb261-5"><a href="linear-models.html#cb261-5"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">20</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb261-6"><a href="linear-models.html#cb261-6"></a>                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb261-7"><a href="linear-models.html#cb261-7"></a>      <span class="dt">iter =</span> <span class="dv">31000</span>, <span class="dt">warmup =</span> <span class="dv">30000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb261-8"><a href="linear-models.html#cb261-8"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb261-9"><a href="linear-models.html#cb261-9"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.01&quot;</span>)</span></code></pre></div>
<p>McElreath’s uniform prior for <span class="math inline">\(\sigma\)</span> was rough on brms. It took an unusually-large number of warmup iterations before the chains sampled properly. As McElreath covered in <a href="markov-chain-monte-carlo.html#estimation.">Chapter 8</a>, Hamiltonian Monte Carlo (HMC) tends to work better when you default to a half Cauchy for <span class="math inline">\(\sigma\)</span>. We can do that like this.</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="linear-models.html#cb262-1"></a>b4<span class="fl">.1</span>_hc &lt;-<span class="st"> </span></span>
<span id="cb262-2"><a href="linear-models.html#cb262-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2, <span class="dt">family =</span> gaussian,</span>
<span id="cb262-3"><a href="linear-models.html#cb262-3"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb262-4"><a href="linear-models.html#cb262-4"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">20</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb262-5"><a href="linear-models.html#cb262-5"></a>                <span class="co"># the magic lives here</span></span>
<span id="cb262-6"><a href="linear-models.html#cb262-6"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb262-7"><a href="linear-models.html#cb262-7"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb262-8"><a href="linear-models.html#cb262-8"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb262-9"><a href="linear-models.html#cb262-9"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.01_hc&quot;</span>)</span></code></pre></div>
<p>This leads to an important point. After running model fit with HMC, it’s a good idea to inspect the chains. As we’ll see, McElreath coverd this in <a href="markov-chain-monte-carlo.html#checking-the-chain.">Chapter 8</a>. Here’s a typical way to do so in brms.</p>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="linear-models.html#cb263-1"></a><span class="kw">plot</span>(b4<span class="fl">.1</span>_hc) </span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-38-1.png" width="576" /></p>
<p>If you want detailed diagnostics for the HMC chains, execute <code>launch_shinystan(b4.1)</code>. It’ll keep you busy for a while. But anyway, the chains look good. We can reasonably trust the results.</p>
<p>Here’s how to get the model summary of our <code>brm()</code> object.</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="linear-models.html#cb264-1"></a><span class="kw">print</span>(b4<span class="fl">.1</span>_hc)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: height ~ 1 
##    Data: d2 (Number of observations: 352) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   154.61      0.41   153.81   155.40 1.00     3277     2424
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     7.74      0.29     7.21     8.34 1.00     3525     2627
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>The <code>summary()</code> function works in a similar way. You can also get a <a href="https://cran.r-project.org/package=rstan/vignettes/rstan.html">Stan-like summary</a> like this.</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="linear-models.html#cb266-1"></a>b4<span class="fl">.1</span>_hc<span class="op">$</span>fit</span></code></pre></div>
<pre><code>## Inference for Stan model: b17964b0f1809ae4f6a6418751eebc6f.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##                 mean se_mean   sd     2.5%      25%      50%      75%    97.5% n_eff Rhat
## b_Intercept   154.61    0.01 0.41   153.81   154.34   154.61   154.88   155.40  3247    1
## sigma           7.74    0.00 0.29     7.21     7.54     7.74     7.93     8.34  3500    1
## lp__        -1227.49    0.02 0.95 -1230.00 -1227.88 -1227.21 -1226.81 -1226.54  1743    1
## 
## Samples were drawn using NUTS(diag_e) at Sun Oct  4 10:54:16 2020.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>Whereas rethinking defaults to 89% intervals, using <code>print()</code> or <code>summary()</code> with brms models defaults to 95% intervals. Unless otherwise specified, I will stick with 95% intervals throughout. However, if you really want those 89% intervals, an easy way is with the <code>prob</code> argument within <code>brms::summary()</code> or <code>brms::print()</code>.</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="linear-models.html#cb268-1"></a><span class="kw">summary</span>(b4<span class="fl">.1</span>_hc, <span class="dt">prob =</span> <span class="fl">.89</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: height ~ 1 
##    Data: d2 (Number of observations: 352) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS
## Intercept   154.61      0.41   153.96   155.24 1.00     3277     2424
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-89% CI u-89% CI Rhat Bulk_ESS Tail_ESS
## sigma     7.74      0.29     7.29     8.23 1.00     3525     2627
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Anyways, here’s how to fit the model with the shockingly-narrow prior on <span class="math inline">\(\mu\)</span>.</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="linear-models.html#cb270-1"></a>b4<span class="fl">.2</span> &lt;-<span class="st"> </span></span>
<span id="cb270-2"><a href="linear-models.html#cb270-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2, <span class="dt">family =</span> gaussian,</span>
<span id="cb270-3"><a href="linear-models.html#cb270-3"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span>,</span>
<span id="cb270-4"><a href="linear-models.html#cb270-4"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="fl">0.1</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb270-5"><a href="linear-models.html#cb270-5"></a>                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb270-6"><a href="linear-models.html#cb270-6"></a>      <span class="dt">iter =</span> <span class="dv">3000</span>, <span class="dt">warmup =</span> <span class="dv">2000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb270-7"><a href="linear-models.html#cb270-7"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb270-8"><a href="linear-models.html#cb270-8"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.02&quot;</span>)</span></code></pre></div>
<p>Check the chains.</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="linear-models.html#cb271-1"></a><span class="kw">plot</span>(b4<span class="fl">.2</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-42-1.png" width="576" /></p>
<p>I had to increase the <code>warmup</code> due to convergence issues. After doing so, everything looks to be on the up and up. The chains look great. Again, we will learn more about these technical details in <a href="markov-chain-monte-carlo.html#checking-the-chain.">Chapter 8</a>.</p>
<p>Here’s the model <code>summary()</code>.</p>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="linear-models.html#cb272-1"></a><span class="kw">summary</span>(b4<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: height ~ 1 
##    Data: d2 (Number of observations: 352) 
## Samples: 4 chains, each with iter = 3000; warmup = 2000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept   177.87      0.10   177.67   178.06 1.00     3860     2504
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma    24.66      0.93    22.91    26.52 1.00     1512     1443
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Subsetting the <code>summary()</code> output with <code>$fixed</code> provides a convenient way to compare the <code>Intercept</code> summaries between <code>b4.1_hc</code> and <code>b4.2</code>.</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="linear-models.html#cb274-1"></a><span class="kw">summary</span>(b4<span class="fl">.1</span>_hc)<span class="op">$</span>fixed</span></code></pre></div>
<pre><code>##           Estimate Est.Error l-95% CI u-95% CI     Rhat Bulk_ESS Tail_ESS
## Intercept 154.6076 0.4076344 153.8064 155.3959 1.000933     3277     2424</code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="linear-models.html#cb276-1"></a><span class="kw">summary</span>(b4<span class="fl">.2</span>)<span class="op">$</span>fixed</span></code></pre></div>
<pre><code>##           Estimate  Est.Error l-95% CI u-95% CI      Rhat Bulk_ESS Tail_ESS
## Intercept 177.8665 0.09898651 177.6732 178.0592 0.9999747     3860     2504</code></pre>
</div>
<div id="sampling-from-a-map-brm-fit." class="section level3">
<h3><span class="header-section-number">4.3.6</span> Sampling from a <del><code>map</code></del> <code>brm()</code> fit.</h3>
<p>brms doesn’t seem to have a convenience function that works the way <code>vcov()</code> does for rethinking.</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="linear-models.html#cb278-1"></a><span class="kw">vcov</span>(b4<span class="fl">.1</span>_hc)</span></code></pre></div>
<pre><code>##           Intercept
## Intercept 0.1661658</code></pre>
<p>This only returned the first element in the matrix it did for rethinking. That is, it appears the <code>brms::vcov()</code> function only returns the variance/covariance matrix for the single-level <span class="math inline">\(\beta\)</span> parameters (i.e., those used to model <span class="math inline">\(\mu\)</span>).</p>
<p>However, if you really wanted this information, you could get it after putting the HMC chains in a data frame. We do that with the <code>posterior_samples()</code>, which we’ll be using a lot of as we go along.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="linear-models.html#cb280-1"></a>post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b4<span class="fl">.1</span>_hc)</span>
<span id="cb280-2"><a href="linear-models.html#cb280-2"></a></span>
<span id="cb280-3"><a href="linear-models.html#cb280-3"></a><span class="kw">head</span>(post)</span></code></pre></div>
<pre><code>##   b_Intercept    sigma      lp__
## 1    154.6786 8.051124 -1227.133
## 2    155.1678 7.460777 -1227.938
## 3    154.8059 7.492012 -1226.967
## 4    154.5193 8.035891 -1227.089
## 5    154.8931 7.316433 -1227.847
## 6    155.1126 7.900020 -1227.420</code></pre>
<p>Now <code>select()</code> the columns containing the draws from the desired parameters and feed them into <code>cov()</code>.</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="linear-models.html#cb282-1"></a><span class="kw">select</span>(post, b_Intercept<span class="op">:</span>sigma) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb282-2"><a href="linear-models.html#cb282-2"></a><span class="st">  </span><span class="kw">cov</span>()</span></code></pre></div>
<pre><code>##               b_Intercept         sigma
## b_Intercept  0.1661658018 -0.0007004767
## sigma       -0.0007004767  0.0832359724</code></pre>
<p>That was “(1) a vector of variances for the parameters and (2) a correlation matrix” for them (p. 90). Here are just the variances (i.e., the diagonal elements) and the correlation matrix.</p>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="linear-models.html#cb284-1"></a><span class="co"># variances</span></span>
<span id="cb284-2"><a href="linear-models.html#cb284-2"></a><span class="kw">select</span>(post, b_Intercept<span class="op">:</span>sigma) <span class="op">%&gt;%</span></span>
<span id="cb284-3"><a href="linear-models.html#cb284-3"></a><span class="st">  </span><span class="kw">cov</span>() <span class="op">%&gt;%</span></span>
<span id="cb284-4"><a href="linear-models.html#cb284-4"></a><span class="st">  </span><span class="kw">diag</span>()</span></code></pre></div>
<pre><code>## b_Intercept       sigma 
##  0.16616580  0.08323597</code></pre>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="linear-models.html#cb286-1"></a><span class="co"># correlation</span></span>
<span id="cb286-2"><a href="linear-models.html#cb286-2"></a>post <span class="op">%&gt;%</span></span>
<span id="cb286-3"><a href="linear-models.html#cb286-3"></a><span class="kw">select</span>(b_Intercept, sigma) <span class="op">%&gt;%</span></span>
<span id="cb286-4"><a href="linear-models.html#cb286-4"></a><span class="st">  </span><span class="kw">cor</span>()</span></code></pre></div>
<pre><code>##              b_Intercept        sigma
## b_Intercept  1.000000000 -0.005956173
## sigma       -0.005956173  1.000000000</code></pre>
<p>With our <code>post &lt;- posterior_samples(b4.1_hc)</code> code from a few lines above, we’ve already done the brms version of what McElreath did with <code>extract.samples()</code> on page 90. However, what happened under the hood was different. Whereas rethinking used the <code>mvnorm()</code> function from the <a href="https://cran.r-project.org/package=MASS">MASS package</a> <span class="citation">(Ripley, <a href="#ref-R-MASS" role="doc-biblioref">2019</a>; Venables &amp; Ripley, <a href="#ref-MASS2002" role="doc-biblioref">2002</a>)</span>, in brms we just extracted the iterations of the HMC chains and put them in a data frame.</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="linear-models.html#cb288-1"></a><span class="kw">str</span>(post)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    4000 obs. of  3 variables:
##  $ b_Intercept: num  155 155 155 155 155 ...
##  $ sigma      : num  8.05 7.46 7.49 8.04 7.32 ...
##  $ lp__       : num  -1227 -1228 -1227 -1227 -1228 ...</code></pre>
<p>Notice how our data frame, <code>post</code>, includes a third vector named <code>lp__</code>. That’s the log posterior. For more information on the log posterior, see the <a href="https://CRAN.R-project.org/package=brms/brms.pdf">brms reference manual</a> <span class="citation">(Bürkner, <a href="#ref-brms2020RM" role="doc-biblioref">2020</a><a href="#ref-brms2020RM" role="doc-biblioref">b</a>)</span>, the “The Log-Posterior (function and gradient)” section of the Stan Development Team’s <span class="citation">(<a href="#ref-standevelopmentteamRStanInterfaceStan2020" role="doc-biblioref">2020</a><a href="#ref-standevelopmentteamRStanInterfaceStan2020" role="doc-biblioref">b</a>)</span> <a href="https://cran.r-project.org/package=rstan/vignettes/rstan.html#the-log-posterior-function-and-gradient"><em>RStan: the R interface to Stan</em></a>, or <a href="https://twitter.com/smartin2018">Stephen Martin</a>’s <a href="https://discourse.mc-stan.org/t/basic-question-what-is-lp-in-posterior-samples-of-a-brms-regression/17567/2?u=solomon">nice explanation</a> on the Stan Forums. The log posterior will largely be outside of our focus in this project.</p>
<p>The <code>summary()</code> function doesn’t work for brms posterior data frames quite the way <code>precis()</code> does for posterior data frames from the rethinking package. E.g.,</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="linear-models.html#cb290-1"></a><span class="kw">summary</span>(post[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>])</span></code></pre></div>
<pre><code>##   b_Intercept        sigma      
##  Min.   :152.8   Min.   :6.838  
##  1st Qu.:154.3   1st Qu.:7.537  
##  Median :154.6   Median :7.738  
##  Mean   :154.6   Mean   :7.743  
##  3rd Qu.:154.9   3rd Qu.:7.932  
##  Max.   :156.1   Max.   :8.832</code></pre>
<p>Here’s one option using the transpose of a <code>quantile()</code> call nested within <code>apply()</code>, which is a very general function you can learn more about <a href="https://www.datacamp.com/community/tutorials/r-tutorial-apply-family#gs.f7fyw2s">here</a> or <a href="https://www.r-bloggers.com/r-tutorial-on-the-apply-family-of-functions/">here</a>.</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="linear-models.html#cb292-1"></a><span class="kw">t</span>(<span class="kw">apply</span>(post[, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>], <span class="dv">2</span>, quantile, <span class="dt">probs =</span> <span class="kw">c</span>(.<span class="dv">5</span>, <span class="fl">.025</span>, <span class="fl">.75</span>)))</span></code></pre></div>
<pre><code>##                    50%       2.5%        75%
## b_Intercept 154.605262 153.806385 154.881238
## sigma         7.738411   7.205024   7.931603</code></pre>
<p>The base R code is compact, but somewhat opaque. Here’s how to do something similar with more explicit tidyverse code.</p>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="linear-models.html#cb294-1"></a>post <span class="op">%&gt;%</span></span>
<span id="cb294-2"><a href="linear-models.html#cb294-2"></a><span class="st">  </span><span class="kw">select</span>(sigma<span class="op">:</span>b_Intercept) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb294-3"><a href="linear-models.html#cb294-3"></a><span class="st">  </span><span class="kw">gather</span>(parameter) <span class="op">%&gt;%</span></span>
<span id="cb294-4"><a href="linear-models.html#cb294-4"></a><span class="st">  </span><span class="kw">group_by</span>(parameter) <span class="op">%&gt;%</span></span>
<span id="cb294-5"><a href="linear-models.html#cb294-5"></a><span class="st">  </span><span class="kw">summarise</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(value),</span>
<span id="cb294-6"><a href="linear-models.html#cb294-6"></a>            <span class="dt">SD   =</span> <span class="kw">sd</span>(value),</span>
<span id="cb294-7"><a href="linear-models.html#cb294-7"></a>            <span class="st">`</span><span class="dt">2.5_percentile</span><span class="st">`</span>  =<span class="st"> </span><span class="kw">quantile</span>(value, <span class="dt">probs =</span> <span class="fl">.025</span>),</span>
<span id="cb294-8"><a href="linear-models.html#cb294-8"></a>            <span class="st">`</span><span class="dt">97.5_percentile</span><span class="st">`</span> =<span class="st"> </span><span class="kw">quantile</span>(value, <span class="dt">probs =</span> <span class="fl">.975</span>)) <span class="op">%&gt;%</span></span>
<span id="cb294-9"><a href="linear-models.html#cb294-9"></a><span class="st">  </span><span class="kw">mutate_if</span>(is.numeric, round, <span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 5
##   parameter     mean    SD `2.5_percentile` `97.5_percentile`
##   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;            &lt;dbl&gt;             &lt;dbl&gt;
## 1 b_Intercept 155.   0.41            154.              155.  
## 2 sigma         7.74 0.290             7.21              8.34</code></pre>
<p>You can always get pretty similar information by just putting the <code>brm()</code> fit object into <code>posterior_summary()</code>.</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="linear-models.html#cb296-1"></a><span class="kw">posterior_summary</span>(b4<span class="fl">.1</span>_hc)</span></code></pre></div>
<pre><code>##                 Estimate Est.Error         Q2.5        Q97.5
## b_Intercept   154.607579 0.4076344   153.806385   155.395943
## sigma           7.743143 0.2885065     7.205024     8.335414
## lp__        -1227.492023 0.9523241 -1230.000431 -1226.541784</code></pre>
<p>And if you’re willing to drop the posterior <span class="math inline">\(SD\)</span>s, you can use <code>tidybayes::mean_qi()</code>, too.</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="linear-models.html#cb298-1"></a>post <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb298-2"><a href="linear-models.html#cb298-2"></a><span class="st">  </span><span class="kw">select</span>(sigma<span class="op">:</span>b_Intercept) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb298-3"><a href="linear-models.html#cb298-3"></a><span class="st">  </span><span class="kw">gather</span>(parameter) <span class="op">%&gt;%</span></span>
<span id="cb298-4"><a href="linear-models.html#cb298-4"></a><span class="st">  </span><span class="kw">group_by</span>(parameter) <span class="op">%&gt;%</span></span>
<span id="cb298-5"><a href="linear-models.html#cb298-5"></a><span class="st">  </span><span class="kw">mean_qi</span>(value)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 7
##   parameter    value .lower .upper .width .point .interval
##   &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;    
## 1 b_Intercept 155.   154.   155.     0.95 mean   qi       
## 2 sigma         7.74   7.21   8.34   0.95 mean   qi</code></pre>
<div id="overthinking-under-the-hood-with-multivariate-sampling." class="section level4">
<h4><span class="header-section-number">4.3.6.1</span> Overthinking: Under the hood with multivariate sampling.</h4>
<p>Again, <code>brms::posterior_samples()</code> is not the same as <code>rethinking::extract.samples()</code>. Rather than use the <code>MASS::mvnorm()</code>, brms takes the iterations from the HMC chains. McElreath covered all of this in <a href="markov-chain-monte-carlo.html#easy-hmc-map2stan-brm">Chapter 8</a> and we will too. You might also look at the brms <a href="https://cran.r-project.org/package=brms/brms.pdf">reference manual</a> or <a href="https://github.com/paul-buerkner/brms">GitHub page</a> for details. To get documentation in a hurry, you could also just execute <code>?posterior_samples</code>.</p>
</div>
<div id="overthinking-getting-sigma-right." class="section level4">
<h4><span class="header-section-number">4.3.6.2</span> Overthinking: Getting <span class="math inline">\(\sigma\)</span> right.</h4>
<p>There’s no need to fret about this when using brms. With HMC, we are not constraining the posteriors to the multivariate normal distribution. Here’s our posterior density for <span class="math inline">\(\sigma\)</span>.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="linear-models.html#cb300-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> post, </span>
<span id="cb300-2"><a href="linear-models.html#cb300-2"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> sigma)) <span class="op">+</span></span>
<span id="cb300-3"><a href="linear-models.html#cb300-3"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">10</span>, <span class="dt">fill =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span></span>
<span id="cb300-4"><a href="linear-models.html#cb300-4"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb300-5"><a href="linear-models.html#cb300-5"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(sigma)) <span class="op">+</span></span>
<span id="cb300-6"><a href="linear-models.html#cb300-6"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-55-1.png" width="288" /></p>
<p>See? HMC handled the mild skew just fine.</p>
<p>But sometimes you want to actually model <span class="math inline">\(\sigma\)</span>, such as in the case where your variances are systematically heterogeneous. Bürkner calls these kinds of models distributional models, which you can learn more about in his <span class="citation">(<a href="#ref-Bürkner2020Distributional" role="doc-biblioref">2020</a><a href="#ref-Bürkner2020Distributional" role="doc-biblioref">f</a>)</span> vignette <a href="https://cran.r-project.org/package=brms/vignettes/brms_distreg.html"><em>Estimating distributional models with brms</em></a>. As he explained in the vignette, you actually model <span class="math inline">\(\log (\sigma)\)</span> in those instances. If you’re curious, we’ll practice with a model like this in <a href="big-entropy-and-the-generalized-linear-model.html#linking-linear-models-to-distributions.">Chapter 9</a>. Kruschke also covered several models of this kind in his (2015) text, <a href="https://sites.google.com/site/doingbayesiandataanalysis/"><em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em></a>, which I’ve translated into brms and tidyverse code. Check out <a href="https://bookdown.org/content/3686/metric-predicted-variable-on-one-or-two-groups.html#two-groups">Section 16.3</a> for an example of modeling <span class="math inline">\(\log \sigma\)</span> with a grouping variable.</p>
</div>
</div>
</div>
<div id="adding-a-predictor" class="section level2">
<h2><span class="header-section-number">4.4</span> Adding a predictor</h2>
<blockquote>
<p>What we’ve done above is a Gaussian model of height in a population of adults. But it doesn’t really have the usual feel of “regression” to it. Typically, we are interested in modeling how an outcome is related to some predictor variable. And by including a predictor variable in a particular way, we’ll have linear regression. (p. 92)</p>
</blockquote>
<p>Here’s our scatter plot of our predictor <code>weight</code> and our criterion <code>height</code>.</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="linear-models.html#cb301-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> d2, </span>
<span id="cb301-2"><a href="linear-models.html#cb301-2"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb301-3"><a href="linear-models.html#cb301-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb301-4"><a href="linear-models.html#cb301-4"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb301-5"><a href="linear-models.html#cb301-5"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-56-1.png" width="288" /></p>
<blockquote>
<p>There’s obviously a relationship: Knowing a person’s weight helps you predict height.</p>
<p>To make this vague observation into a more precise quantitative model that relates values of <code>weight</code> to plausible values of <code>height</code>, we need some more technology. How do we take our Gaussian model from the previous section and incorporate predictor variables? (p. 92)</p>
</blockquote>
<div id="the-linear-model-strategy." class="section level3">
<h3><span class="header-section-number">4.4.1</span> The linear model strategy.</h3>
<blockquote>
<p>The strategy is to make the parameter for the mean of a Gaussian distribution, <span class="math inline">\(\mu\)</span>, into a linear function of the predictor variable and other, new parameters that we invent. This strategy is often simply called the <strong>linear model</strong>. The linear model strategy instructs the golem to assume that the predictor variable has a perfect constant and additive relationship to the mean of the outcome. The golem then computes the posterior distribution of this constant relationship. (p. 92, <strong>emphasis</strong> in the original)</p>
</blockquote>
<p>Our new univariable model will follow the formula</p>
<p><span class="math display">\[\begin{align*}
h_i    &amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i  &amp; = \alpha + \beta x_i \\
\alpha &amp; \sim \operatorname{Normal}(178, 100) \\
\beta  &amp; \sim \operatorname{Normal}(0, 10) \\
\sigma &amp; \sim \operatorname{Uniform}(0, 50).
\end{align*}\]</span></p>
<div id="likelihood.-1" class="section level4">
<h4><span class="header-section-number">4.4.1.1</span> Likelihood.</h4>
<p>The likelihood for our model is <span class="math inline">\(h_i \sim \operatorname{Normal}(\mu_i, \sigma)\)</span>.</p>
</div>
<div id="linear-model." class="section level4">
<h4><span class="header-section-number">4.4.1.2</span> Linear model.</h4>
<p>Our linear model is <span class="math inline">\(\mu_i = \alpha + \beta x_i\)</span>. The thing we’re modeling is <span class="math inline">\(\mu_i\)</span>, the conditional mean of our variable <span class="math inline">\(h_i\)</span>, and we’re modeling it with two parameters:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span> (i.e., the intercept) and</li>
<li><span class="math inline">\(\beta\)</span> (i.e., the slope).</li>
</ul>
</div>
<div id="priors." class="section level4">
<h4><span class="header-section-number">4.4.1.3</span> Priors.</h4>
<p>Our univariable model has three priors:</p>
<p><span class="math display">\[\begin{align*}
\alpha &amp; \sim \operatorname{Normal}(178, 100), \\
\beta  &amp; \sim \operatorname{Normal}(0, 10), \; \text{and} \\
\sigma &amp; \sim \operatorname{Uniform}(0, 50).
\end{align*}\]</span></p>
<p>McElreath recommended we plot them. If you recall, we’ve already plotted <span class="math inline">\(\operatorname{Normal}(178, 100)\)</span> and <span class="math inline">\(\operatorname{Uniform}(0, 50)\)</span>. Here’s what the prior for our new <span class="math inline">\(\beta\)</span> parameter looks like.</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="linear-models.html#cb302-1"></a><span class="kw">tibble</span>(<span class="dt">beta =</span> <span class="dv">-40</span><span class="op">:</span><span class="dv">40</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb302-2"><a href="linear-models.html#cb302-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">density =</span> <span class="kw">dnorm</span>(beta, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">10</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb302-3"><a href="linear-models.html#cb302-3"></a><span class="st">  </span></span>
<span id="cb302-4"><a href="linear-models.html#cb302-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> beta, <span class="dt">ymin =</span> <span class="dv">0</span>, <span class="dt">ymax =</span> density)) <span class="op">+</span></span>
<span id="cb302-5"><a href="linear-models.html#cb302-5"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb302-6"><a href="linear-models.html#cb302-6"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb302-7"><a href="linear-models.html#cb302-7"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(beta)) <span class="op">+</span></span>
<span id="cb302-8"><a href="linear-models.html#cb302-8"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-57-1.png" width="288" /></p>
</div>
</div>
<div id="fitting-the-model." class="section level3">
<h3><span class="header-section-number">4.4.2</span> Fitting the model.</h3>
<p>If you look closely at the statistical model and corresponding rethinking code at the bottom of page 95, you’ll see they contradict each other on the prior for <span class="math inline">\(\alpha\)</span>. Though we didn’t note it at the time, there was similar contradiction in the middle of page 87 for <code>m4.1</code>. McElreath acknowledged this in his <a href="https://github.com/rmcelreath/rethinking/blob/master/ERRATA.md">Errata</a>, where he indicated the intended prior was <span class="math inline">\(\alpha \sim \operatorname{Normal}(178, 100)\)</span>. We will use that prior here, too.</p>
<p>Unlike with the rethinking package, our <code>brms::brm()</code> syntax won’t perfectly mirror the formal statistical notation. But here are the analogues to the exposition at the bottom of page 95 (with the corrected <span class="math inline">\(\alpha\)</span> prior).</p>
<ul>
<li><span class="math inline">\(h_i \sim \operatorname{Normal}(\mu_i, \sigma)\)</span>: <code>family = gaussian</code></li>
<li><span class="math inline">\(\mu_i = \alpha + \beta x_i\)</span>: <code>height ~ 1 + weight</code></li>
<li><span class="math inline">\(\alpha \sim \operatorname{Normal}(178, 100)\)</span>: <code>prior(normal(178, 100), class = Intercept</code></li>
<li><span class="math inline">\(\beta \sim \operatorname{Normal}(0, 10)\)</span>: <code>prior(normal(0, 10), class = b)</code></li>
<li><span class="math inline">\(\sigma \sim \operatorname{Uniform}(0, 50)\)</span>: <code>prior(uniform(0, 50), class = sigma)</code></li>
</ul>
<p>Thus, to add a predictor you just the <code>+</code> operator in the model <code>formula</code>.</p>
<div class="sourceCode" id="cb303"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb303-1"><a href="linear-models.html#cb303-1"></a>b4<span class="fl">.3</span> &lt;-<span class="st"> </span></span>
<span id="cb303-2"><a href="linear-models.html#cb303-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2, </span>
<span id="cb303-3"><a href="linear-models.html#cb303-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb303-4"><a href="linear-models.html#cb303-4"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight,</span>
<span id="cb303-5"><a href="linear-models.html#cb303-5"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb303-6"><a href="linear-models.html#cb303-6"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb303-7"><a href="linear-models.html#cb303-7"></a>                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb303-8"><a href="linear-models.html#cb303-8"></a>      <span class="dt">iter =</span> <span class="dv">31000</span>, <span class="dt">warmup =</span> <span class="dv">30000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb303-9"><a href="linear-models.html#cb303-9"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb303-10"><a href="linear-models.html#cb303-10"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.03&quot;</span>)</span></code></pre></div>
<p>This was another example of how using a uniform prior for <span class="math inline">\(\sigma\)</span> required we use an unusually large number of <code>warmup</code> iterations before the HMC chains converged on the posterior. Change the prior to <code>cauchy(0, 1)</code> and the chains converge with no problem, resulting in much better effective samples, too. Here are the trace plots.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="linear-models.html#cb304-1"></a><span class="kw">plot</span>(b4<span class="fl">.3</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-58-1.png" width="576" /></p>
<div id="overthinking-embedding-linear-models." class="section level4">
<h4><span class="header-section-number">4.4.2.1</span> Overthinking: Embedding linear models.</h4>
<p>I’m not aware that you can embed the linear model within the likelihood function within <code>brms::brm()</code> the way McElreath did in R code 4.39. However, it can be pedagogically useful to write out the statistical model that way:</p>
<p><span class="math display">\[\begin{align*}
h_i    &amp; \sim \operatorname{Normal}(\alpha + \beta x_i, \sigma) \\
\alpha &amp; \sim \operatorname{Normal}(178, 100) \\
\beta  &amp; \sim \operatorname{Normal}(0, 10) \\
\sigma &amp; \sim \operatorname{Uniform}(0, 50)
\end{align*}\]</span></p>
<p><em>Whoah. What? Where did</em> <span class="math inline">\(\mu_i\)</span> <em>go?</em> It’s still there. We just expressed it as <span class="math inline">\(\alpha + \beta x_i\)</span>.</p>
</div>
</div>
<div id="interpreting-the-model-fit." class="section level3">
<h3><span class="header-section-number">4.4.3</span> Interpreting the model fit.</h3>
<blockquote>
<p>One trouble with statistical models is that they are hard to understand. Once you’ve fit the model, it can only report posterior probabilities. These are the right answer to the question that is the combination of model and data. But it’s your responsibility to process the answer and make sense of it.</p>
<p>There are two broad categories of processing: (1) reading tables and (2) plotting. (p. 97).</p>
</blockquote>
<div id="tables-of-estimates." class="section level4">
<h4><span class="header-section-number">4.4.3.1</span> Tables of estimates.</h4>
<p>With a little <code>[]</code> subsetting we can exclude the log posterior from the <code>posterior_summary()</code> so we can fucus on the parameters.</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="linear-models.html#cb305-1"></a><span class="kw">posterior_summary</span>(b4<span class="fl">.3</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, ]</span></code></pre></div>
<pre><code>##                Estimate  Est.Error        Q2.5       Q97.5
## b_Intercept 113.9024754 1.91749817 110.2883691 117.6347788
## b_weight      0.9044158 0.04222142   0.8216734   0.9840718
## sigma         5.0984167 0.19191445   4.7364937   5.4863232</code></pre>
<p>Again, brms doesn’t have a convenient <code>corr = TRUE</code> argument for <code>plot()</code> or <code>summary()</code>. But you can get that information after putting the chains in a data frame.</p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="linear-models.html#cb307-1"></a><span class="kw">posterior_samples</span>(b4<span class="fl">.3</span>) <span class="op">%&gt;%</span></span>
<span id="cb307-2"><a href="linear-models.html#cb307-2"></a><span class="st">  </span><span class="kw">select</span>(b_Intercept<span class="op">:</span>sigma) <span class="op">%&gt;%</span></span>
<span id="cb307-3"><a href="linear-models.html#cb307-3"></a><span class="st">  </span><span class="kw">cor</span>() <span class="op">%&gt;%</span></span>
<span id="cb307-4"><a href="linear-models.html#cb307-4"></a><span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##             b_Intercept b_weight sigma
## b_Intercept        1.00    -0.99     0
## b_weight          -0.99     1.00     0
## sigma              0.00     0.00     1</code></pre>
<p>Much like the results from McElreath’s rethinking package, two of the parameters from our model fit with <code>brm()</code> are highly correlated, too. With centering, we can reduce that correlation.</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="linear-models.html#cb309-1"></a>d2 &lt;-<span class="st"> </span></span>
<span id="cb309-2"><a href="linear-models.html#cb309-2"></a><span class="st">  </span>d2 <span class="op">%&gt;%</span></span>
<span id="cb309-3"><a href="linear-models.html#cb309-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">weight_c =</span> weight <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(weight))</span></code></pre></div>
<p>Fit the <code>weight_c</code> model, <code>b4.4</code>.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="linear-models.html#cb310-1"></a>b4<span class="fl">.4</span> &lt;-<span class="st"> </span></span>
<span id="cb310-2"><a href="linear-models.html#cb310-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2, </span>
<span id="cb310-3"><a href="linear-models.html#cb310-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb310-4"><a href="linear-models.html#cb310-4"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight_c,</span>
<span id="cb310-5"><a href="linear-models.html#cb310-5"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb310-6"><a href="linear-models.html#cb310-6"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb310-7"><a href="linear-models.html#cb310-7"></a>                <span class="kw">prior</span>(<span class="kw">uniform</span>(<span class="dv">0</span>, <span class="dv">50</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb310-8"><a href="linear-models.html#cb310-8"></a>      <span class="dt">iter =</span> <span class="dv">36000</span>, <span class="dt">warmup =</span> <span class="dv">35000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb310-9"><a href="linear-models.html#cb310-9"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb310-10"><a href="linear-models.html#cb310-10"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.04&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="linear-models.html#cb311-1"></a><span class="kw">plot</span>(b4<span class="fl">.4</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-62-1.png" width="576" /></p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="linear-models.html#cb312-1"></a><span class="kw">posterior_summary</span>(b4<span class="fl">.4</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, ]</span></code></pre></div>
<pre><code>##                Estimate  Est.Error        Q2.5       Q97.5
## b_Intercept 154.5957422 0.27017204 154.0632266 155.1330891
## b_weight_c    0.9073481 0.04209104   0.8267917   0.9923301
## sigma         5.0982318 0.18612897   4.7373528   5.4640444</code></pre>
<p>Like before, the uniform prior required extensive <code>warmup</code> iterations to produce a good posterior. This is easily fixed using a half Cauchy prior, instead. Anyways, the effective samples improved. Here’s the parameter correlation info.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="linear-models.html#cb314-1"></a><span class="kw">posterior_samples</span>(b4<span class="fl">.4</span>) <span class="op">%&gt;%</span></span>
<span id="cb314-2"><a href="linear-models.html#cb314-2"></a><span class="st">  </span><span class="kw">select</span>(b_Intercept<span class="op">:</span>sigma) <span class="op">%&gt;%</span></span>
<span id="cb314-3"><a href="linear-models.html#cb314-3"></a><span class="st">  </span><span class="kw">cor</span>() <span class="op">%&gt;%</span></span>
<span id="cb314-4"><a href="linear-models.html#cb314-4"></a><span class="st">  </span><span class="kw">round</span>(<span class="dt">digits =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##             b_Intercept b_weight_c sigma
## b_Intercept        1.00      -0.03  0.00
## b_weight_c        -0.03       1.00  0.02
## sigma              0.00       0.02  1.00</code></pre>
<p>See? Now all the correlations are quite low. If you prefer a visual approach, try executing <code>pairs(b4.4)</code>.</p>
<p>Amidst all this talk about tables, I haven’t actually shown how to put these parameter summaries in a table. Here’s an example of how you might convert the <code>posterior_summary()</code> output into a summary table roughly following APA style.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="linear-models.html#cb316-1"></a><span class="kw">posterior_summary</span>(b4<span class="fl">.4</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, ] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb316-2"><a href="linear-models.html#cb316-2"></a><span class="st">  </span><span class="kw">data.frame</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb316-3"><a href="linear-models.html#cb316-3"></a><span class="st">  </span><span class="kw">rownames_to_column</span>(<span class="st">&quot;parameter&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb316-4"><a href="linear-models.html#cb316-4"></a><span class="st">  </span><span class="kw">mutate_if</span>(is.double, round, <span class="dt">digits =</span> <span class="dv">2</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb316-5"><a href="linear-models.html#cb316-5"></a><span class="st">  </span><span class="kw">rename</span>(<span class="dt">mean =</span> Estimate,</span>
<span id="cb316-6"><a href="linear-models.html#cb316-6"></a>         <span class="dt">sd   =</span> Est.Error) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb316-7"><a href="linear-models.html#cb316-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="st">`</span><span class="dt">95% CI</span><span class="st">`</span> =<span class="st"> </span><span class="kw">str_c</span>(<span class="st">&quot;[&quot;</span>, Q2<span class="fl">.5</span>, <span class="st">&quot;, &quot;</span>, Q97<span class="fl">.5</span>, <span class="st">&quot;]&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb316-8"><a href="linear-models.html#cb316-8"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span><span class="kw">starts_with</span>(<span class="st">&quot;Q&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb316-9"><a href="linear-models.html#cb316-9"></a><span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left">parameter</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="left">95% CI</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">b_Intercept</td>
<td align="right">154.60</td>
<td align="right">0.27</td>
<td align="left">[154.06, 155.13]</td>
</tr>
<tr class="even">
<td align="left">b_weight_c</td>
<td align="right">0.91</td>
<td align="right">0.04</td>
<td align="left">[0.83, 0.99]</td>
</tr>
<tr class="odd">
<td align="left">sigma</td>
<td align="right">5.10</td>
<td align="right">0.19</td>
<td align="left">[4.74, 5.46]</td>
</tr>
</tbody>
</table>
<p>This, of course, is just one way to present the summary information. Hopefully it’s a useful start.</p>
</div>
<div id="plotting-posterior-inference-against-the-data." class="section level4">
<h4><span class="header-section-number">4.4.3.2</span> Plotting posterior inference against the data.</h4>
<blockquote>
<p>In truth, tables of estimates are usually insufficient for understanding the information contained in the posterior distribution. It’s almost always much more useful to plot the posterior inference against the data. Not only does plotting help in interpreting the posterior, bit it also provides an informal check on model assumptions. (p. 100)</p>
</blockquote>
<p>Here is the code for Figure 4.4. Note our use of the <code>fixef()</code> function.</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="linear-models.html#cb317-1"></a>d2 <span class="op">%&gt;%</span></span>
<span id="cb317-2"><a href="linear-models.html#cb317-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb317-3"><a href="linear-models.html#cb317-3"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="kw">fixef</span>(b4<span class="fl">.3</span>)[<span class="dv">1</span>], </span>
<span id="cb317-4"><a href="linear-models.html#cb317-4"></a>              <span class="dt">slope     =</span> <span class="kw">fixef</span>(b4<span class="fl">.3</span>)[<span class="dv">2</span>]) <span class="op">+</span></span>
<span id="cb317-5"><a href="linear-models.html#cb317-5"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb317-6"><a href="linear-models.html#cb317-6"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span></span>
<span id="cb317-7"><a href="linear-models.html#cb317-7"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-65-1.png" width="288" /></p>
<p>In the brms reference manual, Bürkner described the job of the<code>fixef()</code> function as “extract[ing] the population-level (‘fixed’) effects from a brmsfit object”. If you’re new to multilevel models, it might not be clear what he meant by “population-level” or “fixed” effects. Don’t worry. That’ll all become clear starting around <a href="multilevel-models.html#multilevel-models">Chapter 12</a>. In the meantime, just think of them as the typical regression parameters, minus <span class="math inline">\(\sigma\)</span>.</p>
</div>
<div id="adding-uncertainty-around-the-mean." class="section level4">
<h4><span class="header-section-number">4.4.3.3</span> Adding uncertainty around the mean.</h4>
<p>Be default, we extract all the posterior iterations with <code>posterior_samples()</code>. Because we had 4,000 posterior draws, our output will contain 4,000 rows.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="linear-models.html#cb318-1"></a>post &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b4<span class="fl">.3</span>)</span>
<span id="cb318-2"><a href="linear-models.html#cb318-2"></a></span>
<span id="cb318-3"><a href="linear-models.html#cb318-3"></a>post <span class="op">%&gt;%</span></span>
<span id="cb318-4"><a href="linear-models.html#cb318-4"></a><span class="st">  </span><span class="kw">glimpse</span>()</span></code></pre></div>
<pre><code>## Rows: 4,000
## Columns: 4
## $ b_Intercept &lt;dbl&gt; 114.5344, 113.7725, 112.6406, 111.2249, 111.5721, 112.0209, 114.1913, 110.754…
## $ b_weight    &lt;dbl&gt; 0.8930082, 0.9112283, 0.9208557, 0.9729205, 0.9507940, 0.9497624, 0.8947274, …
## $ sigma       &lt;dbl&gt; 5.291571, 5.086167, 5.250765, 5.015392, 4.868523, 5.015356, 5.211914, 4.92507…
## $ lp__        &lt;dbl&gt; -1082.770, -1082.289, -1084.295, -1084.593, -1083.829, -1082.881, -1082.484, …</code></pre>
<blockquote>
<p>Each row is a correlated random sample from the point posterior of all three parameters, using the covariances provided by [<code>cov(posterior_samples(b4.4)</code>]. The paired values of [<code>b_Intercept</code>] and [<code>b_weight</code>] on each row define the line. The average of very many of these lines is the MAP line. (p. 101)</p>
</blockquote>
<p>Here are the four models leading up to McElreath’s Figure 4.5. To reduce my computation time, I used a <code>cauchy(0, 1)</code> prior on <span class="math inline">\(\sigma\)</span>. If you are willing to wait for the warmups, switching that out for McElreath’s uniform prior should work fine as well. With the exception of that <span class="math inline">\(\sigma\)</span> prior, these models are all variations on <code>b4.3</code> from above, which we’ll reflect in our naming convention.</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="linear-models.html#cb320-1"></a>n &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb320-2"><a href="linear-models.html#cb320-2"></a></span>
<span id="cb320-3"><a href="linear-models.html#cb320-3"></a>b4<span class="fl">.3</span>_<span class="dv">010</span> &lt;-<span class="st"> </span></span>
<span id="cb320-4"><a href="linear-models.html#cb320-4"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2 <span class="op">%&gt;%</span></span>
<span id="cb320-5"><a href="linear-models.html#cb320-5"></a><span class="st">        </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span>n),  <span class="co"># note our tricky use of `n` and `slice()`</span></span>
<span id="cb320-6"><a href="linear-models.html#cb320-6"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb320-7"><a href="linear-models.html#cb320-7"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight,</span>
<span id="cb320-8"><a href="linear-models.html#cb320-8"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb320-9"><a href="linear-models.html#cb320-9"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb320-10"><a href="linear-models.html#cb320-10"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb320-11"><a href="linear-models.html#cb320-11"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb320-12"><a href="linear-models.html#cb320-12"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb320-13"><a href="linear-models.html#cb320-13"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.03_010&quot;</span>)</span>
<span id="cb320-14"><a href="linear-models.html#cb320-14"></a></span>
<span id="cb320-15"><a href="linear-models.html#cb320-15"></a>n &lt;-<span class="st"> </span><span class="dv">50</span></span>
<span id="cb320-16"><a href="linear-models.html#cb320-16"></a></span>
<span id="cb320-17"><a href="linear-models.html#cb320-17"></a>b4<span class="fl">.3</span>_<span class="dv">050</span> &lt;-<span class="st"> </span></span>
<span id="cb320-18"><a href="linear-models.html#cb320-18"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2 <span class="op">%&gt;%</span></span>
<span id="cb320-19"><a href="linear-models.html#cb320-19"></a><span class="st">        </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span>n), </span>
<span id="cb320-20"><a href="linear-models.html#cb320-20"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb320-21"><a href="linear-models.html#cb320-21"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight,</span>
<span id="cb320-22"><a href="linear-models.html#cb320-22"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb320-23"><a href="linear-models.html#cb320-23"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb320-24"><a href="linear-models.html#cb320-24"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb320-25"><a href="linear-models.html#cb320-25"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb320-26"><a href="linear-models.html#cb320-26"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb320-27"><a href="linear-models.html#cb320-27"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.03_050&quot;</span>)</span>
<span id="cb320-28"><a href="linear-models.html#cb320-28"></a></span>
<span id="cb320-29"><a href="linear-models.html#cb320-29"></a>n &lt;-<span class="st"> </span><span class="dv">150</span></span>
<span id="cb320-30"><a href="linear-models.html#cb320-30"></a></span>
<span id="cb320-31"><a href="linear-models.html#cb320-31"></a>b4<span class="fl">.3</span>_<span class="dv">150</span> &lt;-<span class="st"> </span></span>
<span id="cb320-32"><a href="linear-models.html#cb320-32"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2 <span class="op">%&gt;%</span></span>
<span id="cb320-33"><a href="linear-models.html#cb320-33"></a><span class="st">        </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span>n), </span>
<span id="cb320-34"><a href="linear-models.html#cb320-34"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb320-35"><a href="linear-models.html#cb320-35"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight,</span>
<span id="cb320-36"><a href="linear-models.html#cb320-36"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb320-37"><a href="linear-models.html#cb320-37"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb320-38"><a href="linear-models.html#cb320-38"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb320-39"><a href="linear-models.html#cb320-39"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb320-40"><a href="linear-models.html#cb320-40"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb320-41"><a href="linear-models.html#cb320-41"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.03_150&quot;</span>)</span>
<span id="cb320-42"><a href="linear-models.html#cb320-42"></a></span>
<span id="cb320-43"><a href="linear-models.html#cb320-43"></a>n &lt;-<span class="st"> </span><span class="dv">352</span></span>
<span id="cb320-44"><a href="linear-models.html#cb320-44"></a></span>
<span id="cb320-45"><a href="linear-models.html#cb320-45"></a>b4<span class="fl">.3</span>_<span class="dv">352</span> &lt;-<span class="st"> </span></span>
<span id="cb320-46"><a href="linear-models.html#cb320-46"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d2 <span class="op">%&gt;%</span></span>
<span id="cb320-47"><a href="linear-models.html#cb320-47"></a><span class="st">        </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span>n), </span>
<span id="cb320-48"><a href="linear-models.html#cb320-48"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb320-49"><a href="linear-models.html#cb320-49"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight,</span>
<span id="cb320-50"><a href="linear-models.html#cb320-50"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb320-51"><a href="linear-models.html#cb320-51"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb320-52"><a href="linear-models.html#cb320-52"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb320-53"><a href="linear-models.html#cb320-53"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb320-54"><a href="linear-models.html#cb320-54"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb320-55"><a href="linear-models.html#cb320-55"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.03_352&quot;</span>)</span></code></pre></div>
<p>I’m not going to clutter up the document with all the trace plots and coefficient summaries from these four models. But here’s how to get that information.</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="linear-models.html#cb321-1"></a><span class="kw">plot</span>(b4<span class="fl">.3</span>_<span class="dv">010</span>)</span>
<span id="cb321-2"><a href="linear-models.html#cb321-2"></a><span class="kw">print</span>(b4<span class="fl">.3</span>_<span class="dv">010</span>)</span>
<span id="cb321-3"><a href="linear-models.html#cb321-3"></a></span>
<span id="cb321-4"><a href="linear-models.html#cb321-4"></a><span class="kw">plot</span>(b4<span class="fl">.3</span>_<span class="dv">050</span>)</span>
<span id="cb321-5"><a href="linear-models.html#cb321-5"></a><span class="kw">print</span>(b4<span class="fl">.3</span>_<span class="dv">050</span>)</span>
<span id="cb321-6"><a href="linear-models.html#cb321-6"></a></span>
<span id="cb321-7"><a href="linear-models.html#cb321-7"></a><span class="kw">plot</span>(b4<span class="fl">.3</span>_<span class="dv">150</span>)</span>
<span id="cb321-8"><a href="linear-models.html#cb321-8"></a><span class="kw">print</span>(b4<span class="fl">.3</span>_<span class="dv">150</span>)</span>
<span id="cb321-9"><a href="linear-models.html#cb321-9"></a></span>
<span id="cb321-10"><a href="linear-models.html#cb321-10"></a><span class="kw">plot</span>(b4<span class="fl">.3</span>_<span class="dv">352</span>)</span>
<span id="cb321-11"><a href="linear-models.html#cb321-11"></a><span class="kw">print</span>(b4<span class="fl">.3</span>_<span class="dv">352</span>)</span></code></pre></div>
<p>We’ll need to put the chains of each model into data frames.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="linear-models.html#cb322-1"></a>post010 &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b4<span class="fl">.3</span>_<span class="dv">010</span>)</span>
<span id="cb322-2"><a href="linear-models.html#cb322-2"></a>post050 &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b4<span class="fl">.3</span>_<span class="dv">050</span>)</span>
<span id="cb322-3"><a href="linear-models.html#cb322-3"></a>post150 &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b4<span class="fl">.3</span>_<span class="dv">150</span>)</span>
<span id="cb322-4"><a href="linear-models.html#cb322-4"></a>post352 &lt;-<span class="st"> </span><span class="kw">posterior_samples</span>(b4<span class="fl">.3</span>_<span class="dv">352</span>)</span></code></pre></div>
<p>Here is the code for the four individual plots.</p>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="linear-models.html#cb323-1"></a>p1 &lt;-<span class="st"> </span></span>
<span id="cb323-2"><a href="linear-models.html#cb323-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">data =</span>  d2[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span> , ], </span>
<span id="cb323-3"><a href="linear-models.html#cb323-3"></a>         <span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb323-4"><a href="linear-models.html#cb323-4"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> post010[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">1</span>], </span>
<span id="cb323-5"><a href="linear-models.html#cb323-5"></a>              <span class="dt">slope     =</span> post010[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">2</span>],</span>
<span id="cb323-6"><a href="linear-models.html#cb323-6"></a>              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></span>
<span id="cb323-7"><a href="linear-models.html#cb323-7"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb323-8"><a href="linear-models.html#cb323-8"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d2<span class="op">$</span>weight),</span>
<span id="cb323-9"><a href="linear-models.html#cb323-9"></a>                  <span class="dt">ylim =</span> <span class="kw">range</span>(d2<span class="op">$</span>height)) <span class="op">+</span></span>
<span id="cb323-10"><a href="linear-models.html#cb323-10"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;N = 10&quot;</span>)</span>
<span id="cb323-11"><a href="linear-models.html#cb323-11"></a></span>
<span id="cb323-12"><a href="linear-models.html#cb323-12"></a>p2 &lt;-</span>
<span id="cb323-13"><a href="linear-models.html#cb323-13"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">data =</span>  d2[<span class="dv">1</span><span class="op">:</span><span class="dv">50</span> , ], </span>
<span id="cb323-14"><a href="linear-models.html#cb323-14"></a>         <span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb323-15"><a href="linear-models.html#cb323-15"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> post050[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">1</span>], </span>
<span id="cb323-16"><a href="linear-models.html#cb323-16"></a>              <span class="dt">slope     =</span> post050[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">2</span>],</span>
<span id="cb323-17"><a href="linear-models.html#cb323-17"></a>              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></span>
<span id="cb323-18"><a href="linear-models.html#cb323-18"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb323-19"><a href="linear-models.html#cb323-19"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d2<span class="op">$</span>weight),</span>
<span id="cb323-20"><a href="linear-models.html#cb323-20"></a>                  <span class="dt">ylim =</span> <span class="kw">range</span>(d2<span class="op">$</span>height)) <span class="op">+</span></span>
<span id="cb323-21"><a href="linear-models.html#cb323-21"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;N = 50&quot;</span>)</span>
<span id="cb323-22"><a href="linear-models.html#cb323-22"></a></span>
<span id="cb323-23"><a href="linear-models.html#cb323-23"></a>p3 &lt;-</span>
<span id="cb323-24"><a href="linear-models.html#cb323-24"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">data =</span>  d2[<span class="dv">1</span><span class="op">:</span><span class="dv">150</span> , ], </span>
<span id="cb323-25"><a href="linear-models.html#cb323-25"></a>         <span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb323-26"><a href="linear-models.html#cb323-26"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> post150[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">1</span>], </span>
<span id="cb323-27"><a href="linear-models.html#cb323-27"></a>              <span class="dt">slope     =</span> post150[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">2</span>],</span>
<span id="cb323-28"><a href="linear-models.html#cb323-28"></a>              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></span>
<span id="cb323-29"><a href="linear-models.html#cb323-29"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb323-30"><a href="linear-models.html#cb323-30"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d2<span class="op">$</span>weight),</span>
<span id="cb323-31"><a href="linear-models.html#cb323-31"></a>                  <span class="dt">ylim =</span> <span class="kw">range</span>(d2<span class="op">$</span>height)) <span class="op">+</span></span>
<span id="cb323-32"><a href="linear-models.html#cb323-32"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;N = 150&quot;</span>)</span>
<span id="cb323-33"><a href="linear-models.html#cb323-33"></a></span>
<span id="cb323-34"><a href="linear-models.html#cb323-34"></a>p4 &lt;-<span class="st"> </span></span>
<span id="cb323-35"><a href="linear-models.html#cb323-35"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="dt">data =</span>  d2[<span class="dv">1</span><span class="op">:</span><span class="dv">352</span> , ], </span>
<span id="cb323-36"><a href="linear-models.html#cb323-36"></a>         <span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb323-37"><a href="linear-models.html#cb323-37"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> post352[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">1</span>], </span>
<span id="cb323-38"><a href="linear-models.html#cb323-38"></a>              <span class="dt">slope     =</span> post352[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>, <span class="dv">2</span>],</span>
<span id="cb323-39"><a href="linear-models.html#cb323-39"></a>              <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dt">alpha =</span> <span class="fl">.3</span>) <span class="op">+</span></span>
<span id="cb323-40"><a href="linear-models.html#cb323-40"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">2</span>, <span class="dt">color =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb323-41"><a href="linear-models.html#cb323-41"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d2<span class="op">$</span>weight),</span>
<span id="cb323-42"><a href="linear-models.html#cb323-42"></a>                  <span class="dt">ylim =</span> <span class="kw">range</span>(d2<span class="op">$</span>height)) <span class="op">+</span></span>
<span id="cb323-43"><a href="linear-models.html#cb323-43"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">subtitle =</span> <span class="st">&quot;N = 352&quot;</span>)</span></code></pre></div>
<p>Note how we used the good old bracket syntax (e.g., <code>d2[1:10 , ]</code>) to index rows from our <code>d2</code> data. With tidyverse-style syntax, we could have done <code>slice(d2, 1:10)</code> or <code>d2 %&gt;% slice(1:10)</code> instead.</p>
<p>Now we can combine the ggplots with patchwork syntax to make the full version of Figure 4.5.</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="linear-models.html#cb324-1"></a>(p1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span>p3 <span class="op">+</span><span class="st"> </span>p4) <span class="op">&amp;</span></span>
<span id="cb324-2"><a href="linear-models.html#cb324-2"></a><span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">&amp;</span></span>
<span id="cb324-3"><a href="linear-models.html#cb324-3"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-70-1.png" width="480" /></p>
</div>
<div id="plotting-regression-intervals-and-contours." class="section level4">
<h4><span class="header-section-number">4.4.3.4</span> Plotting regression intervals and contours.</h4>
<p>Remember, if you want to plot McElreath’s <code>mu_at_50</code> with ggplot2, you’ll need to save it as a data frame or a tibble.</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="linear-models.html#cb325-1"></a>mu_at_<span class="dv">50</span> &lt;-<span class="st"> </span></span>
<span id="cb325-2"><a href="linear-models.html#cb325-2"></a><span class="st">  </span>post <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb325-3"><a href="linear-models.html#cb325-3"></a><span class="st">  </span><span class="kw">transmute</span>(<span class="dt">mu_at_50 =</span> b_Intercept <span class="op">+</span><span class="st"> </span>b_weight <span class="op">*</span><span class="st"> </span><span class="dv">50</span>)</span>
<span id="cb325-4"><a href="linear-models.html#cb325-4"></a> </span>
<span id="cb325-5"><a href="linear-models.html#cb325-5"></a><span class="kw">head</span>(mu_at_<span class="dv">50</span>)</span></code></pre></div>
<pre><code>##   mu_at_50
## 1 159.1848
## 2 159.3339
## 3 158.6834
## 4 159.8710
## 5 159.1118
## 6 159.5090</code></pre>
<p>And here is a version McElreath’s Figure 4.6 density plot.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="linear-models.html#cb327-1"></a>mu_at_<span class="dv">50</span> <span class="op">%&gt;%</span></span>
<span id="cb327-2"><a href="linear-models.html#cb327-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu_at_<span class="dv">50</span>)) <span class="op">+</span></span>
<span id="cb327-3"><a href="linear-models.html#cb327-3"></a><span class="st">  </span><span class="kw">geom_density</span>(<span class="dt">size =</span> <span class="dv">0</span>, <span class="dt">fill =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb327-4"><a href="linear-models.html#cb327-4"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb327-5"><a href="linear-models.html#cb327-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="kw">expression</span>(mu[<span class="st">&quot;height | weight = 50&quot;</span>])) <span class="op">+</span></span>
<span id="cb327-6"><a href="linear-models.html#cb327-6"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-72-1.png" width="288" /></p>
<p>We’ll use <code>mean_hdi()</code> to get both 89% and 95% HPDIs along with the mean.</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="linear-models.html#cb328-1"></a><span class="kw">mean_hdi</span>(mu_at_<span class="dv">50</span>[,<span class="dv">1</span>], <span class="dt">.width =</span> <span class="kw">c</span>(.<span class="dv">89</span>, <span class="fl">.95</span>))</span></code></pre></div>
<pre><code>##          y     ymin     ymax .width .point .interval
## 1 159.1233 158.5899 159.6726   0.89   mean       hdi
## 2 159.1233 158.4536 159.7955   0.95   mean       hdi</code></pre>
<p>If you wanted to express those sweet 95% HPDIs on your density plot, you might use the <code>tidybayes::stat_halfeye()</code> function. Since <code>stat_halfeye()</code> also returns a point estimate, we’ll just throw in the mode.</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="linear-models.html#cb330-1"></a>mu_at_<span class="dv">50</span> <span class="op">%&gt;%</span></span>
<span id="cb330-2"><a href="linear-models.html#cb330-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mu_at_<span class="dv">50</span>, <span class="dt">y =</span> <span class="dv">0</span>)) <span class="op">+</span></span>
<span id="cb330-3"><a href="linear-models.html#cb330-3"></a><span class="st">  </span><span class="kw">stat_halfeye</span>(<span class="dt">point_interval =</span> mode_hdi, <span class="dt">.width =</span> <span class="fl">.95</span>,</span>
<span id="cb330-4"><a href="linear-models.html#cb330-4"></a>               <span class="dt">fill =</span> <span class="st">&quot;royalblue&quot;</span>) <span class="op">+</span></span>
<span id="cb330-5"><a href="linear-models.html#cb330-5"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="ot">NULL</span>, <span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb330-6"><a href="linear-models.html#cb330-6"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="kw">expression</span>(mu[<span class="st">&quot;height | weight = 50&quot;</span>])) <span class="op">+</span></span>
<span id="cb330-7"><a href="linear-models.html#cb330-7"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-74-1.png" width="288" /></p>
<p>In brms, you would use <code>fitted()</code> to do what McElreath accomplished with <code>link()</code> in R code 4.53.</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="linear-models.html#cb331-1"></a>mu &lt;-<span class="st"> </span><span class="kw">fitted</span>(b4<span class="fl">.3</span>, <span class="dt">summary =</span> F)</span>
<span id="cb331-2"><a href="linear-models.html#cb331-2"></a></span>
<span id="cb331-3"><a href="linear-models.html#cb331-3"></a><span class="kw">str</span>(mu)</span></code></pre></div>
<pre><code>##  num [1:4000, 1:352] 157 157 157 158 157 ...</code></pre>
<p>When you specify <code>summary = F</code>, <code>fitted()</code> returns a matrix of values with as many rows as there were post-warmup iterations across your HMC chains and as many columns as there were cases in your data. Because we had 4,000 post-warmup iterations and <span class="math inline">\(n\)</span> = 352, <code>fitted()</code> returned a matrix of 4,000 rows and 352 vectors. If you omitted the <code>summary = F</code> argument, the default is <code>TRUE</code> and <code>fitted()</code> will return summary information instead.</p>
<p>Much like rethinking’s <code>link()</code>, <code>fitted()</code> can accommodate custom predictor values with its <code>newdata</code> argument.</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="linear-models.html#cb333-1"></a>weight_seq &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">weight =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">25</span>, <span class="dt">to =</span> <span class="dv">70</span>, <span class="dt">by =</span> <span class="dv">1</span>))</span>
<span id="cb333-2"><a href="linear-models.html#cb333-2"></a></span>
<span id="cb333-3"><a href="linear-models.html#cb333-3"></a>mu &lt;-</span>
<span id="cb333-4"><a href="linear-models.html#cb333-4"></a><span class="st">  </span><span class="kw">fitted</span>(b4<span class="fl">.3</span>,</span>
<span id="cb333-5"><a href="linear-models.html#cb333-5"></a>         <span class="dt">summary =</span> F,</span>
<span id="cb333-6"><a href="linear-models.html#cb333-6"></a>         <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb333-7"><a href="linear-models.html#cb333-7"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb333-8"><a href="linear-models.html#cb333-8"></a><span class="st">  </span><span class="co"># here we name the columns after the `weight` values from which they were computed</span></span>
<span id="cb333-9"><a href="linear-models.html#cb333-9"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="dv">25</span><span class="op">:</span><span class="dv">70</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb333-10"><a href="linear-models.html#cb333-10"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">iter =</span> <span class="dv">1</span><span class="op">:</span><span class="kw">n</span>())</span>
<span id="cb333-11"><a href="linear-models.html#cb333-11"></a></span>
<span id="cb333-12"><a href="linear-models.html#cb333-12"></a><span class="kw">str</span>(mu)</span></code></pre></div>
<p>Anticipating ggplot2, we went ahead and converted the output to a tibble. But we might do a little more data processing with the aid of <a href="https://tidyr.tidyverse.org/reference/gather.html"><code>tidyr::gather()</code></a>. With the <code>gather()</code> function, we’ll convert the data from the wide format to the long format. If you’re new to the distinction between wide and long data, you can learn more <a href="https://stanford.edu/~ejdemyr/r-tutorials/wide-and-long/">here</a> or <a href="https://www.theanalysisfactor.com/wide-and-long-data/">here</a>.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="linear-models.html#cb334-1"></a>mu &lt;-<span class="st"> </span></span>
<span id="cb334-2"><a href="linear-models.html#cb334-2"></a><span class="st">  </span>mu <span class="op">%&gt;%</span></span>
<span id="cb334-3"><a href="linear-models.html#cb334-3"></a><span class="st">  </span><span class="kw">gather</span>(weight, height, <span class="op">-</span>iter) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb334-4"><a href="linear-models.html#cb334-4"></a><span class="st">  </span><span class="co"># we might reformat `weight` to numerals</span></span>
<span id="cb334-5"><a href="linear-models.html#cb334-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">weight =</span> <span class="kw">as.numeric</span>(weight))</span>
<span id="cb334-6"><a href="linear-models.html#cb334-6"></a></span>
<span id="cb334-7"><a href="linear-models.html#cb334-7"></a><span class="kw">head</span>(mu)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 3
##    iter weight height
##   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1     1     25   137.
## 2     2     25   137.
## 3     3     25   136.
## 4     4     25   136.
## 5     5     25   135.
## 6     6     25   136.</code></pre>
<p>That’s enough data processing. Here we reproduce McElreath’s Figure 4.7.a.</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="linear-models.html#cb336-1"></a>d2 <span class="op">%&gt;%</span></span>
<span id="cb336-2"><a href="linear-models.html#cb336-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb336-3"><a href="linear-models.html#cb336-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> mu <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(iter <span class="op">&lt;</span><span class="st"> </span><span class="dv">101</span>),</span>
<span id="cb336-4"><a href="linear-models.html#cb336-4"></a>             <span class="dt">alpha =</span> <span class="fl">.1</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-78-1.png" width="288" /></p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="linear-models.html#cb337-1"></a><span class="co"># or prettied up a bit</span></span>
<span id="cb337-2"><a href="linear-models.html#cb337-2"></a>d2 <span class="op">%&gt;%</span></span>
<span id="cb337-3"><a href="linear-models.html#cb337-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb337-4"><a href="linear-models.html#cb337-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> mu <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(iter <span class="op">&lt;</span><span class="st"> </span><span class="dv">101</span>), </span>
<span id="cb337-5"><a href="linear-models.html#cb337-5"></a>             <span class="dt">color =</span> <span class="st">&quot;navyblue&quot;</span>, <span class="dt">alpha =</span> <span class="fl">.05</span>) <span class="op">+</span></span>
<span id="cb337-6"><a href="linear-models.html#cb337-6"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb337-7"><a href="linear-models.html#cb337-7"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-78-2.png" width="288" /></p>
<p>With <code>fitted()</code>, it’s quite easy to plot a regression line and its intervals. Just omit the <code>summary = F</code> argument.</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="linear-models.html#cb338-1"></a>mu_summary &lt;-</span>
<span id="cb338-2"><a href="linear-models.html#cb338-2"></a><span class="st">  </span><span class="kw">fitted</span>(b4<span class="fl">.3</span>, </span>
<span id="cb338-3"><a href="linear-models.html#cb338-3"></a>         <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb338-4"><a href="linear-models.html#cb338-4"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb338-5"><a href="linear-models.html#cb338-5"></a><span class="st">  </span><span class="co"># let&#39;s tack on the `weight` values from `weight_seq`</span></span>
<span id="cb338-6"><a href="linear-models.html#cb338-6"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq)</span>
<span id="cb338-7"><a href="linear-models.html#cb338-7"></a></span>
<span id="cb338-8"><a href="linear-models.html#cb338-8"></a><span class="kw">head</span>(mu_summary)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   Estimate Est.Error  Q2.5 Q97.5 weight
##      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     137.     0.885  135.  138.     25
## 2     137.     0.845  136.  139.     26
## 3     138.     0.805  137.  140.     27
## 4     139.     0.766  138.  141.     28
## 5     140.     0.726  139.  142.     29
## 6     141.     0.688  140.  142.     30</code></pre>
<p>Here it is, our analogue to Figure 4.7.b.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="linear-models.html#cb340-1"></a>d2 <span class="op">%&gt;%</span></span>
<span id="cb340-2"><a href="linear-models.html#cb340-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> weight, <span class="dt">y =</span> height)) <span class="op">+</span></span>
<span id="cb340-3"><a href="linear-models.html#cb340-3"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data =</span> mu_summary,</span>
<span id="cb340-4"><a href="linear-models.html#cb340-4"></a>              <span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb340-5"><a href="linear-models.html#cb340-5"></a>              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb340-6"><a href="linear-models.html#cb340-6"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb340-7"><a href="linear-models.html#cb340-7"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="st">&quot;navyblue&quot;</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb340-8"><a href="linear-models.html#cb340-8"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d2<span class="op">$</span>weight)) <span class="op">+</span></span>
<span id="cb340-9"><a href="linear-models.html#cb340-9"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb340-10"><a href="linear-models.html#cb340-10"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-80-1.png" width="288" /></p>
<p>If you wanted to use intervals other than the default 95% ones, you’d enter a <code>probs</code> argument like this: <code>fitted(b4.3, newdata = weight.seq, probs = c(.25, .75))</code>. The resulting third and fourth vectors from the <code>fitted()</code> object would be named <code>Q25</code> and <code>Q75</code> instead of the default <code>Q2.5</code> and <code>Q97.5</code>. The <a href="https://github.com/paul-buerkner/brms/issues/425"><code>Q</code> prefix</a> stands for quantile.</p>
<div id="overthinking-how-link-fitted-works." class="section level5">
<h5><span class="header-section-number">4.4.3.4.1</span> Overthinking: How <del>link</del> <code>fitted()</code> works.</h5>
<p>Similar to <code>rethinking::link()</code>, <code>brms::fitted()</code> uses the formula from your model to compute the model expectations for a given set of predictor values. I use it a lot in this project. If you follow along, you’ll get a good handle on it. For some quick documentation, execute <code>?fitted.brmsfit</code>.</p>
</div>
</div>
<div id="prediction-intervals." class="section level4">
<h4><span class="header-section-number">4.4.3.5</span> Prediction intervals.</h4>
<p>Even though our full statistical model (omitting priors for the sake of simplicity) is</p>
<p><span class="math display">\[h_i \sim \operatorname{Normal}(\mu_i = \alpha + \beta x_i, \sigma),\]</span></p>
<p>we’ve only been plotting the <span class="math inline">\(\mu_i\)</span> part. In order to bring in the variability expressed by <span class="math inline">\(\sigma\)</span>, we’ll have to switch to the <code>predict()</code> function. Much as <code>brms::fitted()</code> was our analogue to <code>rethinking::link()</code>, <code>brms::predict()</code> is our analogue to <code>rethinking::sim()</code>.</p>
<p>We can reuse our <code>weight_seq</code> data from before. But in case you forgot, here’s that code again.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="linear-models.html#cb341-1"></a>weight_seq &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">weight =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="dv">25</span>, <span class="dt">to =</span> <span class="dv">70</span>, <span class="dt">by =</span> <span class="dv">1</span>))</span></code></pre></div>
<p>The <code>predict()</code> code looks a lot like what we used for <code>fitted()</code>.</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="linear-models.html#cb342-1"></a>pred_height &lt;-</span>
<span id="cb342-2"><a href="linear-models.html#cb342-2"></a><span class="st">  </span><span class="kw">predict</span>(b4<span class="fl">.3</span>,</span>
<span id="cb342-3"><a href="linear-models.html#cb342-3"></a>          <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb342-4"><a href="linear-models.html#cb342-4"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb342-5"><a href="linear-models.html#cb342-5"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq)</span>
<span id="cb342-6"><a href="linear-models.html#cb342-6"></a>  </span>
<span id="cb342-7"><a href="linear-models.html#cb342-7"></a>pred_height <span class="op">%&gt;%</span></span>
<span id="cb342-8"><a href="linear-models.html#cb342-8"></a><span class="st">  </span><span class="kw">slice</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 5
##   Estimate Est.Error  Q2.5 Q97.5 weight
##      &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
## 1     136.      5.12  126.  146.     25
## 2     138.      5.12  127.  148.     26
## 3     138.      5.09  128.  148.     27
## 4     139.      5.05  129.  149.     28
## 5     140.      5.12  130.  150.     29
## 6     141.      5.14  131.  151.     30</code></pre>
<p>This time the summary information in our data frame is for, as McElreath put it, “simulated heights, not distributions of plausible average height, <span class="math inline">\(\mu\)</span>” (p. 108). Another way of saying that is that these simulations are the joint consequence of <span class="math inline">\(\mu\)</span> AND <span class="math inline">\(\sigma\)</span>, unlike the results of <code>fitted()</code>, which only reflect <span class="math inline">\(\mu\)</span>. Here’s our plot for Figure 4.8.</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="linear-models.html#cb344-1"></a>d2 <span class="op">%&gt;%</span></span>
<span id="cb344-2"><a href="linear-models.html#cb344-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> weight)) <span class="op">+</span></span>
<span id="cb344-3"><a href="linear-models.html#cb344-3"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> pred_height, </span>
<span id="cb344-4"><a href="linear-models.html#cb344-4"></a>              <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb344-5"><a href="linear-models.html#cb344-5"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="op">+</span></span>
<span id="cb344-6"><a href="linear-models.html#cb344-6"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data =</span> mu_summary,</span>
<span id="cb344-7"><a href="linear-models.html#cb344-7"></a>              <span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb344-8"><a href="linear-models.html#cb344-8"></a>              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb344-9"><a href="linear-models.html#cb344-9"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb344-10"><a href="linear-models.html#cb344-10"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> height),</span>
<span id="cb344-11"><a href="linear-models.html#cb344-11"></a>             <span class="dt">color =</span> <span class="st">&quot;navyblue&quot;</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb344-12"><a href="linear-models.html#cb344-12"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;height&quot;</span>) <span class="op">+</span></span>
<span id="cb344-13"><a href="linear-models.html#cb344-13"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d2<span class="op">$</span>weight),</span>
<span id="cb344-14"><a href="linear-models.html#cb344-14"></a>                  <span class="dt">ylim =</span> <span class="kw">range</span>(d2<span class="op">$</span>height)) <span class="op">+</span></span>
<span id="cb344-15"><a href="linear-models.html#cb344-15"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb344-16"><a href="linear-models.html#cb344-16"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-83-1.png" width="288" /></p>
</div>
</div>
</div>
<div id="polynomial-regression" class="section level2">
<h2><span class="header-section-number">4.5</span> Polynomial regression</h2>
<p>Remember <code>d</code>?</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="linear-models.html#cb345-1"></a>d <span class="op">%&gt;%</span></span>
<span id="cb345-2"><a href="linear-models.html#cb345-2"></a><span class="st">  </span><span class="kw">glimpse</span>()</span></code></pre></div>
<pre><code>## Rows: 544
## Columns: 4
## $ height &lt;dbl&gt; 151.7650, 139.7000, 136.5250, 156.8450, 145.4150, 163.8300, 149.2250, 168.9100, 14…
## $ weight &lt;dbl&gt; 47.82561, 36.48581, 31.86484, 53.04191, 41.27687, 62.99259, 38.24348, 55.47997, 34…
## $ age    &lt;dbl&gt; 63.0, 63.0, 65.0, 41.0, 51.0, 35.0, 32.0, 27.0, 19.0, 54.0, 47.0, 66.0, 73.0, 20.0…
## $ male   &lt;int&gt; 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0…</code></pre>
<p>The quadratic is probably the most commonly-used polynomial regression model. It follows the form</p>
<p><span class="math display">\[\mu = \alpha + \beta_1 x_i + \beta_2 x_i^2.\]</span></p>
<p>McElreath warned: “Fitting these models to data is easy. Interpreting them can be hard” (p. 111). Standardizing will help <code>brm()</code> fit the model. We might standardize our <code>weight</code> variable like so.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="linear-models.html#cb347-1"></a>d &lt;-</span>
<span id="cb347-2"><a href="linear-models.html#cb347-2"></a><span class="st">  </span>d <span class="op">%&gt;%</span></span>
<span id="cb347-3"><a href="linear-models.html#cb347-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">weight_s =</span> (weight <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(weight)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(weight))</span></code></pre></div>
<p>Here’s the quadratic model in brms.</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="linear-models.html#cb348-1"></a>b4<span class="fl">.5</span> &lt;-<span class="st"> </span></span>
<span id="cb348-2"><a href="linear-models.html#cb348-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, </span>
<span id="cb348-3"><a href="linear-models.html#cb348-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb348-4"><a href="linear-models.html#cb348-4"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight_s <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(weight_s<span class="op">^</span><span class="dv">2</span>),</span>
<span id="cb348-5"><a href="linear-models.html#cb348-5"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb348-6"><a href="linear-models.html#cb348-6"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb348-7"><a href="linear-models.html#cb348-7"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb348-8"><a href="linear-models.html#cb348-8"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb348-9"><a href="linear-models.html#cb348-9"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb348-10"><a href="linear-models.html#cb348-10"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.05&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="linear-models.html#cb349-1"></a><span class="kw">plot</span>(b4<span class="fl">.5</span>)</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-86-1.png" width="576" /></p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="linear-models.html#cb350-1"></a><span class="kw">print</span>(b4<span class="fl">.5</span>)</span></code></pre></div>
<pre><code>##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: height ~ 1 + weight_s + I(weight_s^2) 
##    Data: d (Number of observations: 544) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     146.66      0.37   145.95   147.37 1.00     3608     2753
## weight_s       21.41      0.29    20.84    21.97 1.00     3567     2613
## Iweight_sE2    -8.42      0.28    -8.96    -7.86 1.00     3444     3016
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     5.76      0.17     5.44     6.12 1.00     3754     3050
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
<p>Our quadratic plot requires new <code>fitted()</code>- and <code>predict()</code>-oriented wrangling.</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="linear-models.html#cb352-1"></a>weight_seq &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">weight_s =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">-2.5</span>, <span class="dt">to =</span> <span class="fl">2.5</span>, <span class="dt">length.out =</span> <span class="dv">30</span>))</span>
<span id="cb352-2"><a href="linear-models.html#cb352-2"></a></span>
<span id="cb352-3"><a href="linear-models.html#cb352-3"></a>f &lt;-</span>
<span id="cb352-4"><a href="linear-models.html#cb352-4"></a><span class="st">  </span><span class="kw">fitted</span>(b4<span class="fl">.5</span>, </span>
<span id="cb352-5"><a href="linear-models.html#cb352-5"></a>         <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb352-6"><a href="linear-models.html#cb352-6"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb352-7"><a href="linear-models.html#cb352-7"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq)</span>
<span id="cb352-8"><a href="linear-models.html#cb352-8"></a></span>
<span id="cb352-9"><a href="linear-models.html#cb352-9"></a>p &lt;-</span>
<span id="cb352-10"><a href="linear-models.html#cb352-10"></a><span class="st">  </span><span class="kw">predict</span>(b4<span class="fl">.5</span>, </span>
<span id="cb352-11"><a href="linear-models.html#cb352-11"></a>          <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb352-12"><a href="linear-models.html#cb352-12"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb352-13"><a href="linear-models.html#cb352-13"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq)  </span></code></pre></div>
<p>Behold the code for our version of Figure 4.9.a. You’ll notice how little the code changed from that for Figure 4.8, above.</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="linear-models.html#cb353-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> d, </span>
<span id="cb353-2"><a href="linear-models.html#cb353-2"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> weight_s)) <span class="op">+</span></span>
<span id="cb353-3"><a href="linear-models.html#cb353-3"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> p, </span>
<span id="cb353-4"><a href="linear-models.html#cb353-4"></a>              <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb353-5"><a href="linear-models.html#cb353-5"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="op">+</span></span>
<span id="cb353-6"><a href="linear-models.html#cb353-6"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data =</span> f,</span>
<span id="cb353-7"><a href="linear-models.html#cb353-7"></a>              <span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb353-8"><a href="linear-models.html#cb353-8"></a>              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb353-9"><a href="linear-models.html#cb353-9"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb353-10"><a href="linear-models.html#cb353-10"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> height),</span>
<span id="cb353-11"><a href="linear-models.html#cb353-11"></a>             <span class="dt">color =</span> <span class="st">&quot;navyblue&quot;</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb353-12"><a href="linear-models.html#cb353-12"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d<span class="op">$</span>weight_s)) <span class="op">+</span></span>
<span id="cb353-13"><a href="linear-models.html#cb353-13"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb353-14"><a href="linear-models.html#cb353-14"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-88-1.png" width="288" /></p>
<p>From a formula perspective, the cubic model is a simple extenstion of the quadratic:</p>
<p><span class="math display">\[\mu = \alpha + \beta_1 x_i + \beta_2 x_i^2 + \beta_3 x_i^3.\]</span></p>
<p>Fit it like so.</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="linear-models.html#cb354-1"></a>b4<span class="fl">.6</span> &lt;-<span class="st"> </span></span>
<span id="cb354-2"><a href="linear-models.html#cb354-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, </span>
<span id="cb354-3"><a href="linear-models.html#cb354-3"></a>      <span class="dt">family =</span> gaussian,</span>
<span id="cb354-4"><a href="linear-models.html#cb354-4"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight_s <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(weight_s<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(weight_s<span class="op">^</span><span class="dv">3</span>),</span>
<span id="cb354-5"><a href="linear-models.html#cb354-5"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb354-6"><a href="linear-models.html#cb354-6"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb354-7"><a href="linear-models.html#cb354-7"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb354-8"><a href="linear-models.html#cb354-8"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb354-9"><a href="linear-models.html#cb354-9"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb354-10"><a href="linear-models.html#cb354-10"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.06&quot;</span>)</span></code></pre></div>
<p>And now we’ll fit the good old linear model.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="linear-models.html#cb355-1"></a>b4<span class="fl">.7</span> &lt;-<span class="st"> </span></span>
<span id="cb355-2"><a href="linear-models.html#cb355-2"></a><span class="st">  </span><span class="kw">brm</span>(<span class="dt">data =</span> d, <span class="dt">family =</span> gaussian,</span>
<span id="cb355-3"><a href="linear-models.html#cb355-3"></a>      height <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>weight_s,</span>
<span id="cb355-4"><a href="linear-models.html#cb355-4"></a>      <span class="dt">prior =</span> <span class="kw">c</span>(<span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">178</span>, <span class="dv">100</span>), <span class="dt">class =</span> Intercept),</span>
<span id="cb355-5"><a href="linear-models.html#cb355-5"></a>                <span class="kw">prior</span>(<span class="kw">normal</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">class =</span> b),</span>
<span id="cb355-6"><a href="linear-models.html#cb355-6"></a>                <span class="kw">prior</span>(<span class="kw">cauchy</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">class =</span> sigma)),</span>
<span id="cb355-7"><a href="linear-models.html#cb355-7"></a>      <span class="dt">iter =</span> <span class="dv">2000</span>, <span class="dt">warmup =</span> <span class="dv">1000</span>, <span class="dt">chains =</span> <span class="dv">4</span>, <span class="dt">cores =</span> <span class="dv">4</span>,</span>
<span id="cb355-8"><a href="linear-models.html#cb355-8"></a>      <span class="dt">seed =</span> <span class="dv">4</span>,</span>
<span id="cb355-9"><a href="linear-models.html#cb355-9"></a>      <span class="dt">file =</span> <span class="st">&quot;fits/b04.07&quot;</span>)</span></code></pre></div>
<p>Here’s the <code>fitted()</code>, <code>predict()</code>, and ggplot2 code for Figure 4.9.c, the cubic model.</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="linear-models.html#cb356-1"></a>f &lt;-</span>
<span id="cb356-2"><a href="linear-models.html#cb356-2"></a><span class="st">  </span><span class="kw">fitted</span>(b4<span class="fl">.6</span>, </span>
<span id="cb356-3"><a href="linear-models.html#cb356-3"></a>         <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb356-4"><a href="linear-models.html#cb356-4"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb356-5"><a href="linear-models.html#cb356-5"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq)</span>
<span id="cb356-6"><a href="linear-models.html#cb356-6"></a></span>
<span id="cb356-7"><a href="linear-models.html#cb356-7"></a>p &lt;-</span>
<span id="cb356-8"><a href="linear-models.html#cb356-8"></a><span class="st">  </span><span class="kw">predict</span>(b4<span class="fl">.6</span>, </span>
<span id="cb356-9"><a href="linear-models.html#cb356-9"></a>          <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb356-10"><a href="linear-models.html#cb356-10"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb356-11"><a href="linear-models.html#cb356-11"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq) </span>
<span id="cb356-12"><a href="linear-models.html#cb356-12"></a></span>
<span id="cb356-13"><a href="linear-models.html#cb356-13"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> d, </span>
<span id="cb356-14"><a href="linear-models.html#cb356-14"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> weight_s)) <span class="op">+</span></span>
<span id="cb356-15"><a href="linear-models.html#cb356-15"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> p, </span>
<span id="cb356-16"><a href="linear-models.html#cb356-16"></a>              <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb356-17"><a href="linear-models.html#cb356-17"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="op">+</span></span>
<span id="cb356-18"><a href="linear-models.html#cb356-18"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data =</span> f,</span>
<span id="cb356-19"><a href="linear-models.html#cb356-19"></a>              <span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb356-20"><a href="linear-models.html#cb356-20"></a>              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb356-21"><a href="linear-models.html#cb356-21"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb356-22"><a href="linear-models.html#cb356-22"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> height),</span>
<span id="cb356-23"><a href="linear-models.html#cb356-23"></a>             <span class="dt">color =</span> <span class="st">&quot;navyblue&quot;</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb356-24"><a href="linear-models.html#cb356-24"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d<span class="op">$</span>weight_s)) <span class="op">+</span></span>
<span id="cb356-25"><a href="linear-models.html#cb356-25"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb356-26"><a href="linear-models.html#cb356-26"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-89-1.png" width="288" /></p>
<p>And here’s the <code>fitted()</code>, <code>predict()</code>, and ggplot2 code for Figure 4.9.a, the linear model.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="linear-models.html#cb357-1"></a>f &lt;-</span>
<span id="cb357-2"><a href="linear-models.html#cb357-2"></a><span class="st">  </span><span class="kw">fitted</span>(b4<span class="fl">.7</span>, </span>
<span id="cb357-3"><a href="linear-models.html#cb357-3"></a>         <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb357-4"><a href="linear-models.html#cb357-4"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb357-5"><a href="linear-models.html#cb357-5"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq)</span>
<span id="cb357-6"><a href="linear-models.html#cb357-6"></a></span>
<span id="cb357-7"><a href="linear-models.html#cb357-7"></a>p &lt;-</span>
<span id="cb357-8"><a href="linear-models.html#cb357-8"></a><span class="st">  </span><span class="kw">predict</span>(b4<span class="fl">.7</span>, </span>
<span id="cb357-9"><a href="linear-models.html#cb357-9"></a>          <span class="dt">newdata =</span> weight_seq) <span class="op">%&gt;%</span></span>
<span id="cb357-10"><a href="linear-models.html#cb357-10"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></span>
<span id="cb357-11"><a href="linear-models.html#cb357-11"></a><span class="st">  </span><span class="kw">bind_cols</span>(weight_seq) </span>
<span id="cb357-12"><a href="linear-models.html#cb357-12"></a></span>
<span id="cb357-13"><a href="linear-models.html#cb357-13"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> d, </span>
<span id="cb357-14"><a href="linear-models.html#cb357-14"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> weight_s)) <span class="op">+</span></span>
<span id="cb357-15"><a href="linear-models.html#cb357-15"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> p, </span>
<span id="cb357-16"><a href="linear-models.html#cb357-16"></a>              <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb357-17"><a href="linear-models.html#cb357-17"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="op">+</span></span>
<span id="cb357-18"><a href="linear-models.html#cb357-18"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data =</span> f,</span>
<span id="cb357-19"><a href="linear-models.html#cb357-19"></a>              <span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb357-20"><a href="linear-models.html#cb357-20"></a>              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb357-21"><a href="linear-models.html#cb357-21"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb357-22"><a href="linear-models.html#cb357-22"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> height),</span>
<span id="cb357-23"><a href="linear-models.html#cb357-23"></a>             <span class="dt">color =</span> <span class="st">&quot;navyblue&quot;</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb357-24"><a href="linear-models.html#cb357-24"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d<span class="op">$</span>weight_s)) <span class="op">+</span></span>
<span id="cb357-25"><a href="linear-models.html#cb357-25"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb357-26"><a href="linear-models.html#cb357-26"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>())</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-90-1.png" width="288" /></p>
<div id="overthinking-converting-back-to-natural-scale." class="section level5">
<h5><span class="header-section-number">4.5.0.0.1</span> Overthinking: Converting back to natural scale.</h5>
<p>You can apply McElreath’s conversion trick within the ggplot2 environment, too. Here it is with the linear model.</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="linear-models.html#cb358-1"></a>at &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">-1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb358-2"><a href="linear-models.html#cb358-2"></a></span>
<span id="cb358-3"><a href="linear-models.html#cb358-3"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> d, </span>
<span id="cb358-4"><a href="linear-models.html#cb358-4"></a>       <span class="kw">aes</span>(<span class="dt">x =</span> weight_s)) <span class="op">+</span></span>
<span id="cb358-5"><a href="linear-models.html#cb358-5"></a><span class="st">  </span><span class="kw">geom_ribbon</span>(<span class="dt">data =</span> p, </span>
<span id="cb358-6"><a href="linear-models.html#cb358-6"></a>              <span class="kw">aes</span>(<span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb358-7"><a href="linear-models.html#cb358-7"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey83&quot;</span>) <span class="op">+</span></span>
<span id="cb358-8"><a href="linear-models.html#cb358-8"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">data =</span> f,</span>
<span id="cb358-9"><a href="linear-models.html#cb358-9"></a>              <span class="kw">aes</span>(<span class="dt">y =</span> Estimate, <span class="dt">ymin =</span> Q2<span class="fl">.5</span>, <span class="dt">ymax =</span> Q97<span class="fl">.5</span>),</span>
<span id="cb358-10"><a href="linear-models.html#cb358-10"></a>              <span class="dt">stat =</span> <span class="st">&quot;identity&quot;</span>,</span>
<span id="cb358-11"><a href="linear-models.html#cb358-11"></a>              <span class="dt">fill =</span> <span class="st">&quot;grey70&quot;</span>, <span class="dt">color =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">4</span>) <span class="op">+</span></span>
<span id="cb358-12"><a href="linear-models.html#cb358-12"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">y =</span> height),</span>
<span id="cb358-13"><a href="linear-models.html#cb358-13"></a>             <span class="dt">color =</span> <span class="st">&quot;navyblue&quot;</span>, <span class="dt">shape =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="fl">1.5</span>, <span class="dt">alpha =</span> <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb358-14"><a href="linear-models.html#cb358-14"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">range</span>(d<span class="op">$</span>weight_s)) <span class="op">+</span></span>
<span id="cb358-15"><a href="linear-models.html#cb358-15"></a><span class="st">  </span><span class="kw">theme</span>(<span class="dt">text =</span> <span class="kw">element_text</span>(<span class="dt">family =</span> <span class="st">&quot;Times&quot;</span>),</span>
<span id="cb358-16"><a href="linear-models.html#cb358-16"></a>        <span class="dt">panel.grid =</span> <span class="kw">element_blank</span>()) <span class="op">+</span></span>
<span id="cb358-17"><a href="linear-models.html#cb358-17"></a><span class="st">  </span></span>
<span id="cb358-18"><a href="linear-models.html#cb358-18"></a><span class="st">  </span><span class="co"># here it is!</span></span>
<span id="cb358-19"><a href="linear-models.html#cb358-19"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="st">&quot;standardized weight converted back&quot;</span>,</span>
<span id="cb358-20"><a href="linear-models.html#cb358-20"></a>                     <span class="dt">breaks =</span> at,</span>
<span id="cb358-21"><a href="linear-models.html#cb358-21"></a>                     <span class="dt">labels =</span> <span class="kw">round</span>(at <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(d<span class="op">$</span>weight) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(d<span class="op">$</span>weight), <span class="dv">1</span>))</span></code></pre></div>
<p><img src="04_files/figure-gfm/unnamed-chunk-91-1.png" width="288" /></p>
</div>
</div>
<div id="session-info-3" class="section level2 unnumbered">
<h2>Session info</h2>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="linear-models.html#cb359-1"></a><span class="kw">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 3.6.3 (2020-02-29)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS Catalina 10.15.3
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] parallel  stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.1.1      brms_2.13.5          Rcpp_1.0.5           dagitty_0.2-2       
##  [5] rstan_2.19.3         StanHeaders_2.21.0-1 patchwork_1.0.1.9000 forcats_0.5.0       
##  [9] stringr_1.4.0        dplyr_1.0.1          purrr_0.3.4          readr_1.3.1         
## [13] tidyr_1.1.1          tibble_3.0.3         ggplot2_3.3.2        tidyverse_1.3.0     
## 
## loaded via a namespace (and not attached):
##   [1] TH.data_1.0-10       colorspace_1.4-1     ellipsis_0.3.1       ggridges_0.5.2      
##   [5] rsconnect_0.8.16     estimability_1.3     markdown_1.1         base64enc_0.1-3     
##   [9] fs_1.4.1             rstudioapi_0.11      farver_2.0.3         svUnit_1.0.3        
##  [13] DT_0.13              fansi_0.4.1          mvtnorm_1.1-0        lubridate_1.7.8     
##  [17] xml2_1.3.1           codetools_0.2-16     splines_3.6.3        bridgesampling_1.0-0
##  [21] knitr_1.28           shinythemes_1.1.2    bayesplot_1.7.1      jsonlite_1.7.0      
##  [25] broom_0.5.5          dbplyr_1.4.2         ggdist_2.1.1         shiny_1.5.0         
##  [29] compiler_3.6.3       httr_1.4.1           emmeans_1.4.5        backports_1.1.9     
##  [33] assertthat_0.2.1     Matrix_1.2-18        fastmap_1.0.1        cli_2.0.2           
##  [37] later_1.1.0.1        htmltools_0.5.0      prettyunits_1.1.1    tools_3.6.3         
##  [41] igraph_1.2.5         coda_0.19-3          gtable_0.3.0         glue_1.4.2          
##  [45] reshape2_1.4.4       V8_3.0.2             cellranger_1.1.0     vctrs_0.3.4         
##  [49] nlme_3.1-144         crosstalk_1.1.0.1    xfun_0.13            ps_1.3.4            
##  [53] rvest_0.3.5          miniUI_0.1.1.1       mime_0.9             lifecycle_0.2.0     
##  [57] gtools_3.8.2         MASS_7.3-51.5        zoo_1.8-7            scales_1.1.1        
##  [61] colourpicker_1.0     hms_0.5.3            promises_1.1.1       Brobdingnag_1.2-6   
##  [65] sandwich_2.5-1       inline_0.3.15        shinystan_2.5.0      yaml_2.2.1          
##  [69] curl_4.3             gridExtra_2.3        loo_2.3.1            stringi_1.4.6       
##  [73] highr_0.8            dygraphs_1.1.1.6     boot_1.3-24          pkgbuild_1.1.0      
##  [77] shape_1.4.4          rlang_0.4.7          pkgconfig_2.0.3      matrixStats_0.56.0  
##  [81] HDInterval_0.2.0     evaluate_0.14        lattice_0.20-38      rstantools_2.1.1    
##  [85] htmlwidgets_1.5.1    labeling_0.3         processx_3.4.4       tidyselect_1.1.0    
##  [89] plyr_1.8.6           magrittr_1.5         bookdown_0.18        R6_2.4.1            
##  [93] generics_0.0.2       multcomp_1.4-13      DBI_1.1.0            pillar_1.4.6        
##  [97] haven_2.2.0          withr_2.2.0          xts_0.12-0           survival_3.1-12     
## [101] abind_1.4-5          modelr_0.1.6         crayon_1.3.4         arrayhelpers_1.1-0  
## [105] utf8_1.1.4           rmarkdown_2.1        isoband_0.2.2        grid_3.6.3          
## [109] readxl_1.3.1         callr_3.4.4          threejs_0.3.3        reprex_0.3.0        
## [113] digest_0.6.25        xtable_1.8-4         httpuv_1.5.4         stats4_3.6.3        
## [117] munsell_0.5.0        viridisLite_0.3.0    shinyjs_1.1</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-brms2020RM">
<p>Bürkner, P.-C. (2020b). <em>brms reference manual, Version 2.13.5</em>. <a href="https://CRAN.R-project.org/package=brms/brms.pdf">https://CRAN.R-project.org/package=brms/brms.pdf</a></p>
</div>
<div id="ref-Bürkner2020Distributional">
<p>Bürkner, P.-C. (2020f). <em>Estimating distributional models with brms</em>. <a href="https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html">https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html</a></p>
</div>
<div id="ref-howell2001demography">
<p>Howell, N. (2001). <em>Demography of the dobe! Kung</em> (2nd Edition). Routledge. <a href="https://www.routledge.com/Demography-of-the-Dobe-Kung/Howell/p/book/9780202306490">https://www.routledge.com/Demography-of-the-Dobe-Kung/Howell/p/book/9780202306490</a></p>
</div>
<div id="ref-howell2010life">
<p>Howell, N. (2010). <em>Life histories of the Dobe! Kung: Food, fatness, and well-being over the life span</em> (Vol. 4). Univ of California Press. <a href="https://www.ucpress.edu/book/9780520262348/life-histories-of-the-dobe-kung">https://www.ucpress.edu/book/9780520262348/life-histories-of-the-dobe-kung</a></p>
</div>
<div id="ref-kruschkeDoingBayesianData2015">
<p>Kruschke, J. K. (2015). <em>Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan</em>. Academic Press. <a href="https://sites.google.com/site/doingbayesiandataanalysis/">https://sites.google.com/site/doingbayesiandataanalysis/</a></p>
</div>
<div id="ref-kurzDoingBayesianData2020">
<p>Kurz, A. S. (2020a). <em>Doing Bayesian data analysis in brms and the tidyverse</em> (version 0.3.0). <a href="https://bookdown.org/content/3686/">https://bookdown.org/content/3686/</a></p>
</div>
<div id="ref-mcelreathStatisticalRethinkingBayesian2015">
<p>McElreath, R. (2015). <em>Statistical rethinking: A Bayesian course with examples in R and Stan</em>. CRC press. <a href="https://xcelab.net/rm/statistical-rethinking/">https://xcelab.net/rm/statistical-rethinking/</a></p>
</div>
<div id="ref-R-rethinking">
<p>McElreath, R. (2020a). <em>rethinking R package</em>. <a href="https://xcelab.net/rm/software/">https://xcelab.net/rm/software/</a></p>
</div>
<div id="ref-pengProgrammingDataScience2019">
<p>Peng, R. D. (2019). <em>R programming for data science</em>. <a href="https://bookdown.org/rdpeng/rprogdatascience/">https://bookdown.org/rdpeng/rprogdatascience/</a></p>
</div>
<div id="ref-R-MASS">
<p>Ripley, B. (2019). <em>MASS: Support functions and datasets for venables and ripley’s MASS</em>. <a href="https://CRAN.R-project.org/package=MASS">https://CRAN.R-project.org/package=MASS</a></p>
</div>
<div id="ref-standevelopmentteamRStanInterfaceStan2020">
<p>Stan Development Team. (2020b). <em>RStan: The R interface to Stan</em>. <a href="https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html">https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html</a></p>
</div>
<div id="ref-MASS2002">
<p>Venables, W. N., &amp; Ripley, B. D. (2002). <em>Modern applied statistics with S</em> (Fourth Edition). Springer. <a href="http://www.stats.ox.ac.uk/pub/MASS4">http://www.stats.ox.ac.uk/pub/MASS4</a></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sampling-the-imaginary.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multivariate-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
