---
title: "Ch. 10 Counting and Classification"
author: "A Solomon Kurz"
date: "`r format(Sys.Date())`"
output:
  github_document
---

```{r, echo = FALSE, cache = FALSE}
knitr::opts_chunk$set(fig.retina = 2.5)
options(width = 110)
```

preliminary

```{r}
library(tidyverse)
library(brms)
library(wesanderson)
library(ggthemes)
library(bayesplot)
library(broom)
library(loo)
library(ggExtra)
library(GGally)

theme_set(theme_default() + 
            theme_tufte() +
            theme(plot.background = element_rect(fill  = wes_palette("Moonrise2")[3],
                                                 color = wes_palette("Moonrise2")[3])))
```

### Multinomial.

> When more than two types of unordered events are possible, and the probability of each type of event is constant across trials, then the maximum entropy distribution is the multinomial distribution. [We] already met the multinomial, implicitly, in [Chapter 9][Maximum entropy] when we tossed pebbles into buckets as an introduction to maximum entropy. The binomial is really a special case of this distribution. And so its distribution formula resembles the binomial, just extrapolated out to three or more types of events. If there are $K$ types of events with probabilities $p_1, …, p_K$, then the probability of observing $y_1, …, y_K$ events of each type out of $n$ trials is (p. 323):

$$\text{Pr} (y_1, ..., y_K | n, p_1, ..., p_K) = \frac{n!}{\prod_i y_i!} \prod_{i = 1}^K p_i^{y_i}$$

Compare that equation with the simpler version in section 2.3.1 (page 33 in the text).

#### Explicit multinomial models.

"The conventional and natural link is this context is the *multinomial logit*. This link function takes a vector of *scores*, one for each $K$ event types, and computed the probability of a particular type of event $K$ as" (p. 323, *emphasis* in the original)

$$\text{Pr} (k |s_1, s_2, ..., s_K) = \frac{\exp (s_k)}{\sum_{i = 1}^K \exp (s_i)}$$

McElreath then went on to explain how multinomial logistic regression models are among the more difficult of the GLMs to master. He wasn't kidding. To get a grasp on these, we'll cover them in a little more detail than he did in the text. To fully flesh this out, our section headers will be more granual than those in the text. Whereas McElreath keps all of the material in Section 10.3.1.1 together, we will break things up into subsections 10.3.1.1.1 through 10.3.1.1.3. 

##### 10.3.1.1.1 "Intercepts"-only.

To begin, let's simulate the data just like McElreath did in the R code 10.56 block.

```{r, warning = F, message = F}
library(rethinking)

# simulate career choices among 500 individuals
n      <- 500           # number of individuals
income <- 1:3           # expected income of each career
score  <- 0.5 * income  # scores for each career, based on income

# next line converts scores to probabilities
p <- softmax(score[1], score[2], score[3])

# now simulate choice
# outcome career holds event type values, not counts
career <- rep(NA, n)  # empty vector of choices for each individual

set.seed(10)
# sample chosen career for each individual
for(i in 1:n) career[i] <- sample(1:3, size = 1, prob = p)
```

Here's what the data look like.

```{r, fig.width = 3, fig.height = 2.25, message = F, warning = F}
tibble(career = career) %>%
  ggplot(aes(x = career)) +
  geom_bar(size = 0, fill = wes_palette("Moonrise2")[2])
```

Our `career` variable is composed of three categories, `1:3`, with each category more likely than the one before. Here's a breakdown of the counts, percentages, and probabilities of each category.

```{r}
tibble(career) %>% 
  count(career) %>% 
  mutate(percent     = (100 * n / sum(n)),
         probability =        n / sum(n))
```

To help build an appreciation for how we simulated data with these proportions and how the process links in with the formulas, above, we'll retrace the first few simulation steps within a tidyverse-centric work flow. Recall how in those first few steps we defined values for `income`, `score`, and `p`. Here they are again in a tibble.

```{r}
tibble(income = 1:3) %>% 
  mutate(score = 0.5 * income) %>% 
  mutate(p = exp(score) / sum(exp(score)))
```

Notice how the values in the `p` column match up well with the `probability` values from the output from the block just above. Our simulation successfully produces data corresponding to the data-generating values. Woot! Also note how the code we just used to compute those `p` values, `p = exp(score) / sum(exp(score))`, corresponds nicely with the formula from above:

$$\text{Pr} (k |s_1, s_2,..., s_K) = \frac{\exp (s_k)}{\sum_{i = 1}^K \exp (s_i)}.$$

What still might seem mysterious is what those $s$ values in the equation are. In the simulation and in the prose, McElreath called them *scores*. Another way to think about them is as weights. The thing to get is that their exact values aren't important so much as their difference one from another. You'll note that `score` for `income == 2` was 0.5 larger than that of `income == 1`. The same was true for `income == 3` and `income == 2`. So if we add an arbitrary constant to each of those `score` values, like 104, we'll get the same `p` values.

```{r}
tibble(score = 104 + c(0.5, 1, 1.5)) %>% 
  mutate(p = exp(score) / sum(exp(score)))
```

Now keeping that in mind, recall how McElreath said that though we have $K$ categories, $K = 3$ in this case, we only estimate $K - 1$ linear models. "In a multinomial (or categorical) GLM, you need $K - 1$ linear models for $K$ types of events" (pp. 323--324). Right before he showed the code for `m10.16`, he further wrote:

> We also have to pick one of the event types to be the reference type. We'll use the first one. Instead of getting a linear model, that type is assigned a constant value. Then the other types get linear models that contain parameters relative to the reference type. (p. 324)

In his model code (R code 10.57), you'll see he used zero as that constant value. As it turns out, it is common practice to set the score value for the reference category to zero. It's also a common practice to use the first event type as the reference category. Importantly, in his [*Parameterization of response distributions in brms*](https://cran.r-project.org/package=brms/vignettes/brms_families.html#ordinal-and-categorical-models) vignette, Bürkner clarified the brms default is to use the first response category as the reference and set it to a zero as well. Returning to our tibble, here are what the `p` values for each `income` level are if we set the `score` for `income == 1` to 0 and have each following `score` value increase by 0.5.

```{r}
tibble(income = 1:3,
       score  = c(0, 0.5, 1)) %>% 
  mutate(p = exp(score) / sum(exp(score)))
```

Those `p` values are still the same as in the prior examples. If our model fitting is successful, our statistical model will return just those probability estimates. To get ready to fit our model, let's switch out rethinking for brms.

```{r, message = F, warning = F}
detach(package:rethinking, unload = T)
library(brms)
```

Before we fit the model, we might take a quick look at the prior structure with `brms::get_prior()`.

```{r}
get_prior(data = list(career = career), 
          family = categorical(link = logit),
          career ~ 1)
```

In brms-parlance, this an Intercepts-only model. We have two "intercepts", which are differentiated in the `dpar` column. We'll talk more about what these are in just a bit; don't worry. I show this here because as of brms 2.12.0, "specifying global priors for regression coefficients in categorical models is deprecated." The upshot is even if we want to use the same prior for both, we need to use the `dpar` argument for each. With that in mind, here's our multinomial model in brms. Do note the specification `family = categorical(link = logit)`.

```{r b10.16}
b10.16 <-
  brm(data = list(career = career), 
      family = categorical(link = logit),
      career ~ 1,
      prior = c(prior(normal(0, 5), class = Intercept, dpar = mu2),
                prior(normal(0, 5), class = Intercept, dpar = mu3)),
      iter = 2500, warmup = 500, cores = 2, chains = 2,
      seed = 10,
      file = "/Users/solomonkurz/Dropbox/Recoding McElreath/fits/b10.16")
```

Check the results.

```{r}
print(b10.16)
```

`brms::brm()` referred to the $K$ categories as `mu1`, `mu2`, and `mu3`. Since `career == 1` is the reference category, the *score* for which was set to zero, there is no parameter for `mu1_Intercept`. That's a zero. Now notice how `mu2_Intercept` is about 0.5 and `mu3_Intercept` is about 1. That's just like those `score` values from our last tibble block! But these parameters are of *scores* or weights; they are not probabilities. This means just applying the `inv_logit_scaled()` function to them won't work.

```{r}
fixef(b10.16) %>% inv_logit_scaled()
```

Those `Estimate` values are not the probability values we're looking for. Why? Because the weights are all relative to one another. The easiest way to get what we want, the probabilities for the three categories, is with `fitted()`. Since this model has no predictors, only intercepts, we won't specify any `newdata`. In such a case, `fitted()` will return fitted values for each case in the data. Going slow, let's take a look at the structure of the output.

```{r}
fitted(b10.16) %>% str()
```

Just as expected, we have 500 rows--one for each case in the original data. We have four summary columns, the typical `Estimate`, `Est.Error`, `Q2.5`, and `Q97.5`. We also have a third dimension composed of three levels, `P(Y = 1)`, `P(Y = 2)`, and `P(Y = 3)`. Those index which of the three `career` categories each probability summary is for. Since the results are identical for each row, we'll simplify the output by only keeping the first row.

```{r}
fitted(b10.16)[1, , ] %>% 
  round(digits = 2)
```

If we take the transpose of that, it will put the results in the order we're more accustomed to.

```{r}
fitted(b10.16)[1, , ] %>% 
  t() %>% 
  round(digits = 2)
```

Now compare those summaries with the empirically-derived `percent` and `probability` values we computed earlier.

```{r}
tibble(career) %>% 
  count(career) %>% 
  mutate(percent     = (100 * n / sum(n)),
         probability =        n / sum(n))
```

We did it!

"Be aware that the estimates you get from these models are extraordinarily difficult to interpret. You absolutely must convert them to a vector of probabilities, to make much sense of them" (p. 325). Indeed. We spent a lot of time fussing about *score* values. But at no time did we really ever care about those. We wanted probabilities! And somewhat maddeningly, the parameters of our `brm()` model were in the metric of $K - 1$ *scores*, not probabilities. *Sigh*.

At least we can get an intuitive diagnostic summary with `pp_check()`.

```{r, fig.width = 5, fig.height = 3.5, message = F}
# this helps us set our custom color scheme
color_scheme_set(wes_palette("Moonrise2")[c(1, 3, 2, 2, 2, 3)])

pp_check(b10.16, type = "hist", binwidth = 1) +
  theme(legend.position = c(.91, .125),
        legend.key = element_rect(color = "transparent"))
```

Our posterior predictive check indicates the model produces synthetic data that resemble the original data.

Before we move on, I have a confession to make. If you look closely at the code McElreath used fo fit his `m10.16`, you'll see it yields a single `b` parameter. But our `b10.16` model has two parameters. *What gives?* Whereas we estimated the score values for `career == 2` and `career == 3` separately, McElreath used an interesting nonlinear syntax to get them with one. We'll discuss this in detail in [Section 10.3.1.1.3][The non-linear syntax is the solution.]. In the meantime, we'll move along to the next example  in the text.

##### 10.3.1.1.2 Add a predictor into the mix.

Here is the second data simulation, this time based on McElreath's R code 10.58.

```{r, warning = F, message = F}
library(rethinking)

n <- 100

set.seed(10)
# simulate family incomes for each individual
family_income <- runif(n)

# assign a unique coefficient for each type of event
b      <- (1:-1)
career <- rep(NA, n)  # empty vector of choices for each individual

for (i in 1:n) {
    score     <- 0.5 * (1:3) + b * family_income[i]
    p         <- softmax(score[1], score[2], score[3])
    career[i] <- sample(1:3, size = 1, prob = p)
}
```

We might examine what the `family_income` distributions look like across the three levels of `career`. We'll do it in two plots and combine them with the patchwork syntax. The first will be overlapping densities. For the second, we'll display the proportions of `career` across a discretized version of `family_income` in a stacked area plot.

```{r, fig.width = 7, fig.height = 3}
p1 <-
  tibble(career = as.factor(career),
       family_income) %>% 
  
  ggplot(aes(x = family_income, fill = career)) +
  geom_density(size = 0, alpha = 3/4) +
  scale_fill_manual(values = wes_palette("Moonrise2")[c(4, 2, 1)]) +
  theme(legend.position = "none")
  

p2 <-
  tibble(career = as.factor(career),
       family_income) %>% 
  mutate(fi = santoku::chop_width(family_income, width = .2, start = 0, labels = 1:5)) %>% 
  count(fi, career) %>% 
  group_by(fi) %>% 
  mutate(proportion = n / sum(n)) %>% 
  mutate(f = as.double(fi)) %>% 
  
  ggplot(aes(x = (f - 1) / 4, y = proportion, fill = career)) +
  geom_area() +
  scale_fill_manual(values = wes_palette("Moonrise2")[c(4, 2, 1)]) +
  xlab("family_income, descritized")

library(patchwork)

p1 + p2
```

If we were working with a larger $N$, we could have gotten away with discretizing `family_income` into narrower bins. This is about as good as it gets with only 100 cases. It's time to switch out rethinking for brms.

```{r, message = F, warning = F}
detach(package:rethinking, unload = T)
library(brms)
```

Here's the brms version of McElreath's `m10.17`.

```{r b10.17}
b10.17 <-
  brm(data = list(career        = career,  # note how we used a list instead of a tibble
                  family_income = family_income), 
      family = categorical(link = logit),
      career ~ 1 + family_income,
      prior = c(prior(normal(0, 5), class = Intercept, dpar = mu2),
                prior(normal(0, 5), class = Intercept, dpar = mu3),
                prior(normal(0, 5), class = b, dpar = mu2),
                prior(normal(0, 5), class = b, dpar = mu3)),
      iter = 2500, warmup = 500, cores = 2, chains = 2,
      seed = 10,
      file = "/Users/solomonkurz/Dropbox/Recoding McElreath/fits/b10.17")
```

Check the summary.

```{r}
print(b10.17)
```

Happily, these results cohere with the rethinking model. Fit the model with McElreath's `rethinking::map()` code and you'll see. "Again, computing implied predictions is the safest way to interpret these models. They do a great job of classifying discrete, unordered events. But the parameters are on a scale that is very hard to interpret" (p. 325). Like before, we'll do that with `fitted()`. Now we have a predictor, this time we will use the `newdata` argument.

```{r}
nd <- tibble(family_income = seq(from = 0, to = 1, length.out = 60))

f <-
  fitted(b10.17,
         newdata = nd)
```

First we'll plot the fitted probabilities for each `career` level across the full range of `family_income` values.

```{r, fig.width = 7, fig.height = 2.75}
# wrangle
rbind(f[, , 1],
      f[, , 2],
      f[, , 3]) %>% 
  data.frame() %>% 
  bind_cols(nd %>% expand(career = 1:3, family_income)) %>% 
  mutate(career = str_c("career: ", career)) %>% 
  
  # plot
  ggplot(aes(x = family_income, y = Estimate,
             ymin = Q2.5, ymax = Q97.5)) +
  geom_ribbon(aes(fill = career),
              alpha = 2/3) +
  geom_line(aes(color = career), 
            size = 3/4) +
  scale_fill_manual(values = wes_palette("Moonrise2")[c(4, 2, 1)]) +
  scale_color_manual(values = wes_palette("Moonrise2")[c(4, 2, 1)]) +
  scale_x_continuous(breaks = 0:2 / 2) +
  scale_y_continuous("probability", limits = c(0, 1),
                     breaks = 0:3 / 3,
                     labels = c("0", ".33", ".67", "1")) +
  theme(axis.text.y = element_text(hjust = 0),
        legend.position = "none") +
  facet_wrap(~career)
```

If we're willing to summarize those fitted lines by their posterior means, we could also make a model-implied version of the stacked area plot from above.

```{r, fig.width = 3.25, fig.height = 3}
# annotation
text <-
  tibble(family_income = c(.25, .5, .75),
         proportion    = c(.2, .5, .8),
         label         = str_c("career: ", 3:1),
         color         = c("a", "a", "b"))

# wrangle
rbind(f[, , 1],
      f[, , 2],
      f[, , 3]) %>% 
  data.frame() %>% 
  bind_cols(nd %>% expand(career = 1:3, family_income)) %>% 
  group_by(family_income) %>% 
  mutate(proportion = Estimate / sum(Estimate),
         career     = factor(career)) %>% 
  
  # plot!
  ggplot(aes(x = family_income, y = proportion)) +
  geom_area(aes(fill = career)) +
  geom_text(data = text,
            aes(label = label, color = color),
            family = "Times", size = 4.25) +
  scale_color_manual(values = wes_palette("Moonrise2")[4:3]) +
  scale_fill_manual(values = wes_palette("Moonrise2")[c(4, 2, 1)]) +
  theme(legend.position = "none")
```

##### 10.3.1.1.3 The non-linear syntax is the solution.

One of the things that differentiates this ebook with [my translation](https://bookdown.org/content/4857/) of McElreath's (2020) 2nd edition is the non-linear syntax. Virtually all of the models in this book can be handled with what you might call the conventional brms syntax. However, brms offers another very flexible way of specifying models in what Bürkner calls the non-linear syntax (see Bürkner's vignette, [*Estimating non-linear models with brms*](https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html)). McElreath has peppered his 2nd edition with models that require this non-linear syntax, which means readers of my translation get a lot of practice using the non-linear syntax. But for this first edition, McElreath's `m10.16` is the only model requiring the non-linear syntax. In this section, I'll provide a brief introduction.

First, let's simulate the data from McElreath's R code 10.56 block again.

```{r, warning = F, message = F}
library(rethinking)

# simulate career choices among 500 individuals
n      <- 500           # number of individuals
income <- 1:3           # expected income of each career
score  <- 0.5 * income  # scores for each career, based on income

# next line converts scores to probabilities
p <- softmax(score[1], score[2], score[3])

# now simulate choice
# outcome career holds event type values, not counts
career <- rep(NA, n)  # empty vector of choices for each individual

set.seed(10)
# sample chosen career for each individual
for(i in 1:n) career[i] <- sample(1:3, size = 1, prob = p)
```

There are at least two alternative ways to fit our `b10.16`, which is based on the conventional brms syntax. The first uses what we might call a verbose version of the conventional syntax. We'll call it `b10.16_verbose`. The second uses the non-linear syntax. We'll call that one `b10.16_nonlinear`. Fit the models.

```{r}
# verbose syntax
b10.16_verbose <-
  brm(data = list(career = career), 
      family = categorical(link = logit),
      bf(career ~ 1,
         mu2 ~ 1,
         mu3 ~ 1),
      prior = c(prior(normal(0, 5), class = Intercept, dpar = mu2),
                prior(normal(0, 5), class = Intercept, dpar = mu3)),
      iter = 2500, warmup = 500, cores = 2, chains = 2,
      seed = 10)

# nonlinear syntax
b10.16_nonlinear <-
  brm(data = list(career = career), 
      family = categorical(link = logit),
      bf(career ~ 1,
         nlf(mu2 ~ a2),
         nlf(mu3 ~ a3),
         a2 + a3 ~ 1),
      prior = c(prior(normal(0, 5), class = b, nlpar = a2),
                prior(normal(0, 5), class = b, nlpar = a3)),
      iter = 2500, warmup = 500, cores = 2, chains = 2,
      seed = 10)
```

We might use `fixef()` to show that the parameter summaries are the same for all three variants--differing only by simulation variance.

```{r}
fixef(b10.16) %>% round(digits = 2)
fixef(b10.16_verbose) %>% round(digits = 2)
fixef(b10.16_nonlinear) %>% round(digits = 2)
```

I point this out because it's the non-linear approach that will allow us to fit a model like McElreath's `m10.16`. My hope is the syntax we used in the `b10.16_verbose` model will help clarify what's going on with the non-linear syntax. When we fit multinomial models with brms, the terse conventional `formula` syntax might not make clear how there are actually $K - 1$ formulas. The more verbose syntax of our `b10.16_verbose` model shows how we can specify those models directly. In our case, that was with those `mu2 ~ 1, mu3 ~ 1` lines. When we switch to the non-linear syntax, we explicitly model `mu2` and `mu3` and, as is typical of the non-linear syntax, we name our parameters. You can see another comparison of these three ways of fitting a multinomial model at the [Nonlinear syntax with a multinomial model?](https://discourse.mc-stan.org/t/nonlinear-syntax-with-a-multinomial-model/16122) thread on the Stan Forums.

Now it's time to focus on the correct brms version of McElreath's `m10.16`. I'm going to call this `b10.16_true`

```{r}
b10.16_true <-
  brm(data = list(career = career), 
      family = categorical(link = logit),
      bf(career ~ 1,
         nlf(mu2 ~ b * 2),
         nlf(mu3 ~ b * 3),
         b ~ 1),
      prior(normal(0, 5), class = b, nlpar = b),
      iter = 2500, warmup = 500, cores = 2, chains = 2,
      seed = 10)
```

What did we just estimate?

```{r}
print(b10.16_true)
```

This summary is probably even more difficult to interpret than the summary for `b10.16`. Getting these posterior draws out of the log-odds metric will help.

```{r, warning = F, message = F}
library(tidybayes)

posterior_samples(b10.16_true) %>% 
  transmute(b = inv_logit_scaled(b_b_Intercept)) %>% 
  mean_qi(b) %>% 
  mutate_if(is.double, round, digits = 2)
```

The posterior for `b` is about 0.59. What might that be? Well, let's spell this out by substituting it into the model `formula` for `b10.16b`. We get `mu2 ~ 0.59 * 2` and `mu3 ~ 0.59 * 3`. Now look back at the first few lines of code form McElreath's R code 10.56.

```{r, eval = F}
# simulate career choices among 500 individuals
n      <- 500           # number of individuals
income <- 1:3           # expected income of each career
score  <- 0.5 * income  # scores for each career, based on income
```

Our `mu2` is the same as the second score value. Our 0.59 is our estimate for the 0.5 value in the bottom line. The `* 2` part in our `formula` syntax is the same as `* income` in the bottom line. What our non-linear model did was allow us to estimate the 0.5 constant we multiplied the `income` values by to simulate the original `score` data.

You may be wondering what we might do with our vector of `b_b_Intercept` draws. Well, after converting the draws out of the log-odds scale, we can carefully multiply them by our three `income` values, which will return the posteriors for the three score values. We can then use the formula form above,

$$\text{Pr} (k |s_1, s_2, ..., s_K) = \frac{\exp (s_k)}{\sum_{i = 1}^K \exp (s_i)},$$

to return the posterior probabilities for each of the career choices based on their `income` values.

```{r}
posterior_samples(b10.16_true) %>% 
  transmute(iter = 1:n(),
            s1   = inv_logit_scaled(b_b_Intercept) * income[1],
            s2   = inv_logit_scaled(b_b_Intercept) * income[2],
            s3   = inv_logit_scaled(b_b_Intercept) * income[3]) %>% 
  gather(key, score, -iter) %>% 
  mutate(income = str_remove(key, "s")) %>% 
  group_by(iter) %>% 
  # use the formula
  mutate(p = exp(score) / sum(exp(score))) %>% 
  group_by(income) %>% 
  mean_qi(p) %>% 
  mutate_if(is.double, round, digits = 2)
```

Those are fairly close to the empirical probabilities based on the data-generating values.

```{r}
tibble(income = income,
       score  = score) %>% 
  mutate(p = exp(score) / sum(exp(score)))
```

I'm not going to dive any further into the brms non-linear syntax in this ebook. You want a deeper understanding, check out Bürkner's vignette, [*Estimating non-linear models with brms*](https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html) or [my translation](https://bookdown.org/content/4857/) of McElreath's 2nd edition. For more practice fitting multinomial models with brms, you might also check out my [translation of Kruschke's text, Chapter 22](https://bookdown.org/content/3686/nominal-predicted-variable.html).

## Session information

```{r}
sessionInfo()
```

